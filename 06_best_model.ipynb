{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import load_data\n",
    "train_dataloader, test_dataloader = load_data(\"output/\", 8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 30\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb51c4658474b02ba7fcc8d93312cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7141 |train_acc : 0.4583 |test_loss : 0.6906 |test_acc : 0.5417 \n",
      "Epoch 2 |train_loss : 0.6917 |train_acc : 0.5238 |test_loss : 0.6909 |test_acc : 0.5417 \n",
      "Epoch 3 |train_loss : 0.6981 |train_acc : 0.3690 |test_loss : 0.6916 |test_acc : 0.5417 \n",
      "Epoch 4 |train_loss : 0.6951 |train_acc : 0.4226 |test_loss : 0.6929 |test_acc : 0.5417 \n",
      "Epoch 5 |train_loss : 0.6945 |train_acc : 0.5357 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 6 |train_loss : 0.7107 |train_acc : 0.5357 |test_loss : 0.6937 |test_acc : 0.5417 \n",
      "Epoch 7 |train_loss : 0.7009 |train_acc : 0.5417 |test_loss : 0.6908 |test_acc : 0.5417 \n",
      "Epoch 8 |train_loss : 0.6936 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 9 |train_loss : 0.6927 |train_acc : 0.5417 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 10 |train_loss : 0.7025 |train_acc : 0.5357 |test_loss : 0.6914 |test_acc : 0.5417 \n",
      "Epoch 11 |train_loss : 0.6942 |train_acc : 0.5298 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 12 |train_loss : 0.6931 |train_acc : 0.5357 |test_loss : 0.6931 |test_acc : 0.4583 \n",
      "Epoch 13 |train_loss : 0.6935 |train_acc : 0.4643 |test_loss : 0.6909 |test_acc : 0.5417 \n",
      "Epoch 14 |train_loss : 0.6922 |train_acc : 0.5476 |test_loss : 0.6890 |test_acc : 0.5417 \n",
      "Epoch 15 |train_loss : 0.7068 |train_acc : 0.5298 |test_loss : 0.7003 |test_acc : 0.5417 \n",
      "Epoch 16 |train_loss : 0.6922 |train_acc : 0.5417 |test_loss : 0.6896 |test_acc : 0.5833 \n",
      "Epoch 17 |train_loss : 0.6968 |train_acc : 0.5238 |test_loss : 0.6892 |test_acc : 0.5417 \n",
      "Epoch 18 |train_loss : 0.6918 |train_acc : 0.5476 |test_loss : 0.6908 |test_acc : 0.5417 \n",
      "Epoch 19 |train_loss : 0.6941 |train_acc : 0.5536 |test_loss : 0.6894 |test_acc : 0.5417 \n",
      "Epoch 20 |train_loss : 0.7023 |train_acc : 0.5357 |test_loss : 0.7188 |test_acc : 0.4583 \n",
      "Epoch 21 |train_loss : 0.6948 |train_acc : 0.5476 |test_loss : 0.6808 |test_acc : 0.5417 \n",
      "Epoch 22 |train_loss : 0.6884 |train_acc : 0.5417 |test_loss : 0.6851 |test_acc : 0.5417 \n",
      "Epoch 23 |train_loss : 0.6546 |train_acc : 0.6607 |test_loss : 0.6065 |test_acc : 0.8750 \n",
      "Epoch 24 |train_loss : 0.6133 |train_acc : 0.8155 |test_loss : 0.6075 |test_acc : 0.5833 \n",
      "Epoch 25 |train_loss : 0.5791 |train_acc : 0.6845 |test_loss : 0.5620 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.5246 |train_acc : 0.8929 |test_loss : 0.5153 |test_acc : 0.9583 \n",
      "Epoch 27 |train_loss : 0.5226 |train_acc : 0.8750 |test_loss : 0.5059 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.4798 |train_acc : 0.7917 |test_loss : 0.4174 |test_acc : 0.9167 \n",
      "Epoch 29 |train_loss : 0.4169 |train_acc : 0.9464 |test_loss : 0.3764 |test_acc : 0.9583 \n",
      "Epoch 30 |train_loss : 0.4868 |train_acc : 0.7321 |test_loss : 0.3739 |test_acc : 0.9583 \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.experiment_generator import run_experiments\n",
    "\n",
    "parameters = {\"epochs\": [30], \"optimizers\":[\"Adam\"], \"models\": [\"custom_resnet152\"]}\n",
    "\n",
    "cm_fig = run_experiments(test_dataloader, train_dataloader, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cm_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un experimento m√°s largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5ceaff3d4244ccbd4d5d8ac7684f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7141 |train_acc : 0.4583 |test_loss : 0.6906 |test_acc : 0.5417 \n",
      "Epoch 2 |train_loss : 0.6914 |train_acc : 0.5238 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 3 |train_loss : 0.6965 |train_acc : 0.4643 |test_loss : 0.6905 |test_acc : 0.4167 \n",
      "Epoch 4 |train_loss : 0.6935 |train_acc : 0.4583 |test_loss : 0.6796 |test_acc : 0.5000 \n",
      "Epoch 5 |train_loss : 0.6670 |train_acc : 0.7798 |test_loss : 0.6563 |test_acc : 0.6667 \n",
      "Epoch 6 |train_loss : 0.6662 |train_acc : 0.5536 |test_loss : 0.6446 |test_acc : 0.6250 \n",
      "Epoch 7 |train_loss : 0.6426 |train_acc : 0.7500 |test_loss : 0.6126 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.6114 |train_acc : 0.7262 |test_loss : 0.5948 |test_acc : 0.7083 \n",
      "Epoch 9 |train_loss : 0.5863 |train_acc : 0.8690 |test_loss : 0.5716 |test_acc : 0.9167 \n",
      "Epoch 10 |train_loss : 0.5565 |train_acc : 0.8036 |test_loss : 0.5372 |test_acc : 0.8750 \n",
      "Epoch 11 |train_loss : 0.5086 |train_acc : 0.9048 |test_loss : 0.4843 |test_acc : 0.8750 \n",
      "Epoch 12 |train_loss : 0.4593 |train_acc : 0.9583 |test_loss : 0.4410 |test_acc : 0.9583 \n",
      "Epoch 13 |train_loss : 0.3903 |train_acc : 0.9821 |test_loss : 0.3661 |test_acc : 1.0000 \n",
      "Epoch 14 |train_loss : 0.3290 |train_acc : 0.9643 |test_loss : 0.3203 |test_acc : 1.0000 \n",
      "Epoch 15 |train_loss : 0.2788 |train_acc : 0.9821 |test_loss : 0.2686 |test_acc : 0.9583 \n",
      "Epoch 16 |train_loss : 0.2110 |train_acc : 0.9643 |test_loss : 0.2024 |test_acc : 1.0000 \n",
      "Epoch 17 |train_loss : 0.2084 |train_acc : 0.9464 |test_loss : 0.1350 |test_acc : 1.0000 \n",
      "Epoch 18 |train_loss : 0.1691 |train_acc : 0.9643 |test_loss : 0.2202 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.1330 |train_acc : 1.0000 |test_loss : 0.0928 |test_acc : 1.0000 \n",
      "Epoch 20 |train_loss : 0.0762 |train_acc : 1.0000 |test_loss : 0.0837 |test_acc : 1.0000 \n",
      "Epoch 21 |train_loss : 0.0710 |train_acc : 1.0000 |test_loss : 0.0778 |test_acc : 1.0000 \n",
      "Epoch 22 |train_loss : 0.0749 |train_acc : 1.0000 |test_loss : 0.0758 |test_acc : 1.0000 \n",
      "Epoch 23 |train_loss : 0.0435 |train_acc : 1.0000 |test_loss : 0.0490 |test_acc : 1.0000 \n",
      "Epoch 24 |train_loss : 0.0374 |train_acc : 1.0000 |test_loss : 0.0470 |test_acc : 1.0000 \n",
      "Epoch 25 |train_loss : 0.0435 |train_acc : 1.0000 |test_loss : 0.0382 |test_acc : 1.0000 \n",
      "Epoch 26 |train_loss : 0.0340 |train_acc : 1.0000 |test_loss : 0.1253 |test_acc : 1.0000 \n",
      "Epoch 27 |train_loss : 0.0421 |train_acc : 1.0000 |test_loss : 0.0321 |test_acc : 1.0000 \n",
      "Epoch 28 |train_loss : 0.0307 |train_acc : 1.0000 |test_loss : 0.0249 |test_acc : 1.0000 \n",
      "Epoch 29 |train_loss : 0.0255 |train_acc : 1.0000 |test_loss : 0.0374 |test_acc : 1.0000 \n",
      "Epoch 30 |train_loss : 0.0171 |train_acc : 1.0000 |test_loss : 0.0220 |test_acc : 1.0000 \n",
      "Epoch 31 |train_loss : 0.0145 |train_acc : 1.0000 |test_loss : 0.0264 |test_acc : 1.0000 \n",
      "Epoch 32 |train_loss : 0.0123 |train_acc : 1.0000 |test_loss : 0.0192 |test_acc : 1.0000 \n",
      "Epoch 33 |train_loss : 0.0112 |train_acc : 1.0000 |test_loss : 0.0191 |test_acc : 1.0000 \n",
      "Epoch 34 |train_loss : 0.0101 |train_acc : 1.0000 |test_loss : 0.0179 |test_acc : 1.0000 \n",
      "Epoch 35 |train_loss : 0.0089 |train_acc : 1.0000 |test_loss : 0.0161 |test_acc : 1.0000 \n",
      "Epoch 36 |train_loss : 0.0081 |train_acc : 1.0000 |test_loss : 0.0165 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0074 |train_acc : 1.0000 |test_loss : 0.0159 |test_acc : 1.0000 \n",
      "Epoch 38 |train_loss : 0.0068 |train_acc : 1.0000 |test_loss : 0.0145 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0065 |train_acc : 1.0000 |test_loss : 0.0154 |test_acc : 1.0000 \n",
      "Epoch 40 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.0119 |test_acc : 1.0000 \n",
      "Epoch 41 |train_loss : 0.0056 |train_acc : 1.0000 |test_loss : 0.0122 |test_acc : 1.0000 \n",
      "Epoch 42 |train_loss : 0.0056 |train_acc : 1.0000 |test_loss : 0.0113 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0051 |train_acc : 1.0000 |test_loss : 0.0119 |test_acc : 1.0000 \n",
      "Epoch 44 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.0105 |test_acc : 1.0000 \n",
      "Epoch 45 |train_loss : 0.0043 |train_acc : 1.0000 |test_loss : 0.0103 |test_acc : 1.0000 \n",
      "Epoch 46 |train_loss : 0.0041 |train_acc : 1.0000 |test_loss : 0.0097 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0039 |train_acc : 1.0000 |test_loss : 0.0104 |test_acc : 1.0000 \n",
      "Epoch 48 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 0.0086 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.0100 |test_acc : 1.0000 \n",
      "Epoch 50 |train_loss : 0.0041 |train_acc : 1.0000 |test_loss : 0.0081 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 2\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63daf290ad848a59e3e48486deb64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7106 |train_acc : 0.5655 |test_loss : 0.6868 |test_acc : 0.5417 \n",
      "Epoch 2 |train_loss : 0.6910 |train_acc : 0.5417 |test_loss : 0.6827 |test_acc : 0.5417 \n",
      "Epoch 3 |train_loss : 0.6845 |train_acc : 0.5417 |test_loss : 0.6747 |test_acc : 0.5417 \n",
      "Epoch 4 |train_loss : 0.6771 |train_acc : 0.5417 |test_loss : 0.6693 |test_acc : 0.5417 \n",
      "Epoch 5 |train_loss : 0.6643 |train_acc : 0.5833 |test_loss : 0.6611 |test_acc : 0.5417 \n",
      "Epoch 6 |train_loss : 0.6587 |train_acc : 0.6310 |test_loss : 0.6519 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.6541 |train_acc : 0.6071 |test_loss : 0.6434 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.6504 |train_acc : 0.7321 |test_loss : 0.6351 |test_acc : 0.9167 \n",
      "Epoch 9 |train_loss : 0.6382 |train_acc : 0.6607 |test_loss : 0.6460 |test_acc : 0.5833 \n",
      "Epoch 10 |train_loss : 0.6294 |train_acc : 0.7619 |test_loss : 0.6247 |test_acc : 0.9167 \n",
      "Epoch 11 |train_loss : 0.6207 |train_acc : 0.8155 |test_loss : 0.6158 |test_acc : 0.7500 \n",
      "Epoch 12 |train_loss : 0.6068 |train_acc : 0.6905 |test_loss : 0.6027 |test_acc : 0.8333 \n",
      "Epoch 13 |train_loss : 0.6007 |train_acc : 0.7679 |test_loss : 0.5920 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.5870 |train_acc : 0.7619 |test_loss : 0.5806 |test_acc : 0.9167 \n",
      "Epoch 15 |train_loss : 0.5711 |train_acc : 0.9107 |test_loss : 0.5676 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.5559 |train_acc : 0.8929 |test_loss : 0.5599 |test_acc : 0.9167 \n",
      "Epoch 17 |train_loss : 0.5508 |train_acc : 0.8690 |test_loss : 0.5527 |test_acc : 0.9583 \n",
      "Epoch 18 |train_loss : 0.5478 |train_acc : 0.8988 |test_loss : 0.5353 |test_acc : 0.8333 \n",
      "Epoch 19 |train_loss : 0.5098 |train_acc : 0.8512 |test_loss : 0.5159 |test_acc : 0.9583 \n",
      "Epoch 20 |train_loss : 0.5486 |train_acc : 0.7679 |test_loss : 0.5674 |test_acc : 0.7500 \n",
      "Epoch 21 |train_loss : 0.5256 |train_acc : 0.8869 |test_loss : 0.5346 |test_acc : 0.9167 \n",
      "Epoch 22 |train_loss : 0.5080 |train_acc : 0.9048 |test_loss : 0.5083 |test_acc : 0.9583 \n",
      "Epoch 23 |train_loss : 0.4777 |train_acc : 0.9583 |test_loss : 0.4414 |test_acc : 1.0000 \n",
      "Epoch 24 |train_loss : 0.4105 |train_acc : 0.9821 |test_loss : 0.3902 |test_acc : 0.9583 \n",
      "Epoch 25 |train_loss : 0.3866 |train_acc : 0.9464 |test_loss : 0.3389 |test_acc : 0.9583 \n",
      "Epoch 26 |train_loss : 0.3535 |train_acc : 0.9286 |test_loss : 0.3127 |test_acc : 1.0000 \n",
      "Epoch 27 |train_loss : 0.3018 |train_acc : 0.9643 |test_loss : 0.2840 |test_acc : 1.0000 \n",
      "Epoch 28 |train_loss : 0.2729 |train_acc : 0.9643 |test_loss : 0.3417 |test_acc : 0.8333 \n",
      "Epoch 29 |train_loss : 0.2630 |train_acc : 0.9107 |test_loss : 0.2742 |test_acc : 1.0000 \n",
      "Epoch 30 |train_loss : 0.2327 |train_acc : 1.0000 |test_loss : 0.2407 |test_acc : 0.9583 \n",
      "Epoch 31 |train_loss : 0.1813 |train_acc : 1.0000 |test_loss : 0.2360 |test_acc : 1.0000 \n",
      "Epoch 32 |train_loss : 0.1617 |train_acc : 1.0000 |test_loss : 0.1930 |test_acc : 1.0000 \n",
      "Epoch 33 |train_loss : 0.1338 |train_acc : 1.0000 |test_loss : 0.1430 |test_acc : 1.0000 \n",
      "Epoch 34 |train_loss : 0.1173 |train_acc : 1.0000 |test_loss : 0.1316 |test_acc : 1.0000 \n",
      "Epoch 35 |train_loss : 0.0850 |train_acc : 1.0000 |test_loss : 0.1415 |test_acc : 0.9583 \n",
      "Epoch 36 |train_loss : 0.0786 |train_acc : 1.0000 |test_loss : 0.1222 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0822 |train_acc : 1.0000 |test_loss : 0.0963 |test_acc : 1.0000 \n",
      "Epoch 38 |train_loss : 0.0684 |train_acc : 1.0000 |test_loss : 0.0848 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0697 |train_acc : 1.0000 |test_loss : 0.0863 |test_acc : 1.0000 \n",
      "Epoch 40 |train_loss : 0.0564 |train_acc : 1.0000 |test_loss : 0.0662 |test_acc : 1.0000 \n",
      "Epoch 41 |train_loss : 0.0412 |train_acc : 1.0000 |test_loss : 0.0729 |test_acc : 1.0000 \n",
      "Epoch 42 |train_loss : 0.0333 |train_acc : 1.0000 |test_loss : 0.0641 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0280 |train_acc : 1.0000 |test_loss : 0.0763 |test_acc : 1.0000 \n",
      "Epoch 44 |train_loss : 0.0377 |train_acc : 1.0000 |test_loss : 0.0576 |test_acc : 1.0000 \n",
      "Epoch 45 |train_loss : 0.0276 |train_acc : 1.0000 |test_loss : 0.0509 |test_acc : 1.0000 \n",
      "Epoch 46 |train_loss : 0.0204 |train_acc : 1.0000 |test_loss : 0.0670 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0169 |train_acc : 1.0000 |test_loss : 0.0491 |test_acc : 1.0000 \n",
      "Epoch 48 |train_loss : 0.0148 |train_acc : 1.0000 |test_loss : 0.0377 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0114 |train_acc : 1.0000 |test_loss : 0.0311 |test_acc : 1.0000 \n",
      "Epoch 50 |train_loss : 0.0094 |train_acc : 1.0000 |test_loss : 0.0281 |test_acc : 1.0000 \n",
      "Epoch 51 |train_loss : 0.0080 |train_acc : 1.0000 |test_loss : 0.0276 |test_acc : 1.0000 \n",
      "Epoch 52 |train_loss : 0.0068 |train_acc : 1.0000 |test_loss : 0.0255 |test_acc : 1.0000 \n",
      "Epoch 53 |train_loss : 0.0062 |train_acc : 1.0000 |test_loss : 0.0236 |test_acc : 1.0000 \n",
      "Epoch 54 |train_loss : 0.0054 |train_acc : 1.0000 |test_loss : 0.0226 |test_acc : 1.0000 \n",
      "Epoch 55 |train_loss : 0.0050 |train_acc : 1.0000 |test_loss : 0.0213 |test_acc : 1.0000 \n",
      "Epoch 56 |train_loss : 0.0046 |train_acc : 1.0000 |test_loss : 0.0205 |test_acc : 1.0000 \n",
      "Epoch 57 |train_loss : 0.0042 |train_acc : 1.0000 |test_loss : 0.0197 |test_acc : 1.0000 \n",
      "Epoch 58 |train_loss : 0.0042 |train_acc : 1.0000 |test_loss : 0.0203 |test_acc : 1.0000 \n",
      "Epoch 59 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.0189 |test_acc : 1.0000 \n",
      "Epoch 60 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.0177 |test_acc : 1.0000 \n",
      "Epoch 61 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.0172 |test_acc : 1.0000 \n",
      "Epoch 62 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.0172 |test_acc : 1.0000 \n",
      "Epoch 63 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.0164 |test_acc : 1.0000 \n",
      "Epoch 64 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.0164 |test_acc : 1.0000 \n",
      "Epoch 65 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.0145 |test_acc : 1.0000 \n",
      "Epoch 66 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.0145 |test_acc : 1.0000 \n",
      "Epoch 67 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.0159 |test_acc : 1.0000 \n",
      "Epoch 68 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0138 |test_acc : 1.0000 \n",
      "Epoch 69 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0136 |test_acc : 1.0000 \n",
      "Epoch 70 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0136 |test_acc : 1.0000 \n",
      "Epoch 71 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0130 |test_acc : 1.0000 \n",
      "Epoch 72 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0130 |test_acc : 1.0000 \n",
      "Epoch 73 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0126 |test_acc : 1.0000 \n",
      "Epoch 74 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0123 |test_acc : 1.0000 \n",
      "Epoch 75 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0122 |test_acc : 1.0000 \n",
      "Epoch 76 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0119 |test_acc : 1.0000 \n",
      "Epoch 77 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0119 |test_acc : 1.0000 \n",
      "Epoch 78 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0119 |test_acc : 1.0000 \n",
      "Epoch 79 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0111 |test_acc : 1.0000 \n",
      "Epoch 80 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0107 |test_acc : 1.0000 \n",
      "Epoch 81 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0109 |test_acc : 1.0000 \n",
      "Epoch 82 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0103 |test_acc : 1.0000 \n",
      "Epoch 83 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0109 |test_acc : 1.0000 \n",
      "Epoch 84 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0108 |test_acc : 1.0000 \n",
      "Epoch 85 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0102 |test_acc : 1.0000 \n",
      "Epoch 86 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0105 |test_acc : 1.0000 \n",
      "Epoch 87 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0102 |test_acc : 1.0000 \n",
      "Epoch 88 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0102 |test_acc : 1.0000 \n",
      "Epoch 89 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0108 |test_acc : 1.0000 \n",
      "Epoch 90 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0098 |test_acc : 1.0000 \n",
      "Epoch 91 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0107 |test_acc : 1.0000 \n",
      "Epoch 92 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0101 |test_acc : 1.0000 \n",
      "Epoch 93 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0094 |test_acc : 1.0000 \n",
      "Epoch 94 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0097 |test_acc : 1.0000 \n",
      "Epoch 95 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0088 |test_acc : 1.0000 \n",
      "Epoch 96 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0095 |test_acc : 1.0000 \n",
      "Epoch 97 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0094 |test_acc : 1.0000 \n",
      "Epoch 98 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0091 |test_acc : 1.0000 \n",
      "Epoch 99 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0091 |test_acc : 1.0000 \n",
      "Epoch 100 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0093 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 3\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab36f6f3a5034ab5ab4817b4cffb4664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7234 |train_acc : 0.4226 |test_loss : 0.6991 |test_acc : 0.5417 \n",
      "Epoch 2 |train_loss : 0.6964 |train_acc : 0.5238 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 3 |train_loss : 0.7078 |train_acc : 0.4643 |test_loss : 0.7008 |test_acc : 0.4583 \n",
      "Epoch 4 |train_loss : 0.7058 |train_acc : 0.4167 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 5 |train_loss : 0.6957 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 6 |train_loss : 0.6911 |train_acc : 0.5417 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 7 |train_loss : 0.6926 |train_acc : 0.5357 |test_loss : 0.6904 |test_acc : 0.5417 \n",
      "Epoch 8 |train_loss : 0.6921 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 9 |train_loss : 0.6951 |train_acc : 0.5357 |test_loss : 0.6922 |test_acc : 0.5417 \n",
      "Epoch 10 |train_loss : 0.7026 |train_acc : 0.5357 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 11 |train_loss : 0.6942 |train_acc : 0.5298 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 12 |train_loss : 0.6915 |train_acc : 0.5357 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 13 |train_loss : 0.6914 |train_acc : 0.5417 |test_loss : 0.6902 |test_acc : 0.5417 \n",
      "Epoch 14 |train_loss : 0.6965 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 15 |train_loss : 0.6930 |train_acc : 0.5417 |test_loss : 0.6907 |test_acc : 0.5417 \n",
      "Epoch 16 |train_loss : 0.6954 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 17 |train_loss : 0.6969 |train_acc : 0.5357 |test_loss : 0.6909 |test_acc : 0.5417 \n",
      "Epoch 18 |train_loss : 0.6911 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 19 |train_loss : 0.6940 |train_acc : 0.5298 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 20 |train_loss : 0.6958 |train_acc : 0.5238 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 21 |train_loss : 0.6962 |train_acc : 0.4583 |test_loss : 0.6941 |test_acc : 0.4583 \n",
      "Epoch 22 |train_loss : 0.7017 |train_acc : 0.4583 |test_loss : 0.6921 |test_acc : 0.5417 \n",
      "Epoch 23 |train_loss : 0.7041 |train_acc : 0.5298 |test_loss : 0.6981 |test_acc : 0.5417 \n",
      "Epoch 24 |train_loss : 0.7030 |train_acc : 0.5238 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 25 |train_loss : 0.6918 |train_acc : 0.5298 |test_loss : 0.6903 |test_acc : 0.5417 \n",
      "Epoch 26 |train_loss : 0.7174 |train_acc : 0.3214 |test_loss : 0.6989 |test_acc : 0.4583 \n",
      "Epoch 27 |train_loss : 0.6921 |train_acc : 0.5000 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 28 |train_loss : 0.7116 |train_acc : 0.5298 |test_loss : 0.6984 |test_acc : 0.5417 \n",
      "Epoch 29 |train_loss : 0.6929 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 30 |train_loss : 0.7110 |train_acc : 0.3869 |test_loss : 0.6996 |test_acc : 0.4583 \n",
      "Epoch 31 |train_loss : 0.6969 |train_acc : 0.4643 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 32 |train_loss : 0.6958 |train_acc : 0.5476 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 33 |train_loss : 0.6920 |train_acc : 0.5417 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 34 |train_loss : 0.6946 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 35 |train_loss : 0.6919 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 36 |train_loss : 0.6938 |train_acc : 0.5357 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 37 |train_loss : 0.6910 |train_acc : 0.5357 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 38 |train_loss : 0.6996 |train_acc : 0.5298 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 39 |train_loss : 0.7036 |train_acc : 0.3452 |test_loss : 0.6935 |test_acc : 0.4583 \n",
      "Epoch 40 |train_loss : 0.6991 |train_acc : 0.5000 |test_loss : 0.6922 |test_acc : 0.5417 \n",
      "Epoch 41 |train_loss : 0.6995 |train_acc : 0.5298 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 42 |train_loss : 0.6912 |train_acc : 0.5298 |test_loss : 0.6904 |test_acc : 0.5417 \n",
      "Epoch 43 |train_loss : 0.6927 |train_acc : 0.5298 |test_loss : 0.6955 |test_acc : 0.4583 \n",
      "Epoch 44 |train_loss : 0.6967 |train_acc : 0.4643 |test_loss : 0.6904 |test_acc : 0.5417 \n",
      "Epoch 45 |train_loss : 0.7033 |train_acc : 0.5298 |test_loss : 0.6938 |test_acc : 0.5417 \n",
      "Epoch 46 |train_loss : 0.6943 |train_acc : 0.5417 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 47 |train_loss : 0.6957 |train_acc : 0.5298 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 48 |train_loss : 0.6936 |train_acc : 0.5417 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 49 |train_loss : 0.6943 |train_acc : 0.5476 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 50 |train_loss : 0.6973 |train_acc : 0.5298 |test_loss : 0.6920 |test_acc : 0.5417 \n",
      "Epoch 51 |train_loss : 0.6955 |train_acc : 0.5238 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 52 |train_loss : 0.6901 |train_acc : 0.5298 |test_loss : 0.6921 |test_acc : 0.5417 \n",
      "Epoch 53 |train_loss : 0.7032 |train_acc : 0.4286 |test_loss : 0.6949 |test_acc : 0.4583 \n",
      "Epoch 54 |train_loss : 0.6888 |train_acc : 0.5476 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 55 |train_loss : 0.6958 |train_acc : 0.5417 |test_loss : 0.6944 |test_acc : 0.5417 \n",
      "Epoch 56 |train_loss : 0.7035 |train_acc : 0.5298 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 57 |train_loss : 0.6987 |train_acc : 0.5060 |test_loss : 0.6912 |test_acc : 0.5417 \n",
      "Epoch 58 |train_loss : 0.6978 |train_acc : 0.5417 |test_loss : 0.6903 |test_acc : 0.5417 \n",
      "Epoch 59 |train_loss : 0.6956 |train_acc : 0.5357 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 60 |train_loss : 0.6905 |train_acc : 0.5357 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 61 |train_loss : 0.7004 |train_acc : 0.4286 |test_loss : 0.6921 |test_acc : 0.5417 \n",
      "Epoch 62 |train_loss : 0.6890 |train_acc : 0.5476 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 63 |train_loss : 0.6914 |train_acc : 0.5417 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 64 |train_loss : 0.6959 |train_acc : 0.5417 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 65 |train_loss : 0.6916 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 66 |train_loss : 0.6990 |train_acc : 0.5238 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 67 |train_loss : 0.7085 |train_acc : 0.3869 |test_loss : 0.6980 |test_acc : 0.4583 \n",
      "Epoch 68 |train_loss : 0.7008 |train_acc : 0.4940 |test_loss : 0.6904 |test_acc : 0.5417 \n",
      "Epoch 69 |train_loss : 0.6982 |train_acc : 0.5417 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 70 |train_loss : 0.6925 |train_acc : 0.5476 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 71 |train_loss : 0.6952 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 72 |train_loss : 0.6914 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 73 |train_loss : 0.6975 |train_acc : 0.5298 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 74 |train_loss : 0.6946 |train_acc : 0.5357 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 75 |train_loss : 0.6913 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 76 |train_loss : 0.6903 |train_acc : 0.5417 |test_loss : 0.6906 |test_acc : 0.5417 \n",
      "Epoch 77 |train_loss : 0.6947 |train_acc : 0.5357 |test_loss : 0.6916 |test_acc : 0.5417 \n",
      "Epoch 78 |train_loss : 0.7028 |train_acc : 0.5238 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 79 |train_loss : 0.6916 |train_acc : 0.5417 |test_loss : 0.6908 |test_acc : 0.5417 \n",
      "Epoch 80 |train_loss : 0.7008 |train_acc : 0.3512 |test_loss : 0.6921 |test_acc : 0.5417 \n",
      "Epoch 81 |train_loss : 0.6873 |train_acc : 0.5476 |test_loss : 0.6909 |test_acc : 0.5417 \n",
      "Epoch 82 |train_loss : 0.6938 |train_acc : 0.5357 |test_loss : 0.6924 |test_acc : 0.5417 \n",
      "Epoch 83 |train_loss : 0.6958 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 84 |train_loss : 0.6960 |train_acc : 0.5357 |test_loss : 0.6903 |test_acc : 0.5417 \n",
      "Epoch 85 |train_loss : 0.6944 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 86 |train_loss : 0.6910 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 87 |train_loss : 0.6978 |train_acc : 0.5238 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 88 |train_loss : 0.7087 |train_acc : 0.3929 |test_loss : 0.6952 |test_acc : 0.4583 \n",
      "Epoch 89 |train_loss : 0.6988 |train_acc : 0.4226 |test_loss : 0.6903 |test_acc : 0.5417 \n",
      "Epoch 90 |train_loss : 0.7195 |train_acc : 0.5238 |test_loss : 0.6987 |test_acc : 0.5417 \n",
      "Epoch 91 |train_loss : 0.6936 |train_acc : 0.5357 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 92 |train_loss : 0.6936 |train_acc : 0.5238 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 93 |train_loss : 0.6959 |train_acc : 0.4702 |test_loss : 0.6945 |test_acc : 0.4583 \n",
      "Epoch 94 |train_loss : 0.6937 |train_acc : 0.4762 |test_loss : 0.6908 |test_acc : 0.5417 \n",
      "Epoch 95 |train_loss : 0.7070 |train_acc : 0.5357 |test_loss : 0.6931 |test_acc : 0.5417 \n",
      "Epoch 96 |train_loss : 0.7002 |train_acc : 0.5536 |test_loss : 0.6908 |test_acc : 0.5417 \n",
      "Epoch 97 |train_loss : 0.6929 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 98 |train_loss : 0.6916 |train_acc : 0.5417 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 99 |train_loss : 0.6926 |train_acc : 0.5417 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 100 |train_loss : 0.6926 |train_acc : 0.5417 |test_loss : 0.6902 |test_acc : 0.5417 \n",
      "Epoch 101 |train_loss : 0.6914 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 102 |train_loss : 0.7028 |train_acc : 0.5298 |test_loss : 0.6914 |test_acc : 0.5417 \n",
      "Epoch 103 |train_loss : 0.6914 |train_acc : 0.5357 |test_loss : 0.6913 |test_acc : 0.5417 \n",
      "Epoch 104 |train_loss : 0.6919 |train_acc : 0.5417 |test_loss : 0.6918 |test_acc : 0.5417 \n",
      "Epoch 105 |train_loss : 0.6929 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 106 |train_loss : 0.6919 |train_acc : 0.5476 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 107 |train_loss : 0.7020 |train_acc : 0.5357 |test_loss : 0.6922 |test_acc : 0.5417 \n",
      "Epoch 108 |train_loss : 0.7031 |train_acc : 0.5536 |test_loss : 0.6919 |test_acc : 0.5417 \n",
      "Epoch 109 |train_loss : 0.7072 |train_acc : 0.5238 |test_loss : 0.6920 |test_acc : 0.5417 \n",
      "Epoch 110 |train_loss : 0.6942 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 111 |train_loss : 0.6971 |train_acc : 0.4643 |test_loss : 0.6937 |test_acc : 0.4583 \n",
      "Epoch 112 |train_loss : 0.6960 |train_acc : 0.4524 |test_loss : 0.6919 |test_acc : 0.5417 \n",
      "Epoch 113 |train_loss : 0.6968 |train_acc : 0.5357 |test_loss : 0.6947 |test_acc : 0.5417 \n",
      "Epoch 114 |train_loss : 0.6946 |train_acc : 0.5417 |test_loss : 0.6903 |test_acc : 0.5417 \n",
      "Epoch 115 |train_loss : 0.6941 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 116 |train_loss : 0.7009 |train_acc : 0.4226 |test_loss : 0.6947 |test_acc : 0.4583 \n",
      "Epoch 117 |train_loss : 0.7093 |train_acc : 0.4286 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 118 |train_loss : 0.6909 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 119 |train_loss : 0.6913 |train_acc : 0.5357 |test_loss : 0.6906 |test_acc : 0.5417 \n",
      "Epoch 120 |train_loss : 0.6944 |train_acc : 0.5298 |test_loss : 0.6902 |test_acc : 0.5417 \n",
      "Epoch 121 |train_loss : 0.6931 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 122 |train_loss : 0.6964 |train_acc : 0.5298 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 123 |train_loss : 0.6951 |train_acc : 0.5298 |test_loss : 0.6905 |test_acc : 0.5417 \n",
      "Epoch 124 |train_loss : 0.6960 |train_acc : 0.5298 |test_loss : 0.6904 |test_acc : 0.5417 \n",
      "Epoch 125 |train_loss : 0.6982 |train_acc : 0.5238 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 126 |train_loss : 0.6942 |train_acc : 0.5357 |test_loss : 0.6910 |test_acc : 0.5417 \n",
      "Epoch 127 |train_loss : 0.6959 |train_acc : 0.5357 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 128 |train_loss : 0.6955 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 129 |train_loss : 0.6977 |train_acc : 0.5357 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 130 |train_loss : 0.6985 |train_acc : 0.4226 |test_loss : 0.6972 |test_acc : 0.4583 \n",
      "Epoch 131 |train_loss : 0.6967 |train_acc : 0.4226 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "Epoch 132 |train_loss : 0.6887 |train_acc : 0.5417 |test_loss : 0.6902 |test_acc : 0.5417 \n",
      "Epoch 133 |train_loss : 0.6955 |train_acc : 0.5417 |test_loss : 0.6916 |test_acc : 0.5417 \n",
      "Epoch 134 |train_loss : 0.6991 |train_acc : 0.5238 |test_loss : 0.6901 |test_acc : 0.5417 \n",
      "Epoch 135 |train_loss : 0.6979 |train_acc : 0.5000 |test_loss : 0.6955 |test_acc : 0.4583 \n",
      "Epoch 136 |train_loss : 0.6960 |train_acc : 0.4643 |test_loss : 0.6915 |test_acc : 0.5417 \n",
      "Epoch 137 |train_loss : 0.6968 |train_acc : 0.5357 |test_loss : 0.6918 |test_acc : 0.5417 \n",
      "Epoch 138 |train_loss : 0.6948 |train_acc : 0.5357 |test_loss : 0.6902 |test_acc : 0.5417 \n",
      "Epoch 139 |train_loss : 0.6980 |train_acc : 0.5417 |test_loss : 0.6916 |test_acc : 0.5417 \n",
      "Epoch 140 |train_loss : 0.6976 |train_acc : 0.3988 |test_loss : 0.6912 |test_acc : 0.5417 \n",
      "Epoch 141 |train_loss : 0.7235 |train_acc : 0.5238 |test_loss : 0.6988 |test_acc : 0.5417 \n",
      "Epoch 142 |train_loss : 0.6926 |train_acc : 0.5298 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 143 |train_loss : 0.6953 |train_acc : 0.4940 |test_loss : 0.6955 |test_acc : 0.4583 \n",
      "Epoch 144 |train_loss : 0.6957 |train_acc : 0.4643 |test_loss : 0.6925 |test_acc : 0.5417 \n",
      "Epoch 145 |train_loss : 0.6914 |train_acc : 0.4345 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 146 |train_loss : 0.6959 |train_acc : 0.5298 |test_loss : 0.6931 |test_acc : 0.5417 \n",
      "Epoch 147 |train_loss : 0.6972 |train_acc : 0.5417 |test_loss : 0.6899 |test_acc : 0.5417 \n",
      "Epoch 148 |train_loss : 0.6919 |train_acc : 0.5357 |test_loss : 0.6898 |test_acc : 0.5417 \n",
      "Epoch 149 |train_loss : 0.6969 |train_acc : 0.5417 |test_loss : 0.6897 |test_acc : 0.5417 \n",
      "Epoch 150 |train_loss : 0.6954 |train_acc : 0.5357 |test_loss : 0.6900 |test_acc : 0.5417 \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"epochs\": [50, 100, 150], \"optimizers\":[\"Adam\"], \"models\": [\"custom_resnet152\"]}\n",
    "cm_fig = run_experiments(test_dataloader, train_dataloader, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin aumentar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import load_data\n",
    "\n",
    "train_dataloader, test_dataloader = load_data(\"output/\", 4, augmentation=False, all_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de etiquetas en el conjunto de entrenamiento: {0: 13, 1: 29}\n",
      "Conteo de etiquetas en el conjunto de prueba: {0: 5, 1: 13}\n"
     ]
    }
   ],
   "source": [
    "contador = {0: 0, 1: 0}\n",
    "\n",
    "for _, label in train_dataloader:\n",
    "    for l in label:\n",
    "        contador[l.item()] += 1\n",
    "\n",
    "print(f\"Conteo de etiquetas en el conjunto de entrenamiento: {contador}\")\n",
    "\n",
    "\n",
    "contador = {0: 0, 1: 0}\n",
    "for _, label in test_dataloader:\n",
    "    for l in label:\n",
    "        contador[l.item()] += 1\n",
    "\n",
    "print(f\"Conteo de etiquetas en el conjunto de prueba: {contador}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d50c34ff7a64390bcd9f19252110345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.6759 |train_acc : 0.5000 |test_loss : 0.5551 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.5340 |train_acc : 0.7292 |test_loss : 0.4775 |test_acc : 0.7917 \n",
      "Epoch 3 |train_loss : 0.5849 |train_acc : 0.7292 |test_loss : 0.5877 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.5076 |train_acc : 0.7292 |test_loss : 0.5566 |test_acc : 0.6667 \n",
      "Epoch 5 |train_loss : 0.4833 |train_acc : 0.6875 |test_loss : 0.5771 |test_acc : 0.7083 \n",
      "Epoch 6 |train_loss : 0.4654 |train_acc : 0.7708 |test_loss : 0.6619 |test_acc : 0.6667 \n",
      "Epoch 7 |train_loss : 0.5021 |train_acc : 0.7500 |test_loss : 0.4751 |test_acc : 0.8333 \n",
      "Epoch 8 |train_loss : 0.4925 |train_acc : 0.8125 |test_loss : 0.3775 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.3181 |train_acc : 0.8958 |test_loss : 0.4598 |test_acc : 0.7500 \n",
      "Epoch 10 |train_loss : 0.3073 |train_acc : 0.8958 |test_loss : 0.3850 |test_acc : 0.7917 \n",
      "Epoch 11 |train_loss : 0.2451 |train_acc : 0.9792 |test_loss : 0.3314 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.2288 |train_acc : 0.9792 |test_loss : 0.4101 |test_acc : 0.8750 \n",
      "Epoch 13 |train_loss : 0.2354 |train_acc : 0.9583 |test_loss : 0.5717 |test_acc : 0.7083 \n",
      "Epoch 14 |train_loss : 0.3424 |train_acc : 0.8125 |test_loss : 0.3652 |test_acc : 0.7500 \n",
      "Epoch 15 |train_loss : 0.3114 |train_acc : 0.8750 |test_loss : 0.2370 |test_acc : 0.8333 \n",
      "Epoch 16 |train_loss : 0.1551 |train_acc : 0.9375 |test_loss : 0.2554 |test_acc : 0.9167 \n",
      "Epoch 17 |train_loss : 0.2020 |train_acc : 0.9583 |test_loss : 0.3959 |test_acc : 0.7917 \n",
      "Epoch 18 |train_loss : 0.1561 |train_acc : 0.9792 |test_loss : 0.2117 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.1427 |train_acc : 0.9792 |test_loss : 0.2526 |test_acc : 0.9167 \n",
      "Epoch 20 |train_loss : 0.1189 |train_acc : 1.0000 |test_loss : 0.1693 |test_acc : 0.9167 \n",
      "Epoch 21 |train_loss : 0.0872 |train_acc : 1.0000 |test_loss : 0.1856 |test_acc : 0.9583 \n",
      "Epoch 22 |train_loss : 0.1035 |train_acc : 0.9792 |test_loss : 0.0991 |test_acc : 1.0000 \n",
      "Epoch 23 |train_loss : 0.0695 |train_acc : 1.0000 |test_loss : 0.1045 |test_acc : 1.0000 \n",
      "Epoch 24 |train_loss : 0.0543 |train_acc : 1.0000 |test_loss : 0.1260 |test_acc : 0.9583 \n",
      "Epoch 25 |train_loss : 0.0526 |train_acc : 1.0000 |test_loss : 0.0894 |test_acc : 1.0000 \n",
      "Epoch 26 |train_loss : 0.0399 |train_acc : 1.0000 |test_loss : 0.0853 |test_acc : 1.0000 \n",
      "Epoch 27 |train_loss : 0.0459 |train_acc : 1.0000 |test_loss : 0.0884 |test_acc : 1.0000 \n",
      "Epoch 28 |train_loss : 0.0510 |train_acc : 1.0000 |test_loss : 0.0924 |test_acc : 0.9583 \n",
      "Epoch 29 |train_loss : 0.0494 |train_acc : 1.0000 |test_loss : 0.0729 |test_acc : 1.0000 \n",
      "Epoch 30 |train_loss : 0.0537 |train_acc : 1.0000 |test_loss : 0.0760 |test_acc : 1.0000 \n",
      "Epoch 31 |train_loss : 0.0286 |train_acc : 1.0000 |test_loss : 0.1129 |test_acc : 0.9583 \n",
      "Epoch 32 |train_loss : 0.0456 |train_acc : 1.0000 |test_loss : 0.0643 |test_acc : 1.0000 \n",
      "Epoch 33 |train_loss : 0.0349 |train_acc : 1.0000 |test_loss : 0.1212 |test_acc : 1.0000 \n",
      "Epoch 34 |train_loss : 0.0302 |train_acc : 1.0000 |test_loss : 0.0717 |test_acc : 1.0000 \n",
      "Epoch 35 |train_loss : 0.0250 |train_acc : 1.0000 |test_loss : 0.0555 |test_acc : 1.0000 \n",
      "Epoch 36 |train_loss : 0.0217 |train_acc : 1.0000 |test_loss : 0.0596 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0137 |train_acc : 1.0000 |test_loss : 0.0478 |test_acc : 1.0000 \n",
      "Epoch 38 |train_loss : 0.0170 |train_acc : 1.0000 |test_loss : 0.0360 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0122 |train_acc : 1.0000 |test_loss : 0.0477 |test_acc : 1.0000 \n",
      "Epoch 40 |train_loss : 0.0110 |train_acc : 1.0000 |test_loss : 0.0479 |test_acc : 1.0000 \n",
      "Epoch 41 |train_loss : 0.0155 |train_acc : 1.0000 |test_loss : 0.0401 |test_acc : 1.0000 \n",
      "Epoch 42 |train_loss : 0.0133 |train_acc : 1.0000 |test_loss : 0.0621 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0096 |train_acc : 1.0000 |test_loss : 0.0376 |test_acc : 1.0000 \n",
      "Epoch 44 |train_loss : 0.0099 |train_acc : 1.0000 |test_loss : 0.0296 |test_acc : 1.0000 \n",
      "Epoch 45 |train_loss : 0.0078 |train_acc : 1.0000 |test_loss : 0.0474 |test_acc : 1.0000 \n",
      "Epoch 46 |train_loss : 0.0073 |train_acc : 1.0000 |test_loss : 0.0304 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0059 |train_acc : 1.0000 |test_loss : 0.0381 |test_acc : 1.0000 \n",
      "Epoch 48 |train_loss : 0.0056 |train_acc : 1.0000 |test_loss : 0.0269 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0052 |train_acc : 1.0000 |test_loss : 0.0382 |test_acc : 1.0000 \n",
      "Epoch 50 |train_loss : 0.0051 |train_acc : 1.0000 |test_loss : 0.0325 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 2\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af51881578c4f91b7988a246954943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.6263 |train_acc : 0.6875 |test_loss : 0.6459 |test_acc : 0.6667 \n",
      "Epoch 2 |train_loss : 0.6704 |train_acc : 0.6667 |test_loss : 0.6136 |test_acc : 0.6667 \n",
      "Epoch 3 |train_loss : 0.6124 |train_acc : 0.7292 |test_loss : 0.5401 |test_acc : 0.7917 \n",
      "Epoch 4 |train_loss : 0.7408 |train_acc : 0.6042 |test_loss : 0.5072 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.5865 |train_acc : 0.7292 |test_loss : 0.5320 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.5842 |train_acc : 0.7292 |test_loss : 0.5240 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.5724 |train_acc : 0.7292 |test_loss : 0.5125 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.5687 |train_acc : 0.7292 |test_loss : 0.6204 |test_acc : 0.6667 \n",
      "Epoch 9 |train_loss : 0.6255 |train_acc : 0.6667 |test_loss : 0.5986 |test_acc : 0.6667 \n",
      "Epoch 10 |train_loss : 0.6615 |train_acc : 0.6042 |test_loss : 0.5473 |test_acc : 0.7917 \n",
      "Epoch 11 |train_loss : 0.5943 |train_acc : 0.6667 |test_loss : 0.5975 |test_acc : 0.6667 \n",
      "Epoch 12 |train_loss : 0.5961 |train_acc : 0.6667 |test_loss : 0.5282 |test_acc : 0.7917 \n",
      "Epoch 13 |train_loss : 0.5765 |train_acc : 0.6667 |test_loss : 0.5994 |test_acc : 0.6667 \n",
      "Epoch 14 |train_loss : 0.5621 |train_acc : 0.6667 |test_loss : 0.5205 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6139 |train_acc : 0.6042 |test_loss : 0.5049 |test_acc : 0.7917 \n",
      "Epoch 16 |train_loss : 0.5582 |train_acc : 0.6667 |test_loss : 0.5224 |test_acc : 0.7917 \n",
      "Epoch 17 |train_loss : 0.5269 |train_acc : 0.6667 |test_loss : 0.5154 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.4808 |train_acc : 0.7917 |test_loss : 0.4990 |test_acc : 0.7917 \n",
      "Epoch 19 |train_loss : 0.4873 |train_acc : 0.7292 |test_loss : 0.5026 |test_acc : 0.7917 \n",
      "Epoch 20 |train_loss : 0.4886 |train_acc : 0.7292 |test_loss : 0.5536 |test_acc : 0.6667 \n",
      "Epoch 21 |train_loss : 0.4812 |train_acc : 0.7292 |test_loss : 0.4599 |test_acc : 0.7917 \n",
      "Epoch 22 |train_loss : 0.4839 |train_acc : 0.7500 |test_loss : 0.5685 |test_acc : 0.8333 \n",
      "Epoch 23 |train_loss : 0.4140 |train_acc : 0.7500 |test_loss : 0.6667 |test_acc : 0.6667 \n",
      "Epoch 24 |train_loss : 0.4240 |train_acc : 0.7708 |test_loss : 0.6412 |test_acc : 0.7083 \n",
      "Epoch 25 |train_loss : 0.4276 |train_acc : 0.7708 |test_loss : 0.6936 |test_acc : 0.7500 \n",
      "Epoch 26 |train_loss : 0.3825 |train_acc : 0.8958 |test_loss : 0.5217 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.4419 |train_acc : 0.7708 |test_loss : 0.7166 |test_acc : 0.6667 \n",
      "Epoch 28 |train_loss : 0.3671 |train_acc : 0.8750 |test_loss : 0.6606 |test_acc : 0.7083 \n",
      "Epoch 29 |train_loss : 0.4030 |train_acc : 0.8125 |test_loss : 0.7213 |test_acc : 0.7083 \n",
      "Epoch 30 |train_loss : 0.3731 |train_acc : 0.9167 |test_loss : 0.6101 |test_acc : 0.5417 \n",
      "Epoch 31 |train_loss : 0.3312 |train_acc : 0.9583 |test_loss : 0.6454 |test_acc : 0.7083 \n",
      "Epoch 32 |train_loss : 0.3238 |train_acc : 0.9583 |test_loss : 0.5702 |test_acc : 0.6250 \n",
      "Epoch 33 |train_loss : 0.2486 |train_acc : 0.9375 |test_loss : 0.4703 |test_acc : 0.7917 \n",
      "Epoch 34 |train_loss : 0.2799 |train_acc : 0.9167 |test_loss : 0.7926 |test_acc : 0.4583 \n",
      "Epoch 35 |train_loss : 0.5960 |train_acc : 0.6875 |test_loss : 0.6289 |test_acc : 0.6667 \n",
      "Epoch 36 |train_loss : 0.5924 |train_acc : 0.6875 |test_loss : 0.8265 |test_acc : 0.5000 \n",
      "Epoch 37 |train_loss : 0.4131 |train_acc : 0.8542 |test_loss : 0.5009 |test_acc : 0.8333 \n",
      "Epoch 38 |train_loss : 0.4784 |train_acc : 0.7292 |test_loss : 0.6159 |test_acc : 0.5417 \n",
      "Epoch 39 |train_loss : 0.4722 |train_acc : 0.7292 |test_loss : 0.4561 |test_acc : 0.7917 \n",
      "Epoch 40 |train_loss : 0.5155 |train_acc : 0.6667 |test_loss : 0.5468 |test_acc : 0.7083 \n",
      "Epoch 41 |train_loss : 0.4622 |train_acc : 0.7500 |test_loss : 0.5030 |test_acc : 0.8750 \n",
      "Epoch 42 |train_loss : 0.4745 |train_acc : 0.8542 |test_loss : 0.5901 |test_acc : 0.6667 \n",
      "Epoch 43 |train_loss : 0.4684 |train_acc : 0.8542 |test_loss : 0.5194 |test_acc : 0.8333 \n",
      "Epoch 44 |train_loss : 0.5306 |train_acc : 0.6667 |test_loss : 0.4479 |test_acc : 0.7917 \n",
      "Epoch 45 |train_loss : 0.4674 |train_acc : 0.7292 |test_loss : 0.4983 |test_acc : 0.8333 \n",
      "Epoch 46 |train_loss : 0.3648 |train_acc : 0.8542 |test_loss : 0.4756 |test_acc : 0.8333 \n",
      "Epoch 47 |train_loss : 0.3873 |train_acc : 0.8125 |test_loss : 0.6223 |test_acc : 0.6667 \n",
      "Epoch 48 |train_loss : 0.4412 |train_acc : 0.7917 |test_loss : 0.5461 |test_acc : 0.7500 \n",
      "Epoch 49 |train_loss : 0.4033 |train_acc : 0.9375 |test_loss : 0.5705 |test_acc : 0.7083 \n",
      "Epoch 50 |train_loss : 0.4952 |train_acc : 0.8333 |test_loss : 0.5553 |test_acc : 0.7500 \n",
      "Epoch 51 |train_loss : 0.3417 |train_acc : 0.9375 |test_loss : 0.5495 |test_acc : 0.6667 \n",
      "Epoch 52 |train_loss : 0.3388 |train_acc : 0.9375 |test_loss : 0.5513 |test_acc : 0.7500 \n",
      "Epoch 53 |train_loss : 0.3254 |train_acc : 0.9583 |test_loss : 0.5197 |test_acc : 0.7917 \n",
      "Epoch 54 |train_loss : 0.2801 |train_acc : 0.9375 |test_loss : 0.5612 |test_acc : 0.6667 \n",
      "Epoch 55 |train_loss : 0.2678 |train_acc : 0.9583 |test_loss : 1.0235 |test_acc : 0.5000 \n",
      "Epoch 56 |train_loss : 0.2539 |train_acc : 0.9583 |test_loss : 0.7793 |test_acc : 0.6667 \n",
      "Epoch 57 |train_loss : 0.2479 |train_acc : 0.9375 |test_loss : 0.5837 |test_acc : 0.7083 \n",
      "Epoch 58 |train_loss : 0.2313 |train_acc : 0.9375 |test_loss : 0.5425 |test_acc : 0.7500 \n",
      "Epoch 59 |train_loss : 0.2233 |train_acc : 0.9583 |test_loss : 0.5129 |test_acc : 0.7500 \n",
      "Epoch 60 |train_loss : 0.2354 |train_acc : 0.9583 |test_loss : 0.5127 |test_acc : 0.7500 \n",
      "Epoch 61 |train_loss : 0.2889 |train_acc : 0.8958 |test_loss : 0.5892 |test_acc : 0.7083 \n",
      "Epoch 62 |train_loss : 0.2638 |train_acc : 1.0000 |test_loss : 0.4614 |test_acc : 0.8333 \n",
      "Epoch 63 |train_loss : 0.3517 |train_acc : 0.8750 |test_loss : 0.4303 |test_acc : 0.8333 \n",
      "Epoch 64 |train_loss : 0.2372 |train_acc : 0.9583 |test_loss : 0.5898 |test_acc : 0.6250 \n",
      "Epoch 65 |train_loss : 0.1886 |train_acc : 0.9583 |test_loss : 0.4631 |test_acc : 0.7917 \n",
      "Epoch 66 |train_loss : 0.2004 |train_acc : 0.9583 |test_loss : 0.5240 |test_acc : 0.7500 \n",
      "Epoch 67 |train_loss : 0.3054 |train_acc : 0.8542 |test_loss : 0.5514 |test_acc : 0.7500 \n",
      "Epoch 68 |train_loss : 0.2407 |train_acc : 0.9792 |test_loss : 0.5036 |test_acc : 0.7917 \n",
      "Epoch 69 |train_loss : 0.2108 |train_acc : 0.9792 |test_loss : 0.5038 |test_acc : 0.8750 \n",
      "Epoch 70 |train_loss : 0.3277 |train_acc : 0.8958 |test_loss : 0.4590 |test_acc : 0.7917 \n",
      "Epoch 71 |train_loss : 0.2230 |train_acc : 0.9792 |test_loss : 0.4104 |test_acc : 0.9167 \n",
      "Epoch 72 |train_loss : 0.1932 |train_acc : 0.9792 |test_loss : 0.5010 |test_acc : 0.7500 \n",
      "Epoch 73 |train_loss : 0.2412 |train_acc : 0.8958 |test_loss : 0.5520 |test_acc : 0.7500 \n",
      "Epoch 74 |train_loss : 0.1492 |train_acc : 0.9792 |test_loss : 0.5272 |test_acc : 0.7917 \n",
      "Epoch 75 |train_loss : 0.1480 |train_acc : 1.0000 |test_loss : 0.5910 |test_acc : 0.6250 \n",
      "Epoch 76 |train_loss : 0.1212 |train_acc : 0.9583 |test_loss : 0.4246 |test_acc : 0.7917 \n",
      "Epoch 77 |train_loss : 0.1262 |train_acc : 0.9792 |test_loss : 0.4786 |test_acc : 0.8333 \n",
      "Epoch 78 |train_loss : 0.1377 |train_acc : 0.9792 |test_loss : 0.5355 |test_acc : 0.6667 \n",
      "Epoch 79 |train_loss : 0.1042 |train_acc : 0.9792 |test_loss : 0.5601 |test_acc : 0.6667 \n",
      "Epoch 80 |train_loss : 0.0792 |train_acc : 1.0000 |test_loss : 0.8665 |test_acc : 0.6667 \n",
      "Epoch 81 |train_loss : 0.1354 |train_acc : 0.9167 |test_loss : 1.0340 |test_acc : 0.5833 \n",
      "Epoch 82 |train_loss : 0.1127 |train_acc : 1.0000 |test_loss : 0.3497 |test_acc : 0.8333 \n",
      "Epoch 83 |train_loss : 0.0865 |train_acc : 1.0000 |test_loss : 0.7904 |test_acc : 0.6667 \n",
      "Epoch 84 |train_loss : 0.1044 |train_acc : 1.0000 |test_loss : 0.4660 |test_acc : 0.7917 \n",
      "Epoch 85 |train_loss : 0.1043 |train_acc : 0.9583 |test_loss : 0.3884 |test_acc : 0.8750 \n",
      "Epoch 86 |train_loss : 0.1146 |train_acc : 0.9583 |test_loss : 0.3630 |test_acc : 0.8333 \n",
      "Epoch 87 |train_loss : 0.0781 |train_acc : 1.0000 |test_loss : 0.4901 |test_acc : 0.8333 \n",
      "Epoch 88 |train_loss : 0.0925 |train_acc : 0.9792 |test_loss : 0.4561 |test_acc : 0.8333 \n",
      "Epoch 89 |train_loss : 0.0750 |train_acc : 1.0000 |test_loss : 0.8497 |test_acc : 0.7083 \n",
      "Epoch 90 |train_loss : 0.0821 |train_acc : 0.9792 |test_loss : 0.4894 |test_acc : 0.7917 \n",
      "Epoch 91 |train_loss : 0.0582 |train_acc : 1.0000 |test_loss : 0.9706 |test_acc : 0.5833 \n",
      "Epoch 92 |train_loss : 0.0393 |train_acc : 1.0000 |test_loss : 0.5136 |test_acc : 0.7917 \n",
      "Epoch 93 |train_loss : 0.0416 |train_acc : 1.0000 |test_loss : 0.3778 |test_acc : 0.8750 \n",
      "Epoch 94 |train_loss : 0.0334 |train_acc : 1.0000 |test_loss : 0.4411 |test_acc : 0.8333 \n",
      "Epoch 95 |train_loss : 0.0268 |train_acc : 1.0000 |test_loss : 0.3905 |test_acc : 0.8333 \n",
      "Epoch 96 |train_loss : 0.0223 |train_acc : 1.0000 |test_loss : 0.3914 |test_acc : 0.8333 \n",
      "Epoch 97 |train_loss : 0.0310 |train_acc : 1.0000 |test_loss : 0.5350 |test_acc : 0.7083 \n",
      "Epoch 98 |train_loss : 0.0258 |train_acc : 1.0000 |test_loss : 0.4077 |test_acc : 0.8333 \n",
      "Epoch 99 |train_loss : 0.0205 |train_acc : 1.0000 |test_loss : 0.9000 |test_acc : 0.7083 \n",
      "Epoch 100 |train_loss : 0.0181 |train_acc : 1.0000 |test_loss : 0.7698 |test_acc : 0.5833 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 3\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-22/Adam/custom_resnet152/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712c62a71a3f4d07b66c631e018b3342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.6869 |train_acc : 0.5417 |test_loss : 0.5299 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.5780 |train_acc : 0.7292 |test_loss : 0.6687 |test_acc : 0.6667 \n",
      "Epoch 3 |train_loss : 0.5579 |train_acc : 0.7292 |test_loss : 0.6995 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.6088 |train_acc : 0.7292 |test_loss : 0.5234 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.7368 |train_acc : 0.6042 |test_loss : 0.5268 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.6036 |train_acc : 0.7292 |test_loss : 0.5817 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.6450 |train_acc : 0.6667 |test_loss : 0.6423 |test_acc : 0.6667 \n",
      "Epoch 8 |train_loss : 0.6009 |train_acc : 0.7292 |test_loss : 0.5538 |test_acc : 0.7917 \n",
      "Epoch 9 |train_loss : 0.5818 |train_acc : 0.7292 |test_loss : 0.5300 |test_acc : 0.7917 \n",
      "Epoch 10 |train_loss : 0.6580 |train_acc : 0.6667 |test_loss : 0.6558 |test_acc : 0.6667 \n",
      "Epoch 11 |train_loss : 0.7098 |train_acc : 0.6042 |test_loss : 0.6417 |test_acc : 0.6667 \n",
      "Epoch 12 |train_loss : 0.6145 |train_acc : 0.7292 |test_loss : 0.6423 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.6420 |train_acc : 0.6667 |test_loss : 0.5640 |test_acc : 0.7917 \n",
      "Epoch 14 |train_loss : 0.6441 |train_acc : 0.6667 |test_loss : 0.5427 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6376 |train_acc : 0.6667 |test_loss : 0.6371 |test_acc : 0.6667 \n",
      "Epoch 16 |train_loss : 0.5952 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 17 |train_loss : 0.5916 |train_acc : 0.7292 |test_loss : 0.6400 |test_acc : 0.6667 \n",
      "Epoch 18 |train_loss : 0.7279 |train_acc : 0.6042 |test_loss : 0.6502 |test_acc : 0.6667 \n",
      "Epoch 19 |train_loss : 0.6366 |train_acc : 0.6667 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 20 |train_loss : 0.6077 |train_acc : 0.7292 |test_loss : 0.6399 |test_acc : 0.6667 \n",
      "Epoch 21 |train_loss : 0.6390 |train_acc : 0.6667 |test_loss : 0.5530 |test_acc : 0.7917 \n",
      "Epoch 22 |train_loss : 0.6390 |train_acc : 0.6667 |test_loss : 0.6381 |test_acc : 0.6667 \n",
      "Epoch 23 |train_loss : 0.5943 |train_acc : 0.7292 |test_loss : 0.5386 |test_acc : 0.7917 \n",
      "Epoch 24 |train_loss : 0.6416 |train_acc : 0.6667 |test_loss : 0.5251 |test_acc : 0.7917 \n",
      "Epoch 25 |train_loss : 0.7057 |train_acc : 0.6042 |test_loss : 0.6428 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.6312 |train_acc : 0.6667 |test_loss : 0.5688 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.6116 |train_acc : 0.7292 |test_loss : 0.5875 |test_acc : 0.7917 \n",
      "Epoch 28 |train_loss : 0.5836 |train_acc : 0.7292 |test_loss : 0.5247 |test_acc : 0.7917 \n",
      "Epoch 29 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5231 |test_acc : 0.7917 \n",
      "Epoch 30 |train_loss : 0.5891 |train_acc : 0.7292 |test_loss : 0.5215 |test_acc : 0.7917 \n",
      "Epoch 31 |train_loss : 0.5901 |train_acc : 0.7292 |test_loss : 0.5182 |test_acc : 0.7917 \n",
      "Epoch 32 |train_loss : 0.5878 |train_acc : 0.7292 |test_loss : 0.6526 |test_acc : 0.6667 \n",
      "Epoch 33 |train_loss : 0.7114 |train_acc : 0.6042 |test_loss : 0.5287 |test_acc : 0.7917 \n",
      "Epoch 34 |train_loss : 0.6058 |train_acc : 0.7292 |test_loss : 0.5694 |test_acc : 0.7917 \n",
      "Epoch 35 |train_loss : 0.6041 |train_acc : 0.7292 |test_loss : 0.5572 |test_acc : 0.7917 \n",
      "Epoch 36 |train_loss : 0.5888 |train_acc : 0.7292 |test_loss : 0.6462 |test_acc : 0.6667 \n",
      "Epoch 37 |train_loss : 0.6569 |train_acc : 0.6667 |test_loss : 0.5154 |test_acc : 0.7917 \n",
      "Epoch 38 |train_loss : 0.5882 |train_acc : 0.7292 |test_loss : 0.6440 |test_acc : 0.6667 \n",
      "Epoch 39 |train_loss : 0.5934 |train_acc : 0.7292 |test_loss : 0.5362 |test_acc : 0.7917 \n",
      "Epoch 40 |train_loss : 0.5874 |train_acc : 0.7292 |test_loss : 0.7468 |test_acc : 0.5417 \n",
      "Epoch 41 |train_loss : 0.6525 |train_acc : 0.6667 |test_loss : 0.5202 |test_acc : 0.7917 \n",
      "Epoch 42 |train_loss : 0.5918 |train_acc : 0.7292 |test_loss : 0.5339 |test_acc : 0.7917 \n",
      "Epoch 43 |train_loss : 0.5883 |train_acc : 0.7292 |test_loss : 0.5302 |test_acc : 0.7917 \n",
      "Epoch 44 |train_loss : 0.6541 |train_acc : 0.6667 |test_loss : 0.5214 |test_acc : 0.7917 \n",
      "Epoch 45 |train_loss : 0.6403 |train_acc : 0.6667 |test_loss : 0.5368 |test_acc : 0.7917 \n",
      "Epoch 46 |train_loss : 0.6346 |train_acc : 0.6667 |test_loss : 0.6372 |test_acc : 0.6667 \n",
      "Epoch 47 |train_loss : 0.6402 |train_acc : 0.6667 |test_loss : 0.5691 |test_acc : 0.7917 \n",
      "Epoch 48 |train_loss : 0.6394 |train_acc : 0.6667 |test_loss : 0.5580 |test_acc : 0.7917 \n",
      "Epoch 49 |train_loss : 0.6386 |train_acc : 0.6667 |test_loss : 0.5480 |test_acc : 0.7917 \n",
      "Epoch 50 |train_loss : 0.6392 |train_acc : 0.6667 |test_loss : 0.6370 |test_acc : 0.6667 \n",
      "Epoch 51 |train_loss : 0.6386 |train_acc : 0.6667 |test_loss : 0.5410 |test_acc : 0.7917 \n",
      "Epoch 52 |train_loss : 0.6389 |train_acc : 0.6667 |test_loss : 0.5476 |test_acc : 0.7917 \n",
      "Epoch 53 |train_loss : 0.5968 |train_acc : 0.7292 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "Epoch 54 |train_loss : 0.7078 |train_acc : 0.6042 |test_loss : 0.5293 |test_acc : 0.7917 \n",
      "Epoch 55 |train_loss : 0.6382 |train_acc : 0.6667 |test_loss : 0.6370 |test_acc : 0.6667 \n",
      "Epoch 56 |train_loss : 0.6043 |train_acc : 0.7292 |test_loss : 0.6380 |test_acc : 0.6667 \n",
      "Epoch 57 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5333 |test_acc : 0.7917 \n",
      "Epoch 58 |train_loss : 0.6464 |train_acc : 0.6667 |test_loss : 0.5184 |test_acc : 0.7917 \n",
      "Epoch 59 |train_loss : 0.6506 |train_acc : 0.6667 |test_loss : 0.6436 |test_acc : 0.6667 \n",
      "Epoch 60 |train_loss : 0.6027 |train_acc : 0.7292 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "Epoch 61 |train_loss : 0.5955 |train_acc : 0.7292 |test_loss : 0.5308 |test_acc : 0.7917 \n",
      "Epoch 62 |train_loss : 0.5846 |train_acc : 0.7292 |test_loss : 0.5239 |test_acc : 0.7917 \n",
      "Epoch 63 |train_loss : 0.6540 |train_acc : 0.6667 |test_loss : 0.6491 |test_acc : 0.6667 \n",
      "Epoch 64 |train_loss : 0.6966 |train_acc : 0.6042 |test_loss : 0.6375 |test_acc : 0.6667 \n",
      "Epoch 65 |train_loss : 0.6616 |train_acc : 0.6042 |test_loss : 0.6044 |test_acc : 0.7917 \n",
      "Epoch 66 |train_loss : 0.6408 |train_acc : 0.7292 |test_loss : 0.6265 |test_acc : 0.7917 \n",
      "Epoch 67 |train_loss : 0.6128 |train_acc : 0.7292 |test_loss : 0.5555 |test_acc : 0.7917 \n",
      "Epoch 68 |train_loss : 0.6421 |train_acc : 0.6667 |test_loss : 0.5167 |test_acc : 0.7917 \n",
      "Epoch 69 |train_loss : 0.5861 |train_acc : 0.7292 |test_loss : 0.5166 |test_acc : 0.7917 \n",
      "Epoch 70 |train_loss : 0.5877 |train_acc : 0.7292 |test_loss : 0.6512 |test_acc : 0.6667 \n",
      "Epoch 71 |train_loss : 0.6511 |train_acc : 0.6667 |test_loss : 0.6427 |test_acc : 0.6667 \n",
      "Epoch 72 |train_loss : 0.6406 |train_acc : 0.6667 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 73 |train_loss : 0.6391 |train_acc : 0.6667 |test_loss : 0.7160 |test_acc : 0.5417 \n",
      "Epoch 74 |train_loss : 0.6497 |train_acc : 0.6667 |test_loss : 0.6379 |test_acc : 0.6667 \n",
      "Epoch 75 |train_loss : 0.5970 |train_acc : 0.7292 |test_loss : 0.5467 |test_acc : 0.7917 \n",
      "Epoch 76 |train_loss : 0.7121 |train_acc : 0.6042 |test_loss : 0.6447 |test_acc : 0.6667 \n",
      "Epoch 77 |train_loss : 0.5890 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 78 |train_loss : 0.6377 |train_acc : 0.6667 |test_loss : 0.6371 |test_acc : 0.6667 \n",
      "Epoch 79 |train_loss : 0.6372 |train_acc : 0.6667 |test_loss : 0.5448 |test_acc : 0.7917 \n",
      "Epoch 80 |train_loss : 0.5965 |train_acc : 0.7292 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "Epoch 81 |train_loss : 0.6380 |train_acc : 0.6667 |test_loss : 0.5362 |test_acc : 0.7917 \n",
      "Epoch 82 |train_loss : 0.6412 |train_acc : 0.6667 |test_loss : 0.5345 |test_acc : 0.7917 \n",
      "Epoch 83 |train_loss : 0.6379 |train_acc : 0.6667 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 84 |train_loss : 0.6418 |train_acc : 0.6667 |test_loss : 0.5434 |test_acc : 0.7917 \n",
      "Epoch 85 |train_loss : 0.6150 |train_acc : 0.7292 |test_loss : 0.5658 |test_acc : 0.7917 \n",
      "Epoch 86 |train_loss : 0.6861 |train_acc : 0.6042 |test_loss : 0.5439 |test_acc : 0.7917 \n",
      "Epoch 87 |train_loss : 0.6417 |train_acc : 0.6667 |test_loss : 0.5554 |test_acc : 0.7917 \n",
      "Epoch 88 |train_loss : 0.5939 |train_acc : 0.7292 |test_loss : 0.5405 |test_acc : 0.7917 \n",
      "Epoch 89 |train_loss : 0.5861 |train_acc : 0.7292 |test_loss : 0.6439 |test_acc : 0.6667 \n",
      "Epoch 90 |train_loss : 0.6463 |train_acc : 0.6667 |test_loss : 0.5237 |test_acc : 0.7917 \n",
      "Epoch 91 |train_loss : 0.6447 |train_acc : 0.6667 |test_loss : 0.6410 |test_acc : 0.6667 \n",
      "Epoch 92 |train_loss : 0.5989 |train_acc : 0.7292 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "Epoch 93 |train_loss : 0.6432 |train_acc : 0.6667 |test_loss : 0.6381 |test_acc : 0.6667 \n",
      "Epoch 94 |train_loss : 0.6404 |train_acc : 0.6667 |test_loss : 0.5372 |test_acc : 0.7917 \n",
      "Epoch 95 |train_loss : 0.6017 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 96 |train_loss : 0.5908 |train_acc : 0.7292 |test_loss : 0.5375 |test_acc : 0.7917 \n",
      "Epoch 97 |train_loss : 0.5790 |train_acc : 0.7292 |test_loss : 0.6503 |test_acc : 0.6667 \n",
      "Epoch 98 |train_loss : 0.5903 |train_acc : 0.7292 |test_loss : 0.6640 |test_acc : 0.6667 \n",
      "Epoch 99 |train_loss : 0.6655 |train_acc : 0.6667 |test_loss : 0.6554 |test_acc : 0.6667 \n",
      "Epoch 100 |train_loss : 0.6433 |train_acc : 0.6667 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 101 |train_loss : 0.6000 |train_acc : 0.7292 |test_loss : 0.5681 |test_acc : 0.7917 \n",
      "Epoch 102 |train_loss : 0.6441 |train_acc : 0.6667 |test_loss : 0.5425 |test_acc : 0.7917 \n",
      "Epoch 103 |train_loss : 0.5915 |train_acc : 0.7292 |test_loss : 0.6374 |test_acc : 0.6667 \n",
      "Epoch 104 |train_loss : 0.5888 |train_acc : 0.7292 |test_loss : 0.5220 |test_acc : 0.7917 \n",
      "Epoch 105 |train_loss : 0.6494 |train_acc : 0.6667 |test_loss : 0.6475 |test_acc : 0.6667 \n",
      "Epoch 106 |train_loss : 0.6995 |train_acc : 0.6042 |test_loss : 0.6381 |test_acc : 0.6667 \n",
      "Epoch 107 |train_loss : 0.6261 |train_acc : 0.6667 |test_loss : 0.5855 |test_acc : 0.7917 \n",
      "Epoch 108 |train_loss : 0.6293 |train_acc : 0.7292 |test_loss : 0.5960 |test_acc : 0.7917 \n",
      "Epoch 109 |train_loss : 0.5997 |train_acc : 0.7292 |test_loss : 0.5353 |test_acc : 0.7917 \n",
      "Epoch 110 |train_loss : 0.5765 |train_acc : 0.7292 |test_loss : 0.5182 |test_acc : 0.7917 \n",
      "Epoch 111 |train_loss : 0.6684 |train_acc : 0.6667 |test_loss : 0.5128 |test_acc : 0.7917 \n",
      "Epoch 112 |train_loss : 0.6548 |train_acc : 0.6667 |test_loss : 0.6456 |test_acc : 0.6667 \n",
      "Epoch 113 |train_loss : 0.6020 |train_acc : 0.7292 |test_loss : 0.5615 |test_acc : 0.7917 \n",
      "Epoch 114 |train_loss : 0.7047 |train_acc : 0.6042 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 115 |train_loss : 0.6080 |train_acc : 0.7292 |test_loss : 0.7046 |test_acc : 0.5417 \n",
      "Epoch 116 |train_loss : 0.6443 |train_acc : 0.6667 |test_loss : 0.5475 |test_acc : 0.7917 \n",
      "Epoch 117 |train_loss : 0.6386 |train_acc : 0.6667 |test_loss : 0.5372 |test_acc : 0.7917 \n",
      "Epoch 118 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.7385 |test_acc : 0.5417 \n",
      "Epoch 119 |train_loss : 0.6567 |train_acc : 0.6667 |test_loss : 0.5224 |test_acc : 0.7917 \n",
      "Epoch 120 |train_loss : 0.5917 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 121 |train_loss : 0.5936 |train_acc : 0.7292 |test_loss : 0.6374 |test_acc : 0.6667 \n",
      "Epoch 122 |train_loss : 0.6405 |train_acc : 0.6667 |test_loss : 0.5281 |test_acc : 0.7917 \n",
      "Epoch 123 |train_loss : 0.6420 |train_acc : 0.6667 |test_loss : 0.6379 |test_acc : 0.6667 \n",
      "Epoch 124 |train_loss : 0.5888 |train_acc : 0.7292 |test_loss : 0.5368 |test_acc : 0.7917 \n",
      "Epoch 125 |train_loss : 0.6442 |train_acc : 0.6667 |test_loss : 0.6407 |test_acc : 0.6667 \n",
      "Epoch 126 |train_loss : 0.5878 |train_acc : 0.7292 |test_loss : 0.5346 |test_acc : 0.7917 \n",
      "Epoch 127 |train_loss : 0.7174 |train_acc : 0.6042 |test_loss : 0.6404 |test_acc : 0.6667 \n",
      "Epoch 128 |train_loss : 0.6196 |train_acc : 0.7292 |test_loss : 0.5852 |test_acc : 0.7917 \n",
      "Epoch 129 |train_loss : 0.6057 |train_acc : 0.7292 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 130 |train_loss : 0.6454 |train_acc : 0.6667 |test_loss : 0.5223 |test_acc : 0.7917 \n",
      "Epoch 131 |train_loss : 0.5866 |train_acc : 0.7292 |test_loss : 0.6463 |test_acc : 0.6667 \n",
      "Epoch 132 |train_loss : 0.6554 |train_acc : 0.6667 |test_loss : 0.5205 |test_acc : 0.7917 \n",
      "Epoch 133 |train_loss : 0.5882 |train_acc : 0.7292 |test_loss : 0.6376 |test_acc : 0.6667 \n",
      "Epoch 134 |train_loss : 0.6381 |train_acc : 0.6667 |test_loss : 0.5496 |test_acc : 0.7917 \n",
      "Epoch 135 |train_loss : 0.5947 |train_acc : 0.7292 |test_loss : 0.5483 |test_acc : 0.7917 \n",
      "Epoch 136 |train_loss : 0.5877 |train_acc : 0.7292 |test_loss : 0.5322 |test_acc : 0.7917 \n",
      "Epoch 137 |train_loss : 0.5815 |train_acc : 0.7292 |test_loss : 0.6518 |test_acc : 0.6667 \n",
      "Epoch 138 |train_loss : 0.5870 |train_acc : 0.7292 |test_loss : 0.5172 |test_acc : 0.7917 \n",
      "Epoch 139 |train_loss : 0.6564 |train_acc : 0.6667 |test_loss : 0.6521 |test_acc : 0.6667 \n",
      "Epoch 140 |train_loss : 0.6527 |train_acc : 0.6667 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 141 |train_loss : 0.5992 |train_acc : 0.7292 |test_loss : 0.7154 |test_acc : 0.5417 \n",
      "Epoch 142 |train_loss : 0.6483 |train_acc : 0.6667 |test_loss : 0.5320 |test_acc : 0.7917 \n",
      "Epoch 143 |train_loss : 0.5926 |train_acc : 0.7292 |test_loss : 0.5387 |test_acc : 0.7917 \n",
      "Epoch 144 |train_loss : 0.5858 |train_acc : 0.7292 |test_loss : 0.5258 |test_acc : 0.7917 \n",
      "Epoch 145 |train_loss : 0.5834 |train_acc : 0.7292 |test_loss : 0.5197 |test_acc : 0.7917 \n",
      "Epoch 146 |train_loss : 0.6525 |train_acc : 0.6667 |test_loss : 0.5197 |test_acc : 0.7917 \n",
      "Epoch 147 |train_loss : 0.5941 |train_acc : 0.7292 |test_loss : 0.6376 |test_acc : 0.6667 \n",
      "Epoch 148 |train_loss : 0.5901 |train_acc : 0.7292 |test_loss : 0.5381 |test_acc : 0.7917 \n",
      "Epoch 149 |train_loss : 0.5850 |train_acc : 0.7292 |test_loss : 0.7582 |test_acc : 0.5417 \n",
      "Epoch 150 |train_loss : 0.5883 |train_acc : 0.7292 |test_loss : 0.5158 |test_acc : 0.7917 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 4\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_resnet101/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812a492206f74b9692fa95226a00e424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.6524 |train_acc : 0.6458 |test_loss : 0.6425 |test_acc : 0.6667 \n",
      "Epoch 2 |train_loss : 0.5952 |train_acc : 0.7292 |test_loss : 0.6403 |test_acc : 0.6667 \n",
      "Epoch 3 |train_loss : 0.6431 |train_acc : 0.6667 |test_loss : 0.5143 |test_acc : 0.7917 \n",
      "Epoch 4 |train_loss : 0.6264 |train_acc : 0.6667 |test_loss : 0.6216 |test_acc : 0.6667 \n",
      "Epoch 5 |train_loss : 0.5692 |train_acc : 0.7292 |test_loss : 0.7035 |test_acc : 0.5417 \n",
      "Epoch 6 |train_loss : 0.6828 |train_acc : 0.6042 |test_loss : 0.5012 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.5581 |train_acc : 0.7292 |test_loss : 0.5037 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.5710 |train_acc : 0.6667 |test_loss : 0.4890 |test_acc : 0.7917 \n",
      "Epoch 9 |train_loss : 0.5163 |train_acc : 0.7292 |test_loss : 0.5802 |test_acc : 0.6667 \n",
      "Epoch 10 |train_loss : 0.4995 |train_acc : 0.7292 |test_loss : 0.4447 |test_acc : 0.7917 \n",
      "Epoch 11 |train_loss : 0.5350 |train_acc : 0.6667 |test_loss : 0.4305 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.4963 |train_acc : 0.7500 |test_loss : 0.4760 |test_acc : 0.9167 \n",
      "Epoch 13 |train_loss : 0.4174 |train_acc : 0.8542 |test_loss : 0.4075 |test_acc : 0.8750 \n",
      "Epoch 14 |train_loss : 0.4026 |train_acc : 0.7917 |test_loss : 0.3885 |test_acc : 0.8750 \n",
      "Epoch 15 |train_loss : 0.3575 |train_acc : 0.8125 |test_loss : 0.3166 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.3523 |train_acc : 0.8958 |test_loss : 0.3394 |test_acc : 0.9167 \n",
      "Epoch 17 |train_loss : 0.3134 |train_acc : 0.9375 |test_loss : 0.4812 |test_acc : 0.7917 \n",
      "Epoch 18 |train_loss : 0.2755 |train_acc : 0.9375 |test_loss : 0.3165 |test_acc : 0.8333 \n",
      "Epoch 19 |train_loss : 0.2352 |train_acc : 0.9375 |test_loss : 0.2208 |test_acc : 1.0000 \n",
      "Epoch 20 |train_loss : 0.1928 |train_acc : 1.0000 |test_loss : 0.4903 |test_acc : 0.7917 \n",
      "Epoch 21 |train_loss : 0.2609 |train_acc : 0.9167 |test_loss : 0.1725 |test_acc : 1.0000 \n",
      "Epoch 22 |train_loss : 0.1861 |train_acc : 0.9583 |test_loss : 0.1851 |test_acc : 0.9583 \n",
      "Epoch 23 |train_loss : 0.1558 |train_acc : 0.9375 |test_loss : 0.2138 |test_acc : 1.0000 \n",
      "Epoch 24 |train_loss : 0.2118 |train_acc : 0.9167 |test_loss : 0.1937 |test_acc : 0.9167 \n",
      "Epoch 25 |train_loss : 0.1481 |train_acc : 1.0000 |test_loss : 0.1249 |test_acc : 1.0000 \n",
      "Epoch 26 |train_loss : 0.1250 |train_acc : 1.0000 |test_loss : 0.1065 |test_acc : 1.0000 \n",
      "Epoch 27 |train_loss : 0.1547 |train_acc : 0.8958 |test_loss : 0.2153 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1564 |train_acc : 0.9583 |test_loss : 0.1274 |test_acc : 0.9583 \n",
      "Epoch 29 |train_loss : 0.1168 |train_acc : 1.0000 |test_loss : 0.1159 |test_acc : 1.0000 \n",
      "Epoch 30 |train_loss : 0.0630 |train_acc : 1.0000 |test_loss : 0.0784 |test_acc : 1.0000 \n",
      "Epoch 31 |train_loss : 0.0400 |train_acc : 1.0000 |test_loss : 0.0575 |test_acc : 1.0000 \n",
      "Epoch 32 |train_loss : 0.0333 |train_acc : 1.0000 |test_loss : 0.0608 |test_acc : 1.0000 \n",
      "Epoch 33 |train_loss : 0.0313 |train_acc : 1.0000 |test_loss : 0.0644 |test_acc : 1.0000 \n",
      "Epoch 34 |train_loss : 0.0252 |train_acc : 1.0000 |test_loss : 0.0523 |test_acc : 1.0000 \n",
      "Epoch 35 |train_loss : 0.0179 |train_acc : 1.0000 |test_loss : 0.0550 |test_acc : 1.0000 \n",
      "Epoch 36 |train_loss : 0.0182 |train_acc : 1.0000 |test_loss : 0.0263 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0138 |train_acc : 1.0000 |test_loss : 0.0333 |test_acc : 1.0000 \n",
      "Epoch 38 |train_loss : 0.0193 |train_acc : 1.0000 |test_loss : 0.0252 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0270 |train_acc : 1.0000 |test_loss : 0.0858 |test_acc : 0.9583 \n",
      "Epoch 40 |train_loss : 0.0291 |train_acc : 1.0000 |test_loss : 0.0179 |test_acc : 1.0000 \n",
      "Epoch 41 |train_loss : 0.0258 |train_acc : 1.0000 |test_loss : 0.0248 |test_acc : 1.0000 \n",
      "Epoch 42 |train_loss : 0.0160 |train_acc : 1.0000 |test_loss : 0.0570 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0153 |train_acc : 1.0000 |test_loss : 0.0226 |test_acc : 1.0000 \n",
      "Epoch 44 |train_loss : 0.0105 |train_acc : 1.0000 |test_loss : 0.0139 |test_acc : 1.0000 \n",
      "Epoch 45 |train_loss : 0.0106 |train_acc : 1.0000 |test_loss : 0.0147 |test_acc : 1.0000 \n",
      "Epoch 46 |train_loss : 0.0093 |train_acc : 1.0000 |test_loss : 0.0121 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0068 |train_acc : 1.0000 |test_loss : 0.0111 |test_acc : 1.0000 \n",
      "Epoch 48 |train_loss : 0.0063 |train_acc : 1.0000 |test_loss : 0.0118 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0050 |train_acc : 1.0000 |test_loss : 0.0122 |test_acc : 1.0000 \n",
      "Epoch 50 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.0099 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 5\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_resnet101/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59e2cba3c43430b883f22eaf28abe8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.6983 |train_acc : 0.5833 |test_loss : 0.5938 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.6040 |train_acc : 0.7292 |test_loss : 0.6395 |test_acc : 0.6667 \n",
      "Epoch 3 |train_loss : 0.7164 |train_acc : 0.6042 |test_loss : 0.5194 |test_acc : 0.7917 \n",
      "Epoch 4 |train_loss : 0.6438 |train_acc : 0.6667 |test_loss : 0.5289 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.5937 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 6 |train_loss : 0.5906 |train_acc : 0.7292 |test_loss : 0.7348 |test_acc : 0.5417 \n",
      "Epoch 7 |train_loss : 0.5882 |train_acc : 0.7292 |test_loss : 0.5357 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.5836 |train_acc : 0.7292 |test_loss : 0.5259 |test_acc : 0.7917 \n",
      "Epoch 9 |train_loss : 0.6461 |train_acc : 0.6667 |test_loss : 0.5217 |test_acc : 0.7917 \n",
      "Epoch 10 |train_loss : 0.5870 |train_acc : 0.7292 |test_loss : 0.7576 |test_acc : 0.5417 \n",
      "Epoch 11 |train_loss : 0.5855 |train_acc : 0.7292 |test_loss : 0.5270 |test_acc : 0.7917 \n",
      "Epoch 12 |train_loss : 0.5855 |train_acc : 0.7292 |test_loss : 0.6443 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.5877 |train_acc : 0.7292 |test_loss : 0.6429 |test_acc : 0.6667 \n",
      "Epoch 14 |train_loss : 0.5857 |train_acc : 0.7292 |test_loss : 0.5250 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6564 |train_acc : 0.6667 |test_loss : 0.6504 |test_acc : 0.6667 \n",
      "Epoch 16 |train_loss : 0.6485 |train_acc : 0.6667 |test_loss : 0.5313 |test_acc : 0.7917 \n",
      "Epoch 17 |train_loss : 0.6362 |train_acc : 0.6667 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 18 |train_loss : 0.5959 |train_acc : 0.7292 |test_loss : 0.5547 |test_acc : 0.7917 \n",
      "Epoch 19 |train_loss : 0.5942 |train_acc : 0.7292 |test_loss : 0.5464 |test_acc : 0.7917 \n",
      "Epoch 20 |train_loss : 0.5877 |train_acc : 0.7292 |test_loss : 0.5278 |test_acc : 0.7917 \n",
      "Epoch 21 |train_loss : 0.5832 |train_acc : 0.7292 |test_loss : 0.6491 |test_acc : 0.6667 \n",
      "Epoch 22 |train_loss : 0.5846 |train_acc : 0.7292 |test_loss : 0.6504 |test_acc : 0.6667 \n",
      "Epoch 23 |train_loss : 0.7263 |train_acc : 0.6042 |test_loss : 0.6512 |test_acc : 0.6667 \n",
      "Epoch 24 |train_loss : 0.6392 |train_acc : 0.6667 |test_loss : 0.5385 |test_acc : 0.7917 \n",
      "Epoch 25 |train_loss : 0.5967 |train_acc : 0.7292 |test_loss : 0.6373 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.5977 |train_acc : 0.7292 |test_loss : 0.5487 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.6387 |train_acc : 0.6667 |test_loss : 0.5361 |test_acc : 0.7917 \n",
      "Epoch 28 |train_loss : 0.5892 |train_acc : 0.7292 |test_loss : 0.5359 |test_acc : 0.7917 \n",
      "Epoch 29 |train_loss : 0.5846 |train_acc : 0.7292 |test_loss : 0.6416 |test_acc : 0.6667 \n",
      "Epoch 30 |train_loss : 0.6462 |train_acc : 0.6667 |test_loss : 0.6456 |test_acc : 0.6667 \n",
      "Epoch 31 |train_loss : 0.5862 |train_acc : 0.7292 |test_loss : 0.5275 |test_acc : 0.7917 \n",
      "Epoch 32 |train_loss : 0.6429 |train_acc : 0.6667 |test_loss : 0.7549 |test_acc : 0.5417 \n",
      "Epoch 33 |train_loss : 0.5911 |train_acc : 0.7292 |test_loss : 0.5388 |test_acc : 0.7917 \n",
      "Epoch 34 |train_loss : 0.5910 |train_acc : 0.7292 |test_loss : 0.5387 |test_acc : 0.7917 \n",
      "Epoch 35 |train_loss : 0.7016 |train_acc : 0.6042 |test_loss : 0.5291 |test_acc : 0.7917 \n",
      "Epoch 36 |train_loss : 0.5880 |train_acc : 0.7292 |test_loss : 0.5392 |test_acc : 0.7917 \n",
      "Epoch 37 |train_loss : 0.5892 |train_acc : 0.7292 |test_loss : 0.5352 |test_acc : 0.7917 \n",
      "Epoch 38 |train_loss : 0.6391 |train_acc : 0.6667 |test_loss : 0.6387 |test_acc : 0.6667 \n",
      "Epoch 39 |train_loss : 0.6395 |train_acc : 0.6667 |test_loss : 0.6382 |test_acc : 0.6667 \n",
      "Epoch 40 |train_loss : 0.6370 |train_acc : 0.6667 |test_loss : 0.5434 |test_acc : 0.7917 \n",
      "Epoch 41 |train_loss : 0.5939 |train_acc : 0.7292 |test_loss : 0.5497 |test_acc : 0.7917 \n",
      "Epoch 42 |train_loss : 0.5905 |train_acc : 0.7292 |test_loss : 0.5385 |test_acc : 0.7917 \n",
      "Epoch 43 |train_loss : 0.7070 |train_acc : 0.6042 |test_loss : 0.6419 |test_acc : 0.6667 \n",
      "Epoch 44 |train_loss : 0.6872 |train_acc : 0.6042 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 45 |train_loss : 0.5965 |train_acc : 0.7292 |test_loss : 0.6380 |test_acc : 0.6667 \n",
      "Epoch 46 |train_loss : 0.6031 |train_acc : 0.7292 |test_loss : 0.6374 |test_acc : 0.6667 \n",
      "Epoch 47 |train_loss : 0.5908 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 48 |train_loss : 0.6490 |train_acc : 0.6667 |test_loss : 0.6449 |test_acc : 0.6667 \n",
      "Epoch 49 |train_loss : 0.6460 |train_acc : 0.6667 |test_loss : 0.5249 |test_acc : 0.7917 \n",
      "Epoch 50 |train_loss : 0.5859 |train_acc : 0.7292 |test_loss : 0.5315 |test_acc : 0.7917 \n",
      "Epoch 51 |train_loss : 0.5974 |train_acc : 0.7292 |test_loss : 0.6373 |test_acc : 0.6667 \n",
      "Epoch 52 |train_loss : 0.6410 |train_acc : 0.6667 |test_loss : 0.5308 |test_acc : 0.7917 \n",
      "Epoch 53 |train_loss : 0.5874 |train_acc : 0.7292 |test_loss : 0.7534 |test_acc : 0.5417 \n",
      "Epoch 54 |train_loss : 0.5870 |train_acc : 0.7292 |test_loss : 0.6407 |test_acc : 0.6667 \n",
      "Epoch 55 |train_loss : 0.7034 |train_acc : 0.6042 |test_loss : 0.6417 |test_acc : 0.6667 \n",
      "Epoch 56 |train_loss : 0.5900 |train_acc : 0.7292 |test_loss : 0.7302 |test_acc : 0.5417 \n",
      "Epoch 57 |train_loss : 0.5926 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 58 |train_loss : 0.5887 |train_acc : 0.7292 |test_loss : 0.6380 |test_acc : 0.6667 \n",
      "Epoch 59 |train_loss : 0.6437 |train_acc : 0.6667 |test_loss : 0.6437 |test_acc : 0.6667 \n",
      "Epoch 60 |train_loss : 0.6433 |train_acc : 0.6667 |test_loss : 0.5287 |test_acc : 0.7917 \n",
      "Epoch 61 |train_loss : 0.5913 |train_acc : 0.7292 |test_loss : 0.6376 |test_acc : 0.6667 \n",
      "Epoch 62 |train_loss : 0.5890 |train_acc : 0.7292 |test_loss : 0.7395 |test_acc : 0.5417 \n",
      "Epoch 63 |train_loss : 0.6465 |train_acc : 0.6667 |test_loss : 0.5254 |test_acc : 0.7917 \n",
      "Epoch 64 |train_loss : 0.7009 |train_acc : 0.6042 |test_loss : 0.5308 |test_acc : 0.7917 \n",
      "Epoch 65 |train_loss : 0.6779 |train_acc : 0.6042 |test_loss : 0.5526 |test_acc : 0.7917 \n",
      "Epoch 66 |train_loss : 0.6144 |train_acc : 0.7292 |test_loss : 0.5928 |test_acc : 0.7917 \n",
      "Epoch 67 |train_loss : 0.6452 |train_acc : 0.6667 |test_loss : 0.5733 |test_acc : 0.7917 \n",
      "Epoch 68 |train_loss : 0.6009 |train_acc : 0.7292 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "Epoch 69 |train_loss : 0.6377 |train_acc : 0.6667 |test_loss : 0.5353 |test_acc : 0.7917 \n",
      "Epoch 70 |train_loss : 0.5859 |train_acc : 0.7292 |test_loss : 0.6401 |test_acc : 0.6667 \n",
      "Epoch 71 |train_loss : 0.6410 |train_acc : 0.6667 |test_loss : 0.5284 |test_acc : 0.7917 \n",
      "Epoch 72 |train_loss : 0.5866 |train_acc : 0.7292 |test_loss : 0.6404 |test_acc : 0.6667 \n",
      "Epoch 73 |train_loss : 0.5851 |train_acc : 0.7292 |test_loss : 0.5259 |test_acc : 0.7917 \n",
      "Epoch 74 |train_loss : 0.7199 |train_acc : 0.6042 |test_loss : 0.6466 |test_acc : 0.6667 \n",
      "Epoch 75 |train_loss : 0.6039 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 76 |train_loss : 0.5929 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 77 |train_loss : 0.6398 |train_acc : 0.6667 |test_loss : 0.5348 |test_acc : 0.7917 \n",
      "Epoch 78 |train_loss : 0.6388 |train_acc : 0.6667 |test_loss : 0.6384 |test_acc : 0.6667 \n",
      "Epoch 79 |train_loss : 0.5886 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 80 |train_loss : 0.6952 |train_acc : 0.6042 |test_loss : 0.6383 |test_acc : 0.6667 \n",
      "Epoch 81 |train_loss : 0.6343 |train_acc : 0.6667 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 82 |train_loss : 0.6751 |train_acc : 0.6042 |test_loss : 0.5667 |test_acc : 0.7917 \n",
      "Epoch 83 |train_loss : 0.6396 |train_acc : 0.6667 |test_loss : 0.6425 |test_acc : 0.6667 \n",
      "Epoch 84 |train_loss : 0.6109 |train_acc : 0.7292 |test_loss : 0.5720 |test_acc : 0.7917 \n",
      "Epoch 85 |train_loss : 0.6493 |train_acc : 0.6667 |test_loss : 0.5396 |test_acc : 0.7917 \n",
      "Epoch 86 |train_loss : 0.5876 |train_acc : 0.7292 |test_loss : 0.6385 |test_acc : 0.6667 \n",
      "Epoch 87 |train_loss : 0.5849 |train_acc : 0.7292 |test_loss : 0.6427 |test_acc : 0.6667 \n",
      "Epoch 88 |train_loss : 0.5836 |train_acc : 0.7292 |test_loss : 0.7737 |test_acc : 0.5417 \n",
      "Epoch 89 |train_loss : 0.5852 |train_acc : 0.7292 |test_loss : 0.6483 |test_acc : 0.6667 \n",
      "Epoch 90 |train_loss : 0.5874 |train_acc : 0.7292 |test_loss : 0.5217 |test_acc : 0.7917 \n",
      "Epoch 91 |train_loss : 0.6476 |train_acc : 0.6667 |test_loss : 0.6465 |test_acc : 0.6667 \n",
      "Epoch 92 |train_loss : 0.5862 |train_acc : 0.7292 |test_loss : 0.6417 |test_acc : 0.6667 \n",
      "Epoch 93 |train_loss : 0.5870 |train_acc : 0.7292 |test_loss : 0.6399 |test_acc : 0.6667 \n",
      "Epoch 94 |train_loss : 0.6992 |train_acc : 0.6042 |test_loss : 0.5309 |test_acc : 0.7917 \n",
      "Epoch 95 |train_loss : 0.5893 |train_acc : 0.7292 |test_loss : 0.7295 |test_acc : 0.5417 \n",
      "Epoch 96 |train_loss : 0.5915 |train_acc : 0.7292 |test_loss : 0.5434 |test_acc : 0.7917 \n",
      "Epoch 97 |train_loss : 0.5897 |train_acc : 0.7292 |test_loss : 0.7390 |test_acc : 0.5417 \n",
      "Epoch 98 |train_loss : 0.5837 |train_acc : 0.7292 |test_loss : 0.6435 |test_acc : 0.6667 \n",
      "Epoch 99 |train_loss : 0.5833 |train_acc : 0.7292 |test_loss : 0.5200 |test_acc : 0.7917 \n",
      "Epoch 100 |train_loss : 0.6525 |train_acc : 0.6667 |test_loss : 0.5179 |test_acc : 0.7917 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 6\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_resnet101/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f232569ec1542528026f6a481620a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.5933 |train_acc : 0.7292 |test_loss : 0.6261 |test_acc : 0.6667 \n",
      "Epoch 2 |train_loss : 0.5523 |train_acc : 0.7292 |test_loss : 0.4916 |test_acc : 0.7917 \n",
      "Epoch 3 |train_loss : 0.5735 |train_acc : 0.7292 |test_loss : 0.6341 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.5642 |train_acc : 0.6667 |test_loss : 0.4717 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.6078 |train_acc : 0.6042 |test_loss : 0.4553 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.5020 |train_acc : 0.7500 |test_loss : 0.4631 |test_acc : 0.8333 \n",
      "Epoch 7 |train_loss : 0.4711 |train_acc : 0.6875 |test_loss : 0.3848 |test_acc : 0.7917 \n",
      "Epoch 8 |train_loss : 0.4665 |train_acc : 0.7708 |test_loss : 0.3403 |test_acc : 0.7917 \n",
      "Epoch 9 |train_loss : 0.4108 |train_acc : 0.8542 |test_loss : 0.3118 |test_acc : 0.8333 \n",
      "Epoch 10 |train_loss : 0.4340 |train_acc : 0.6667 |test_loss : 0.4133 |test_acc : 0.7500 \n",
      "Epoch 11 |train_loss : 0.3443 |train_acc : 0.9375 |test_loss : 0.3277 |test_acc : 0.9167 \n",
      "Epoch 12 |train_loss : 0.2924 |train_acc : 0.8958 |test_loss : 0.3247 |test_acc : 0.9167 \n",
      "Epoch 13 |train_loss : 0.3816 |train_acc : 0.8125 |test_loss : 0.4436 |test_acc : 0.7917 \n",
      "Epoch 14 |train_loss : 0.2623 |train_acc : 1.0000 |test_loss : 0.3384 |test_acc : 0.9583 \n",
      "Epoch 15 |train_loss : 0.2724 |train_acc : 0.9375 |test_loss : 0.3430 |test_acc : 0.9583 \n",
      "Epoch 16 |train_loss : 0.2733 |train_acc : 0.9792 |test_loss : 0.2711 |test_acc : 0.9583 \n",
      "Epoch 17 |train_loss : 0.2543 |train_acc : 0.9583 |test_loss : 0.2224 |test_acc : 0.9167 \n",
      "Epoch 18 |train_loss : 0.2181 |train_acc : 1.0000 |test_loss : 0.2740 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.2156 |train_acc : 0.9167 |test_loss : 0.4233 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.2073 |train_acc : 1.0000 |test_loss : 0.1818 |test_acc : 0.9583 \n",
      "Epoch 21 |train_loss : 0.1563 |train_acc : 0.9583 |test_loss : 0.2327 |test_acc : 0.9583 \n",
      "Epoch 22 |train_loss : 0.1337 |train_acc : 1.0000 |test_loss : 0.2234 |test_acc : 0.9583 \n",
      "Epoch 23 |train_loss : 0.1184 |train_acc : 0.9792 |test_loss : 0.1516 |test_acc : 0.9583 \n",
      "Epoch 24 |train_loss : 0.0862 |train_acc : 1.0000 |test_loss : 0.1404 |test_acc : 0.9583 \n",
      "Epoch 25 |train_loss : 0.0814 |train_acc : 1.0000 |test_loss : 0.1209 |test_acc : 0.9583 \n",
      "Epoch 26 |train_loss : 0.0673 |train_acc : 1.0000 |test_loss : 0.2303 |test_acc : 0.8333 \n",
      "Epoch 27 |train_loss : 0.0607 |train_acc : 1.0000 |test_loss : 0.1324 |test_acc : 0.9583 \n",
      "Epoch 28 |train_loss : 0.0641 |train_acc : 1.0000 |test_loss : 0.1186 |test_acc : 0.9583 \n",
      "Epoch 29 |train_loss : 0.0801 |train_acc : 1.0000 |test_loss : 0.1322 |test_acc : 0.9583 \n",
      "Epoch 30 |train_loss : 0.0544 |train_acc : 1.0000 |test_loss : 0.2862 |test_acc : 0.8333 \n",
      "Epoch 31 |train_loss : 0.0605 |train_acc : 1.0000 |test_loss : 0.1412 |test_acc : 0.9583 \n",
      "Epoch 32 |train_loss : 0.0516 |train_acc : 1.0000 |test_loss : 0.1319 |test_acc : 0.9583 \n",
      "Epoch 33 |train_loss : 0.0310 |train_acc : 1.0000 |test_loss : 0.3389 |test_acc : 0.8333 \n",
      "Epoch 34 |train_loss : 0.0265 |train_acc : 1.0000 |test_loss : 0.1297 |test_acc : 0.9583 \n",
      "Epoch 35 |train_loss : 0.0213 |train_acc : 1.0000 |test_loss : 0.1392 |test_acc : 0.9583 \n",
      "Epoch 36 |train_loss : 0.0190 |train_acc : 1.0000 |test_loss : 0.1133 |test_acc : 0.9583 \n",
      "Epoch 37 |train_loss : 0.0140 |train_acc : 1.0000 |test_loss : 0.1252 |test_acc : 0.9583 \n",
      "Epoch 38 |train_loss : 0.0132 |train_acc : 1.0000 |test_loss : 0.1144 |test_acc : 0.9583 \n",
      "Epoch 39 |train_loss : 0.0101 |train_acc : 1.0000 |test_loss : 0.0986 |test_acc : 0.9583 \n",
      "Epoch 40 |train_loss : 0.0081 |train_acc : 1.0000 |test_loss : 0.1178 |test_acc : 0.9583 \n",
      "Epoch 41 |train_loss : 0.0083 |train_acc : 1.0000 |test_loss : 0.1032 |test_acc : 0.9583 \n",
      "Epoch 42 |train_loss : 0.0067 |train_acc : 1.0000 |test_loss : 0.1075 |test_acc : 0.9583 \n",
      "Epoch 43 |train_loss : 0.0076 |train_acc : 1.0000 |test_loss : 0.1041 |test_acc : 0.9583 \n",
      "Epoch 44 |train_loss : 0.0063 |train_acc : 1.0000 |test_loss : 0.1070 |test_acc : 0.9583 \n",
      "Epoch 45 |train_loss : 0.0056 |train_acc : 1.0000 |test_loss : 0.1071 |test_acc : 0.9583 \n",
      "Epoch 46 |train_loss : 0.0060 |train_acc : 1.0000 |test_loss : 0.1220 |test_acc : 0.9583 \n",
      "Epoch 47 |train_loss : 0.0049 |train_acc : 1.0000 |test_loss : 0.0969 |test_acc : 0.9583 \n",
      "Epoch 48 |train_loss : 0.0053 |train_acc : 1.0000 |test_loss : 0.1044 |test_acc : 0.9583 \n",
      "Epoch 49 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.0991 |test_acc : 0.9583 \n",
      "Epoch 50 |train_loss : 0.0050 |train_acc : 1.0000 |test_loss : 0.3417 |test_acc : 0.8333 \n",
      "Epoch 51 |train_loss : 0.0041 |train_acc : 1.0000 |test_loss : 0.0956 |test_acc : 0.9583 \n",
      "Epoch 52 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.1010 |test_acc : 0.9583 \n",
      "Epoch 53 |train_loss : 0.0070 |train_acc : 1.0000 |test_loss : 0.1279 |test_acc : 0.9583 \n",
      "Epoch 54 |train_loss : 0.0058 |train_acc : 1.0000 |test_loss : 0.0699 |test_acc : 0.9583 \n",
      "Epoch 55 |train_loss : 0.0062 |train_acc : 1.0000 |test_loss : 0.1165 |test_acc : 0.9583 \n",
      "Epoch 56 |train_loss : 0.0048 |train_acc : 1.0000 |test_loss : 0.0853 |test_acc : 0.9583 \n",
      "Epoch 57 |train_loss : 0.0038 |train_acc : 1.0000 |test_loss : 0.1002 |test_acc : 0.9583 \n",
      "Epoch 58 |train_loss : 0.0029 |train_acc : 1.0000 |test_loss : 0.1097 |test_acc : 0.9583 \n",
      "Epoch 59 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.3444 |test_acc : 0.8333 \n",
      "Epoch 60 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.0909 |test_acc : 0.9583 \n",
      "Epoch 61 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.1059 |test_acc : 0.9583 \n",
      "Epoch 62 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.1002 |test_acc : 0.9583 \n",
      "Epoch 63 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.3674 |test_acc : 0.8333 \n",
      "Epoch 64 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.0903 |test_acc : 0.9583 \n",
      "Epoch 65 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0953 |test_acc : 0.9583 \n",
      "Epoch 66 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0907 |test_acc : 0.9583 \n",
      "Epoch 67 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0905 |test_acc : 0.9583 \n",
      "Epoch 68 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.0979 |test_acc : 0.9583 \n",
      "Epoch 69 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0833 |test_acc : 0.9583 \n",
      "Epoch 70 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0889 |test_acc : 0.9583 \n",
      "Epoch 71 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.0911 |test_acc : 0.9583 \n",
      "Epoch 72 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.0960 |test_acc : 0.9583 \n",
      "Epoch 73 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0904 |test_acc : 0.9583 \n",
      "Epoch 74 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.3213 |test_acc : 0.8333 \n",
      "Epoch 75 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0901 |test_acc : 0.9583 \n",
      "Epoch 76 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0909 |test_acc : 0.9583 \n",
      "Epoch 77 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0918 |test_acc : 0.9583 \n",
      "Epoch 78 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0843 |test_acc : 0.9583 \n",
      "Epoch 79 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0893 |test_acc : 0.9583 \n",
      "Epoch 80 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3228 |test_acc : 0.8333 \n",
      "Epoch 81 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0891 |test_acc : 0.9583 \n",
      "Epoch 82 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0829 |test_acc : 0.9583 \n",
      "Epoch 83 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0792 |test_acc : 0.9583 \n",
      "Epoch 84 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0833 |test_acc : 0.9583 \n",
      "Epoch 85 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0787 |test_acc : 0.9583 \n",
      "Epoch 86 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0875 |test_acc : 0.9583 \n",
      "Epoch 87 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0888 |test_acc : 0.9583 \n",
      "Epoch 88 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0878 |test_acc : 0.9583 \n",
      "Epoch 89 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0915 |test_acc : 0.9583 \n",
      "Epoch 90 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0804 |test_acc : 0.9583 \n",
      "Epoch 91 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.2829 |test_acc : 0.8333 \n",
      "Epoch 92 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0853 |test_acc : 0.9583 \n",
      "Epoch 93 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0916 |test_acc : 0.9583 \n",
      "Epoch 94 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0852 |test_acc : 0.9583 \n",
      "Epoch 95 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0793 |test_acc : 0.9583 \n",
      "Epoch 96 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0849 |test_acc : 0.9583 \n",
      "Epoch 97 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0800 |test_acc : 0.9583 \n",
      "Epoch 98 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0882 |test_acc : 0.9583 \n",
      "Epoch 99 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0835 |test_acc : 0.9583 \n",
      "Epoch 100 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0850 |test_acc : 0.9583 \n",
      "Epoch 101 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0810 |test_acc : 0.9583 \n",
      "Epoch 102 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0788 |test_acc : 0.9583 \n",
      "Epoch 103 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0756 |test_acc : 0.9583 \n",
      "Epoch 104 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0645 |test_acc : 0.9583 \n",
      "Epoch 105 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0777 |test_acc : 0.9583 \n",
      "Epoch 106 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0782 |test_acc : 0.9583 \n",
      "Epoch 107 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0727 |test_acc : 0.9583 \n",
      "Epoch 108 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0692 |test_acc : 0.9583 \n",
      "Epoch 109 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0737 |test_acc : 0.9583 \n",
      "Epoch 110 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0753 |test_acc : 0.9583 \n",
      "Epoch 111 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0801 |test_acc : 0.9583 \n",
      "Epoch 112 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0733 |test_acc : 0.9583 \n",
      "Epoch 113 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0712 |test_acc : 0.9583 \n",
      "Epoch 114 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0685 |test_acc : 0.9583 \n",
      "Epoch 115 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0724 |test_acc : 0.9583 \n",
      "Epoch 116 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0670 |test_acc : 0.9583 \n",
      "Epoch 117 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0512 |test_acc : 0.9583 \n",
      "Epoch 118 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.2388 |test_acc : 0.8333 \n",
      "Epoch 119 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0759 |test_acc : 0.9583 \n",
      "Epoch 120 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0754 |test_acc : 0.9583 \n",
      "Epoch 121 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.2176 |test_acc : 0.8333 \n",
      "Epoch 122 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0628 |test_acc : 0.9583 \n",
      "Epoch 123 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0590 |test_acc : 0.9583 \n",
      "Epoch 124 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0634 |test_acc : 0.9583 \n",
      "Epoch 125 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0665 |test_acc : 0.9583 \n",
      "Epoch 126 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0686 |test_acc : 0.9583 \n",
      "Epoch 127 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.2364 |test_acc : 0.8333 \n",
      "Epoch 128 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.2337 |test_acc : 0.8333 \n",
      "Epoch 129 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.0613 |test_acc : 0.9583 \n",
      "Epoch 130 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0596 |test_acc : 0.9583 \n",
      "Epoch 131 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0621 |test_acc : 0.9583 \n",
      "Epoch 132 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0622 |test_acc : 0.9583 \n",
      "Epoch 133 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0621 |test_acc : 0.9583 \n",
      "Epoch 134 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0624 |test_acc : 0.9583 \n",
      "Epoch 135 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0525 |test_acc : 0.9583 \n",
      "Epoch 136 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0476 |test_acc : 0.9583 \n",
      "Epoch 137 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0588 |test_acc : 0.9583 \n",
      "Epoch 138 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0585 |test_acc : 0.9583 \n",
      "Epoch 139 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0634 |test_acc : 0.9583 \n",
      "Epoch 140 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0628 |test_acc : 0.9583 \n",
      "Epoch 141 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0535 |test_acc : 0.9583 \n",
      "Epoch 142 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0530 |test_acc : 0.9583 \n",
      "Epoch 143 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0519 |test_acc : 0.9583 \n",
      "Epoch 144 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0542 |test_acc : 0.9583 \n",
      "Epoch 145 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0528 |test_acc : 0.9583 \n",
      "Epoch 146 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0450 |test_acc : 0.9583 \n",
      "Epoch 147 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0443 |test_acc : 0.9583 \n",
      "Epoch 148 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.0516 |test_acc : 0.9583 \n",
      "Epoch 149 |train_loss : 0.0003 |train_acc : 1.0000 |test_loss : 0.2221 |test_acc : 0.8333 \n",
      "Epoch 150 |train_loss : 0.0004 |train_acc : 1.0000 |test_loss : 0.0564 |test_acc : 0.9583 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 7\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_effntb2/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2b23328ba94b9dadfddbb652c4b283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5114 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.6077 |train_acc : 0.7292 |test_loss : 0.5121 |test_acc : 0.7917 \n",
      "Epoch 3 |train_loss : 0.7274 |train_acc : 0.6042 |test_loss : 0.6438 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.6334 |train_acc : 0.6667 |test_loss : 0.6070 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.6535 |train_acc : 0.6667 |test_loss : 0.6195 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.7024 |train_acc : 0.6042 |test_loss : 0.5609 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.6051 |train_acc : 0.7292 |test_loss : 0.6371 |test_acc : 0.6667 \n",
      "Epoch 8 |train_loss : 0.5846 |train_acc : 0.7292 |test_loss : 0.6408 |test_acc : 0.6667 \n",
      "Epoch 9 |train_loss : 0.5848 |train_acc : 0.7292 |test_loss : 0.6670 |test_acc : 0.6667 \n",
      "Epoch 10 |train_loss : 0.6006 |train_acc : 0.7292 |test_loss : 0.6684 |test_acc : 0.6667 \n",
      "Epoch 11 |train_loss : 0.6599 |train_acc : 0.6667 |test_loss : 0.6416 |test_acc : 0.6667 \n",
      "Epoch 12 |train_loss : 0.6093 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.6512 |train_acc : 0.6667 |test_loss : 0.5322 |test_acc : 0.7917 \n",
      "Epoch 14 |train_loss : 0.6386 |train_acc : 0.6667 |test_loss : 0.5425 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6424 |train_acc : 0.6667 |test_loss : 0.5444 |test_acc : 0.7917 \n",
      "Epoch 16 |train_loss : 0.6418 |train_acc : 0.6667 |test_loss : 0.5634 |test_acc : 0.7917 \n",
      "Epoch 17 |train_loss : 0.6392 |train_acc : 0.6667 |test_loss : 0.5565 |test_acc : 0.7917 \n",
      "Epoch 18 |train_loss : 0.6393 |train_acc : 0.6667 |test_loss : 0.5462 |test_acc : 0.7917 \n",
      "Epoch 19 |train_loss : 0.5902 |train_acc : 0.7292 |test_loss : 0.5341 |test_acc : 0.7917 \n",
      "Epoch 20 |train_loss : 0.7223 |train_acc : 0.6042 |test_loss : 0.6443 |test_acc : 0.6667 \n",
      "Epoch 21 |train_loss : 0.6027 |train_acc : 0.7292 |test_loss : 0.6394 |test_acc : 0.6667 \n",
      "Epoch 22 |train_loss : 0.6437 |train_acc : 0.6667 |test_loss : 0.7245 |test_acc : 0.5417 \n",
      "Epoch 23 |train_loss : 0.6017 |train_acc : 0.7292 |test_loss : 0.5485 |test_acc : 0.7917 \n",
      "Epoch 24 |train_loss : 0.5840 |train_acc : 0.7292 |test_loss : 0.5200 |test_acc : 0.7917 \n",
      "Epoch 25 |train_loss : 0.5890 |train_acc : 0.7292 |test_loss : 0.6579 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.5910 |train_acc : 0.7292 |test_loss : 0.5185 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.6482 |train_acc : 0.6667 |test_loss : 0.6412 |test_acc : 0.6667 \n",
      "Epoch 28 |train_loss : 0.5945 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 29 |train_loss : 0.6404 |train_acc : 0.6667 |test_loss : 0.7396 |test_acc : 0.5417 \n",
      "Epoch 30 |train_loss : 0.6950 |train_acc : 0.6042 |test_loss : 0.5423 |test_acc : 0.7917 \n",
      "Epoch 31 |train_loss : 0.6079 |train_acc : 0.7292 |test_loss : 0.6423 |test_acc : 0.6667 \n",
      "Epoch 32 |train_loss : 0.5989 |train_acc : 0.7292 |test_loss : 0.6375 |test_acc : 0.6667 \n",
      "Epoch 33 |train_loss : 0.5984 |train_acc : 0.7292 |test_loss : 0.6619 |test_acc : 0.6667 \n",
      "Epoch 34 |train_loss : 0.6640 |train_acc : 0.6667 |test_loss : 0.6530 |test_acc : 0.6667 \n",
      "Epoch 35 |train_loss : 0.6897 |train_acc : 0.6042 |test_loss : 0.5499 |test_acc : 0.7917 \n",
      "Epoch 36 |train_loss : 0.6307 |train_acc : 0.7292 |test_loss : 0.6229 |test_acc : 0.7917 \n",
      "Epoch 37 |train_loss : 0.6144 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 38 |train_loss : 0.6454 |train_acc : 0.6667 |test_loss : 0.5145 |test_acc : 0.7917 \n",
      "Epoch 39 |train_loss : 0.5903 |train_acc : 0.7292 |test_loss : 0.5158 |test_acc : 0.7917 \n",
      "Epoch 40 |train_loss : 0.6505 |train_acc : 0.6667 |test_loss : 0.5248 |test_acc : 0.7917 \n",
      "Epoch 41 |train_loss : 0.6590 |train_acc : 0.6667 |test_loss : 0.6408 |test_acc : 0.6667 \n",
      "Epoch 42 |train_loss : 0.6425 |train_acc : 0.6667 |test_loss : 0.5671 |test_acc : 0.7917 \n",
      "Epoch 43 |train_loss : 0.6406 |train_acc : 0.6667 |test_loss : 0.5440 |test_acc : 0.7917 \n",
      "Epoch 44 |train_loss : 0.5967 |train_acc : 0.7292 |test_loss : 0.6371 |test_acc : 0.6667 \n",
      "Epoch 45 |train_loss : 0.6573 |train_acc : 0.6667 |test_loss : 0.6514 |test_acc : 0.6667 \n",
      "Epoch 46 |train_loss : 0.5952 |train_acc : 0.7292 |test_loss : 0.5342 |test_acc : 0.7917 \n",
      "Epoch 47 |train_loss : 0.5878 |train_acc : 0.7292 |test_loss : 0.5318 |test_acc : 0.7917 \n",
      "Epoch 48 |train_loss : 0.5862 |train_acc : 0.7292 |test_loss : 0.6459 |test_acc : 0.6667 \n",
      "Epoch 49 |train_loss : 0.6474 |train_acc : 0.6667 |test_loss : 0.5215 |test_acc : 0.7917 \n",
      "Epoch 50 |train_loss : 0.6414 |train_acc : 0.6667 |test_loss : 0.5350 |test_acc : 0.7917 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 8\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_effntb2/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b864173bd9b844d8ba9c1c6eebae4ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5114 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.6077 |train_acc : 0.7292 |test_loss : 0.5121 |test_acc : 0.7917 \n",
      "Epoch 3 |train_loss : 0.7274 |train_acc : 0.6042 |test_loss : 0.6438 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.6334 |train_acc : 0.6667 |test_loss : 0.6070 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.6535 |train_acc : 0.6667 |test_loss : 0.6058 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.6936 |train_acc : 0.6042 |test_loss : 0.5563 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.6017 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 8 |train_loss : 0.5843 |train_acc : 0.7292 |test_loss : 0.6411 |test_acc : 0.6667 \n",
      "Epoch 9 |train_loss : 0.5847 |train_acc : 0.7292 |test_loss : 0.6656 |test_acc : 0.6667 \n",
      "Epoch 10 |train_loss : 0.6002 |train_acc : 0.7292 |test_loss : 0.6668 |test_acc : 0.6667 \n",
      "Epoch 11 |train_loss : 0.6587 |train_acc : 0.6667 |test_loss : 0.6411 |test_acc : 0.6667 \n",
      "Epoch 12 |train_loss : 0.6093 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.6518 |train_acc : 0.6667 |test_loss : 0.5313 |test_acc : 0.7917 \n",
      "Epoch 14 |train_loss : 0.6388 |train_acc : 0.6667 |test_loss : 0.5421 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6422 |train_acc : 0.6667 |test_loss : 0.5447 |test_acc : 0.7917 \n",
      "Epoch 16 |train_loss : 0.6419 |train_acc : 0.6667 |test_loss : 0.5642 |test_acc : 0.7917 \n",
      "Epoch 17 |train_loss : 0.6393 |train_acc : 0.6667 |test_loss : 0.5565 |test_acc : 0.7917 \n",
      "Epoch 18 |train_loss : 0.6393 |train_acc : 0.6667 |test_loss : 0.5457 |test_acc : 0.7917 \n",
      "Epoch 19 |train_loss : 0.5900 |train_acc : 0.7292 |test_loss : 0.5339 |test_acc : 0.7917 \n",
      "Epoch 20 |train_loss : 0.7225 |train_acc : 0.6042 |test_loss : 0.6443 |test_acc : 0.6667 \n",
      "Epoch 21 |train_loss : 0.6031 |train_acc : 0.7292 |test_loss : 0.6396 |test_acc : 0.6667 \n",
      "Epoch 22 |train_loss : 0.6439 |train_acc : 0.6667 |test_loss : 0.7245 |test_acc : 0.5417 \n",
      "Epoch 23 |train_loss : 0.6016 |train_acc : 0.7292 |test_loss : 0.5482 |test_acc : 0.7917 \n",
      "Epoch 24 |train_loss : 0.5839 |train_acc : 0.7292 |test_loss : 0.5197 |test_acc : 0.7917 \n",
      "Epoch 25 |train_loss : 0.5892 |train_acc : 0.7292 |test_loss : 0.6580 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.5911 |train_acc : 0.7292 |test_loss : 0.5186 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.6481 |train_acc : 0.6667 |test_loss : 0.6411 |test_acc : 0.6667 \n",
      "Epoch 28 |train_loss : 0.5946 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 29 |train_loss : 0.6404 |train_acc : 0.6667 |test_loss : 0.7399 |test_acc : 0.5417 \n",
      "Epoch 30 |train_loss : 0.6952 |train_acc : 0.6042 |test_loss : 0.5419 |test_acc : 0.7917 \n",
      "Epoch 31 |train_loss : 0.6079 |train_acc : 0.7292 |test_loss : 0.6423 |test_acc : 0.6667 \n",
      "Epoch 32 |train_loss : 0.6002 |train_acc : 0.7292 |test_loss : 0.6370 |test_acc : 0.6667 \n",
      "Epoch 33 |train_loss : 0.5976 |train_acc : 0.7292 |test_loss : 0.6594 |test_acc : 0.6667 \n",
      "Epoch 34 |train_loss : 0.6617 |train_acc : 0.6667 |test_loss : 0.6516 |test_acc : 0.6667 \n",
      "Epoch 35 |train_loss : 0.6894 |train_acc : 0.6042 |test_loss : 0.5500 |test_acc : 0.7917 \n",
      "Epoch 36 |train_loss : 0.6301 |train_acc : 0.7292 |test_loss : 0.6213 |test_acc : 0.7917 \n",
      "Epoch 37 |train_loss : 0.6134 |train_acc : 0.7292 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 38 |train_loss : 0.6456 |train_acc : 0.6667 |test_loss : 0.5144 |test_acc : 0.7917 \n",
      "Epoch 39 |train_loss : 0.5904 |train_acc : 0.7292 |test_loss : 0.5159 |test_acc : 0.7917 \n",
      "Epoch 40 |train_loss : 0.6501 |train_acc : 0.6667 |test_loss : 0.5252 |test_acc : 0.7917 \n",
      "Epoch 41 |train_loss : 0.6590 |train_acc : 0.6667 |test_loss : 0.6409 |test_acc : 0.6667 \n",
      "Epoch 42 |train_loss : 0.6426 |train_acc : 0.6667 |test_loss : 0.5667 |test_acc : 0.7917 \n",
      "Epoch 43 |train_loss : 0.6406 |train_acc : 0.6667 |test_loss : 0.5436 |test_acc : 0.7917 \n",
      "Epoch 44 |train_loss : 0.5967 |train_acc : 0.7292 |test_loss : 0.6371 |test_acc : 0.6667 \n",
      "Epoch 45 |train_loss : 0.6573 |train_acc : 0.6667 |test_loss : 0.6514 |test_acc : 0.6667 \n",
      "Epoch 46 |train_loss : 0.5953 |train_acc : 0.7292 |test_loss : 0.5344 |test_acc : 0.7917 \n",
      "Epoch 47 |train_loss : 0.5878 |train_acc : 0.7292 |test_loss : 0.5319 |test_acc : 0.7917 \n",
      "Epoch 48 |train_loss : 0.5861 |train_acc : 0.7292 |test_loss : 0.6460 |test_acc : 0.6667 \n",
      "Epoch 49 |train_loss : 0.6475 |train_acc : 0.6667 |test_loss : 0.5214 |test_acc : 0.7917 \n",
      "Epoch 50 |train_loss : 0.6414 |train_acc : 0.6667 |test_loss : 0.5351 |test_acc : 0.7917 \n",
      "Epoch 51 |train_loss : 0.6400 |train_acc : 0.6667 |test_loss : 0.5725 |test_acc : 0.7917 \n",
      "Epoch 52 |train_loss : 0.6048 |train_acc : 0.7292 |test_loss : 0.7163 |test_acc : 0.5417 \n",
      "Epoch 53 |train_loss : 0.6374 |train_acc : 0.6667 |test_loss : 0.5299 |test_acc : 0.7917 \n",
      "Epoch 54 |train_loss : 0.6416 |train_acc : 0.6667 |test_loss : 0.6406 |test_acc : 0.6667 \n",
      "Epoch 55 |train_loss : 0.6384 |train_acc : 0.6667 |test_loss : 0.5495 |test_acc : 0.7917 \n",
      "Epoch 56 |train_loss : 0.6052 |train_acc : 0.7292 |test_loss : 0.6368 |test_acc : 0.6667 \n",
      "Epoch 57 |train_loss : 0.6463 |train_acc : 0.6667 |test_loss : 0.6444 |test_acc : 0.6667 \n",
      "Epoch 58 |train_loss : 0.5870 |train_acc : 0.7292 |test_loss : 0.5283 |test_acc : 0.7917 \n",
      "Epoch 59 |train_loss : 0.6464 |train_acc : 0.6667 |test_loss : 0.6413 |test_acc : 0.6667 \n",
      "Epoch 60 |train_loss : 0.6404 |train_acc : 0.6667 |test_loss : 0.5405 |test_acc : 0.7917 \n",
      "Epoch 61 |train_loss : 0.5992 |train_acc : 0.7292 |test_loss : 0.6369 |test_acc : 0.6667 \n",
      "Epoch 62 |train_loss : 0.6657 |train_acc : 0.6667 |test_loss : 0.5240 |test_acc : 0.7917 \n",
      "Epoch 63 |train_loss : 0.5968 |train_acc : 0.7292 |test_loss : 0.6370 |test_acc : 0.6667 \n",
      "Epoch 64 |train_loss : 0.5906 |train_acc : 0.7292 |test_loss : 0.5334 |test_acc : 0.7917 \n",
      "Epoch 65 |train_loss : 0.5803 |train_acc : 0.7292 |test_loss : 0.6548 |test_acc : 0.6667 \n",
      "Epoch 66 |train_loss : 0.6719 |train_acc : 0.6667 |test_loss : 0.5147 |test_acc : 0.7917 \n",
      "Epoch 67 |train_loss : 0.6484 |train_acc : 0.6667 |test_loss : 0.5550 |test_acc : 0.7917 \n",
      "Epoch 68 |train_loss : 0.6239 |train_acc : 0.7292 |test_loss : 0.7015 |test_acc : 0.5417 \n",
      "Epoch 69 |train_loss : 0.5883 |train_acc : 0.7292 |test_loss : 0.5273 |test_acc : 0.7917 \n",
      "Epoch 70 |train_loss : 0.7429 |train_acc : 0.6042 |test_loss : 0.5135 |test_acc : 0.7917 \n",
      "Epoch 71 |train_loss : 0.6459 |train_acc : 0.6667 |test_loss : 0.5556 |test_acc : 0.7917 \n",
      "Epoch 72 |train_loss : 0.6337 |train_acc : 0.6667 |test_loss : 0.6404 |test_acc : 0.6667 \n",
      "Epoch 73 |train_loss : 0.6124 |train_acc : 0.7292 |test_loss : 0.6381 |test_acc : 0.6667 \n",
      "Epoch 74 |train_loss : 0.5881 |train_acc : 0.7292 |test_loss : 0.7608 |test_acc : 0.5417 \n",
      "Epoch 75 |train_loss : 0.5820 |train_acc : 0.7292 |test_loss : 0.6590 |test_acc : 0.6667 \n",
      "Epoch 76 |train_loss : 0.6652 |train_acc : 0.6667 |test_loss : 0.6592 |test_acc : 0.6667 \n",
      "Epoch 77 |train_loss : 0.6166 |train_acc : 0.7292 |test_loss : 0.5501 |test_acc : 0.7917 \n",
      "Epoch 78 |train_loss : 0.5950 |train_acc : 0.7292 |test_loss : 0.6410 |test_acc : 0.6667 \n",
      "Epoch 79 |train_loss : 0.5879 |train_acc : 0.7292 |test_loss : 0.6487 |test_acc : 0.6667 \n",
      "Epoch 80 |train_loss : 0.6556 |train_acc : 0.6667 |test_loss : 0.6469 |test_acc : 0.6667 \n",
      "Epoch 81 |train_loss : 0.6565 |train_acc : 0.6667 |test_loss : 0.6394 |test_acc : 0.6667 \n",
      "Epoch 82 |train_loss : 0.6447 |train_acc : 0.6667 |test_loss : 0.5607 |test_acc : 0.7917 \n",
      "Epoch 83 |train_loss : 0.6382 |train_acc : 0.6667 |test_loss : 0.6366 |test_acc : 0.6667 \n",
      "Epoch 84 |train_loss : 0.6396 |train_acc : 0.6667 |test_loss : 0.5450 |test_acc : 0.7917 \n",
      "Epoch 85 |train_loss : 0.5906 |train_acc : 0.7292 |test_loss : 0.5342 |test_acc : 0.7917 \n",
      "Epoch 86 |train_loss : 0.5835 |train_acc : 0.7292 |test_loss : 0.5224 |test_acc : 0.7917 \n",
      "Epoch 87 |train_loss : 0.6770 |train_acc : 0.6667 |test_loss : 0.5153 |test_acc : 0.7917 \n",
      "Epoch 88 |train_loss : 0.6454 |train_acc : 0.6667 |test_loss : 0.5573 |test_acc : 0.7917 \n",
      "Epoch 89 |train_loss : 0.6584 |train_acc : 0.6667 |test_loss : 0.6465 |test_acc : 0.6667 \n",
      "Epoch 90 |train_loss : 0.7013 |train_acc : 0.6042 |test_loss : 0.5498 |test_acc : 0.7917 \n",
      "Epoch 91 |train_loss : 0.6072 |train_acc : 0.7292 |test_loss : 0.7105 |test_acc : 0.5417 \n",
      "Epoch 92 |train_loss : 0.5901 |train_acc : 0.7292 |test_loss : 0.6428 |test_acc : 0.6667 \n",
      "Epoch 93 |train_loss : 0.6666 |train_acc : 0.6667 |test_loss : 0.5145 |test_acc : 0.7917 \n",
      "Epoch 94 |train_loss : 0.5933 |train_acc : 0.7292 |test_loss : 0.6387 |test_acc : 0.6667 \n",
      "Epoch 95 |train_loss : 0.5906 |train_acc : 0.7292 |test_loss : 0.6379 |test_acc : 0.6667 \n",
      "Epoch 96 |train_loss : 0.6413 |train_acc : 0.6667 |test_loss : 0.5312 |test_acc : 0.7917 \n",
      "Epoch 97 |train_loss : 0.6415 |train_acc : 0.6667 |test_loss : 0.5442 |test_acc : 0.7917 \n",
      "Epoch 98 |train_loss : 0.5925 |train_acc : 0.7292 |test_loss : 0.5376 |test_acc : 0.7917 \n",
      "Epoch 99 |train_loss : 0.6451 |train_acc : 0.6667 |test_loss : 0.6413 |test_acc : 0.6667 \n",
      "Epoch 100 |train_loss : 0.6903 |train_acc : 0.6042 |test_loss : 0.6365 |test_acc : 0.6667 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 9\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/Adam/custom_effntb2/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dee0c94274e407db10e0f0066af4f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5114 |test_acc : 0.7917 \n",
      "Epoch 2 |train_loss : 0.6077 |train_acc : 0.7292 |test_loss : 0.5121 |test_acc : 0.7917 \n",
      "Epoch 3 |train_loss : 0.7274 |train_acc : 0.6042 |test_loss : 0.6438 |test_acc : 0.6667 \n",
      "Epoch 4 |train_loss : 0.6334 |train_acc : 0.6667 |test_loss : 0.6070 |test_acc : 0.7917 \n",
      "Epoch 5 |train_loss : 0.6535 |train_acc : 0.6667 |test_loss : 0.6101 |test_acc : 0.7917 \n",
      "Epoch 6 |train_loss : 0.6947 |train_acc : 0.6042 |test_loss : 0.5570 |test_acc : 0.7917 \n",
      "Epoch 7 |train_loss : 0.6022 |train_acc : 0.7292 |test_loss : 0.6367 |test_acc : 0.6667 \n",
      "Epoch 8 |train_loss : 0.5843 |train_acc : 0.7292 |test_loss : 0.6411 |test_acc : 0.6667 \n",
      "Epoch 9 |train_loss : 0.5848 |train_acc : 0.7292 |test_loss : 0.6660 |test_acc : 0.6667 \n",
      "Epoch 10 |train_loss : 0.6000 |train_acc : 0.7292 |test_loss : 0.6669 |test_acc : 0.6667 \n",
      "Epoch 11 |train_loss : 0.6587 |train_acc : 0.6667 |test_loss : 0.6411 |test_acc : 0.6667 \n",
      "Epoch 12 |train_loss : 0.6094 |train_acc : 0.7292 |test_loss : 0.6377 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.6522 |train_acc : 0.6667 |test_loss : 0.5313 |test_acc : 0.7917 \n",
      "Epoch 14 |train_loss : 0.6386 |train_acc : 0.6667 |test_loss : 0.5425 |test_acc : 0.7917 \n",
      "Epoch 15 |train_loss : 0.6423 |train_acc : 0.6667 |test_loss : 0.5447 |test_acc : 0.7917 \n",
      "Epoch 16 |train_loss : 0.6419 |train_acc : 0.6667 |test_loss : 0.5638 |test_acc : 0.7917 \n",
      "Epoch 17 |train_loss : 0.6391 |train_acc : 0.6667 |test_loss : 0.5561 |test_acc : 0.7917 \n",
      "Epoch 18 |train_loss : 0.6392 |train_acc : 0.6667 |test_loss : 0.5456 |test_acc : 0.7917 \n",
      "Epoch 19 |train_loss : 0.5895 |train_acc : 0.7292 |test_loss : 0.5337 |test_acc : 0.7917 \n",
      "Epoch 20 |train_loss : 0.7206 |train_acc : 0.6042 |test_loss : 0.6437 |test_acc : 0.6667 \n",
      "Epoch 21 |train_loss : 0.6031 |train_acc : 0.7292 |test_loss : 0.6393 |test_acc : 0.6667 \n",
      "Epoch 22 |train_loss : 0.6422 |train_acc : 0.6667 |test_loss : 0.7207 |test_acc : 0.5417 \n",
      "Epoch 23 |train_loss : 0.5687 |train_acc : 0.7292 |test_loss : 0.5155 |test_acc : 0.7917 \n",
      "Epoch 24 |train_loss : 0.6297 |train_acc : 0.7292 |test_loss : 0.5219 |test_acc : 0.7917 \n",
      "Epoch 25 |train_loss : 0.6437 |train_acc : 0.7083 |test_loss : 0.6012 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.5653 |train_acc : 0.7292 |test_loss : 0.4763 |test_acc : 0.7917 \n",
      "Epoch 27 |train_loss : 0.6185 |train_acc : 0.6667 |test_loss : 0.5788 |test_acc : 0.6667 \n",
      "Epoch 28 |train_loss : 0.5566 |train_acc : 0.7500 |test_loss : 0.5950 |test_acc : 0.6667 \n",
      "Epoch 29 |train_loss : 0.6031 |train_acc : 0.6667 |test_loss : 0.6718 |test_acc : 0.5417 \n",
      "Epoch 30 |train_loss : 0.5664 |train_acc : 0.7083 |test_loss : 0.5029 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.5406 |train_acc : 0.7917 |test_loss : 0.6268 |test_acc : 0.6667 \n",
      "Epoch 32 |train_loss : 0.5115 |train_acc : 0.7292 |test_loss : 0.5996 |test_acc : 0.6667 \n",
      "Epoch 33 |train_loss : 0.4950 |train_acc : 0.7292 |test_loss : 0.5926 |test_acc : 0.7917 \n",
      "Epoch 34 |train_loss : 0.5080 |train_acc : 0.7917 |test_loss : 0.5032 |test_acc : 0.7500 \n",
      "Epoch 35 |train_loss : 0.4352 |train_acc : 0.8333 |test_loss : 0.4158 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.4201 |train_acc : 0.8750 |test_loss : 0.3553 |test_acc : 0.9167 \n",
      "Epoch 37 |train_loss : 0.2997 |train_acc : 0.8750 |test_loss : 0.4522 |test_acc : 0.6667 \n",
      "Epoch 38 |train_loss : 0.3112 |train_acc : 0.8333 |test_loss : 0.3764 |test_acc : 0.9167 \n",
      "Epoch 39 |train_loss : 0.2440 |train_acc : 0.9583 |test_loss : 0.2990 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.2186 |train_acc : 0.9375 |test_loss : 0.2954 |test_acc : 0.9583 \n",
      "Epoch 41 |train_loss : 0.2940 |train_acc : 0.8542 |test_loss : 0.3380 |test_acc : 0.9167 \n",
      "Epoch 42 |train_loss : 0.3016 |train_acc : 0.8542 |test_loss : 0.2572 |test_acc : 0.9583 \n",
      "Epoch 43 |train_loss : 0.1958 |train_acc : 0.9792 |test_loss : 0.2742 |test_acc : 0.9583 \n",
      "Epoch 44 |train_loss : 0.1704 |train_acc : 1.0000 |test_loss : 0.3318 |test_acc : 0.7500 \n",
      "Epoch 45 |train_loss : 0.2245 |train_acc : 0.9583 |test_loss : 0.2300 |test_acc : 0.9583 \n",
      "Epoch 46 |train_loss : 0.1235 |train_acc : 1.0000 |test_loss : 0.2203 |test_acc : 0.9583 \n",
      "Epoch 47 |train_loss : 0.0977 |train_acc : 0.9792 |test_loss : 0.1869 |test_acc : 0.9583 \n",
      "Epoch 48 |train_loss : 0.1094 |train_acc : 1.0000 |test_loss : 0.1858 |test_acc : 0.9583 \n",
      "Epoch 49 |train_loss : 0.0680 |train_acc : 1.0000 |test_loss : 0.1919 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0937 |train_acc : 1.0000 |test_loss : 0.2597 |test_acc : 0.9583 \n",
      "Epoch 51 |train_loss : 0.1002 |train_acc : 1.0000 |test_loss : 0.1781 |test_acc : 0.9583 \n",
      "Epoch 52 |train_loss : 0.0860 |train_acc : 1.0000 |test_loss : 0.3119 |test_acc : 0.8333 \n",
      "Epoch 53 |train_loss : 0.0739 |train_acc : 1.0000 |test_loss : 0.1569 |test_acc : 0.9583 \n",
      "Epoch 54 |train_loss : 0.0546 |train_acc : 1.0000 |test_loss : 0.4742 |test_acc : 0.8333 \n",
      "Epoch 55 |train_loss : 0.0516 |train_acc : 1.0000 |test_loss : 0.1575 |test_acc : 0.9583 \n",
      "Epoch 56 |train_loss : 0.0346 |train_acc : 1.0000 |test_loss : 0.1413 |test_acc : 0.9583 \n",
      "Epoch 57 |train_loss : 0.0312 |train_acc : 1.0000 |test_loss : 0.2449 |test_acc : 0.8333 \n",
      "Epoch 58 |train_loss : 0.0246 |train_acc : 1.0000 |test_loss : 0.1083 |test_acc : 0.9583 \n",
      "Epoch 59 |train_loss : 0.0230 |train_acc : 1.0000 |test_loss : 0.3246 |test_acc : 0.8333 \n",
      "Epoch 60 |train_loss : 0.0224 |train_acc : 1.0000 |test_loss : 0.1134 |test_acc : 0.9583 \n",
      "Epoch 61 |train_loss : 0.0229 |train_acc : 1.0000 |test_loss : 0.2706 |test_acc : 0.8333 \n",
      "Epoch 62 |train_loss : 0.0205 |train_acc : 1.0000 |test_loss : 0.0897 |test_acc : 0.9583 \n",
      "Epoch 63 |train_loss : 0.0183 |train_acc : 1.0000 |test_loss : 0.1038 |test_acc : 0.9583 \n",
      "Epoch 64 |train_loss : 0.0174 |train_acc : 1.0000 |test_loss : 0.0922 |test_acc : 0.9583 \n",
      "Epoch 65 |train_loss : 0.0183 |train_acc : 1.0000 |test_loss : 0.1118 |test_acc : 0.9583 \n",
      "Epoch 66 |train_loss : 0.0150 |train_acc : 1.0000 |test_loss : 0.1182 |test_acc : 0.9583 \n",
      "Epoch 67 |train_loss : 0.0123 |train_acc : 1.0000 |test_loss : 0.0815 |test_acc : 0.9583 \n",
      "Epoch 68 |train_loss : 0.0130 |train_acc : 1.0000 |test_loss : 0.0670 |test_acc : 0.9583 \n",
      "Epoch 69 |train_loss : 0.0111 |train_acc : 1.0000 |test_loss : 0.0717 |test_acc : 0.9583 \n",
      "Epoch 70 |train_loss : 0.0138 |train_acc : 1.0000 |test_loss : 0.0721 |test_acc : 0.9583 \n",
      "Epoch 71 |train_loss : 0.0093 |train_acc : 1.0000 |test_loss : 0.0617 |test_acc : 1.0000 \n",
      "Epoch 72 |train_loss : 0.0097 |train_acc : 1.0000 |test_loss : 0.0752 |test_acc : 0.9583 \n",
      "Epoch 73 |train_loss : 0.0073 |train_acc : 1.0000 |test_loss : 0.1439 |test_acc : 0.8333 \n",
      "Epoch 74 |train_loss : 0.0069 |train_acc : 1.0000 |test_loss : 0.1483 |test_acc : 1.0000 \n",
      "Epoch 75 |train_loss : 0.0065 |train_acc : 1.0000 |test_loss : 0.0540 |test_acc : 1.0000 \n",
      "Epoch 76 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.0515 |test_acc : 0.9583 \n",
      "Epoch 77 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.0480 |test_acc : 1.0000 \n",
      "Epoch 78 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.0582 |test_acc : 1.0000 \n",
      "Epoch 79 |train_loss : 0.0054 |train_acc : 1.0000 |test_loss : 0.0506 |test_acc : 1.0000 \n",
      "Epoch 80 |train_loss : 0.0052 |train_acc : 1.0000 |test_loss : 0.0576 |test_acc : 1.0000 \n",
      "Epoch 81 |train_loss : 0.0051 |train_acc : 1.0000 |test_loss : 0.0437 |test_acc : 1.0000 \n",
      "Epoch 82 |train_loss : 0.0049 |train_acc : 1.0000 |test_loss : 0.0442 |test_acc : 1.0000 \n",
      "Epoch 83 |train_loss : 0.0048 |train_acc : 1.0000 |test_loss : 0.0960 |test_acc : 1.0000 \n",
      "Epoch 84 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.0384 |test_acc : 1.0000 \n",
      "Epoch 85 |train_loss : 0.0041 |train_acc : 1.0000 |test_loss : 0.0406 |test_acc : 1.0000 \n",
      "Epoch 86 |train_loss : 0.0041 |train_acc : 1.0000 |test_loss : 0.0467 |test_acc : 1.0000 \n",
      "Epoch 87 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.0380 |test_acc : 1.0000 \n",
      "Epoch 88 |train_loss : 0.0038 |train_acc : 1.0000 |test_loss : 0.0354 |test_acc : 1.0000 \n",
      "Epoch 89 |train_loss : 0.0040 |train_acc : 1.0000 |test_loss : 0.0432 |test_acc : 1.0000 \n",
      "Epoch 90 |train_loss : 0.0064 |train_acc : 1.0000 |test_loss : 0.0364 |test_acc : 1.0000 \n",
      "Epoch 91 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 0.0560 |test_acc : 1.0000 \n",
      "Epoch 92 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.0309 |test_acc : 1.0000 \n",
      "Epoch 93 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.0354 |test_acc : 1.0000 \n",
      "Epoch 94 |train_loss : 0.0030 |train_acc : 1.0000 |test_loss : 0.0325 |test_acc : 1.0000 \n",
      "Epoch 95 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.0409 |test_acc : 1.0000 \n",
      "Epoch 96 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.0284 |test_acc : 1.0000 \n",
      "Epoch 97 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.0351 |test_acc : 1.0000 \n",
      "Epoch 98 |train_loss : 0.0027 |train_acc : 1.0000 |test_loss : 0.0341 |test_acc : 1.0000 \n",
      "Epoch 99 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.0480 |test_acc : 1.0000 \n",
      "Epoch 100 |train_loss : 0.0029 |train_acc : 1.0000 |test_loss : 0.0308 |test_acc : 1.0000 \n",
      "Epoch 101 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.0313 |test_acc : 1.0000 \n",
      "Epoch 102 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.0339 |test_acc : 1.0000 \n",
      "Epoch 103 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.0255 |test_acc : 1.0000 \n",
      "Epoch 104 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.0320 |test_acc : 1.0000 \n",
      "Epoch 105 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.0301 |test_acc : 1.0000 \n",
      "Epoch 106 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.0373 |test_acc : 1.0000 \n",
      "Epoch 107 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0467 |test_acc : 1.0000 \n",
      "Epoch 108 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0197 |test_acc : 1.0000 \n",
      "Epoch 109 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0262 |test_acc : 1.0000 \n",
      "Epoch 110 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0200 |test_acc : 1.0000 \n",
      "Epoch 111 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0215 |test_acc : 1.0000 \n",
      "Epoch 112 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0190 |test_acc : 1.0000 \n",
      "Epoch 113 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0250 |test_acc : 1.0000 \n",
      "Epoch 114 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0329 |test_acc : 1.0000 \n",
      "Epoch 115 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0180 |test_acc : 1.0000 \n",
      "Epoch 116 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0464 |test_acc : 1.0000 \n",
      "Epoch 117 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.0376 |test_acc : 1.0000 \n",
      "Epoch 118 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0427 |test_acc : 1.0000 \n",
      "Epoch 119 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0289 |test_acc : 1.0000 \n",
      "Epoch 120 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0175 |test_acc : 1.0000 \n",
      "Epoch 121 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0162 |test_acc : 1.0000 \n",
      "Epoch 122 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0172 |test_acc : 1.0000 \n",
      "Epoch 123 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0183 |test_acc : 1.0000 \n",
      "Epoch 124 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0242 |test_acc : 1.0000 \n",
      "Epoch 125 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0225 |test_acc : 1.0000 \n",
      "Epoch 126 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0233 |test_acc : 1.0000 \n",
      "Epoch 127 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0217 |test_acc : 1.0000 \n",
      "Epoch 128 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0181 |test_acc : 1.0000 \n",
      "Epoch 129 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0147 |test_acc : 1.0000 \n",
      "Epoch 130 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0151 |test_acc : 1.0000 \n",
      "Epoch 131 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0151 |test_acc : 1.0000 \n",
      "Epoch 132 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0161 |test_acc : 1.0000 \n",
      "Epoch 133 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0200 |test_acc : 1.0000 \n",
      "Epoch 134 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0145 |test_acc : 1.0000 \n",
      "Epoch 135 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0160 |test_acc : 1.0000 \n",
      "Epoch 136 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0179 |test_acc : 1.0000 \n",
      "Epoch 137 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0125 |test_acc : 1.0000 \n",
      "Epoch 138 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0173 |test_acc : 1.0000 \n",
      "Epoch 139 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0141 |test_acc : 1.0000 \n",
      "Epoch 140 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0170 |test_acc : 1.0000 \n",
      "Epoch 141 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0123 |test_acc : 1.0000 \n",
      "Epoch 142 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0198 |test_acc : 1.0000 \n",
      "Epoch 143 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0127 |test_acc : 1.0000 \n",
      "Epoch 144 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0148 |test_acc : 1.0000 \n",
      "Epoch 145 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0116 |test_acc : 1.0000 \n",
      "Epoch 146 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0116 |test_acc : 1.0000 \n",
      "Epoch 147 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0118 |test_acc : 1.0000 \n",
      "Epoch 148 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0165 |test_acc : 1.0000 \n",
      "Epoch 149 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0118 |test_acc : 1.0000 \n",
      "Epoch 150 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0117 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.experiment_generator import run_experiments\n",
    "\n",
    "parameters = {\"epochs\": [50, 100, 150], \"optimizers\":[\"Adam\"], \"models\": [\"custom_resnet152\", \"custom_resnet101\", \"custom_effntb2\"]}\n",
    "cm_fig = run_experiments(test_dataloader, train_dataloader, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo tomando una sesi√≥n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import load_data\n",
    "\n",
    "train_dataloader, test_dataloader = load_data(\"output/\", 4, augmentation=False, all_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de etiquetas en el conjunto de entrenamiento: {0: 7, 1: 14}\n",
      "Conteo de etiquetas en el conjunto de prueba: {0: 2, 1: 7}\n"
     ]
    }
   ],
   "source": [
    "contador = {0: 0, 1: 0}\n",
    "\n",
    "for _, label in train_dataloader:\n",
    "    for l in label:\n",
    "        contador[l.item()] += 1\n",
    "\n",
    "print(f\"Conteo de etiquetas en el conjunto de entrenamiento: {contador}\")\n",
    "\n",
    "\n",
    "contador = {0: 0, 1: 0}\n",
    "for _, label in test_dataloader:\n",
    "    for l in label:\n",
    "        contador[l.item()] += 1\n",
    "\n",
    "print(f\"Conteo de etiquetas en el conjunto de prueba: {contador}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet152/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1df129cca6f4794801865de46804057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.8391 |train_acc : 0.4167 |test_loss : 0.6799 |test_acc : 0.9167 \n",
      "Epoch 2 |train_loss : 0.6745 |train_acc : 0.7500 |test_loss : 0.5925 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.6688 |train_acc : 0.6250 |test_loss : 0.6485 |test_acc : 0.9167 \n",
      "Epoch 4 |train_loss : 0.6660 |train_acc : 0.5417 |test_loss : 0.6703 |test_acc : 0.5000 \n",
      "Epoch 5 |train_loss : 0.6879 |train_acc : 0.5417 |test_loss : 0.6385 |test_acc : 0.5833 \n",
      "Epoch 6 |train_loss : 0.6142 |train_acc : 0.7500 |test_loss : 0.5944 |test_acc : 1.0000 \n",
      "Epoch 7 |train_loss : 0.6074 |train_acc : 0.7917 |test_loss : 0.7006 |test_acc : 0.5833 \n",
      "Epoch 8 |train_loss : 0.6685 |train_acc : 0.7083 |test_loss : 0.6535 |test_acc : 0.7500 \n",
      "Epoch 9 |train_loss : 0.6616 |train_acc : 0.5833 |test_loss : 0.6570 |test_acc : 0.9167 \n",
      "Epoch 10 |train_loss : 0.6173 |train_acc : 0.8333 |test_loss : 0.6833 |test_acc : 0.6667 \n",
      "Epoch 11 |train_loss : 0.5692 |train_acc : 0.7917 |test_loss : 0.5836 |test_acc : 0.9167 \n",
      "Epoch 12 |train_loss : 0.5256 |train_acc : 0.7917 |test_loss : 0.5027 |test_acc : 0.9167 \n",
      "Epoch 13 |train_loss : 0.5907 |train_acc : 0.5833 |test_loss : 0.5612 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.5153 |train_acc : 0.9167 |test_loss : 0.5709 |test_acc : 0.7500 \n",
      "Epoch 15 |train_loss : 0.5358 |train_acc : 0.7917 |test_loss : 0.5762 |test_acc : 0.6667 \n",
      "Epoch 16 |train_loss : 0.4982 |train_acc : 0.8333 |test_loss : 0.6200 |test_acc : 0.5833 \n",
      "Epoch 17 |train_loss : 0.4637 |train_acc : 0.9167 |test_loss : 0.4743 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.4825 |train_acc : 0.8333 |test_loss : 0.4374 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.3886 |train_acc : 0.9583 |test_loss : 0.5009 |test_acc : 0.9167 \n",
      "Epoch 20 |train_loss : 0.2854 |train_acc : 1.0000 |test_loss : 0.3979 |test_acc : 0.8333 \n",
      "Epoch 21 |train_loss : 0.3400 |train_acc : 0.9167 |test_loss : 0.5244 |test_acc : 0.9167 \n",
      "Epoch 22 |train_loss : 0.3880 |train_acc : 0.9167 |test_loss : 0.4889 |test_acc : 0.8333 \n",
      "Epoch 23 |train_loss : 0.2762 |train_acc : 0.9583 |test_loss : 0.4695 |test_acc : 0.9167 \n",
      "Epoch 24 |train_loss : 0.2294 |train_acc : 1.0000 |test_loss : 0.3412 |test_acc : 0.8333 \n",
      "Epoch 25 |train_loss : 0.2484 |train_acc : 1.0000 |test_loss : 0.3971 |test_acc : 0.8333 \n",
      "Epoch 26 |train_loss : 0.2199 |train_acc : 1.0000 |test_loss : 0.3032 |test_acc : 0.9167 \n",
      "Epoch 27 |train_loss : 0.2129 |train_acc : 1.0000 |test_loss : 0.4883 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.2253 |train_acc : 1.0000 |test_loss : 0.3714 |test_acc : 0.9167 \n",
      "Epoch 29 |train_loss : 0.1644 |train_acc : 1.0000 |test_loss : 0.4528 |test_acc : 0.6667 \n",
      "Epoch 30 |train_loss : 0.1429 |train_acc : 1.0000 |test_loss : 0.3149 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.0868 |train_acc : 1.0000 |test_loss : 0.3697 |test_acc : 0.9167 \n",
      "Epoch 32 |train_loss : 0.0903 |train_acc : 1.0000 |test_loss : 0.2301 |test_acc : 0.9167 \n",
      "Epoch 33 |train_loss : 0.0820 |train_acc : 1.0000 |test_loss : 0.4151 |test_acc : 0.6667 \n",
      "Epoch 34 |train_loss : 0.0497 |train_acc : 1.0000 |test_loss : 0.2093 |test_acc : 0.9167 \n",
      "Epoch 35 |train_loss : 0.0599 |train_acc : 1.0000 |test_loss : 0.2459 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.0448 |train_acc : 1.0000 |test_loss : 0.3225 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0466 |train_acc : 1.0000 |test_loss : 0.1972 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0485 |train_acc : 1.0000 |test_loss : 0.3115 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0338 |train_acc : 1.0000 |test_loss : 0.1830 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.0293 |train_acc : 1.0000 |test_loss : 0.2524 |test_acc : 0.9167 \n",
      "Epoch 41 |train_loss : 0.0232 |train_acc : 1.0000 |test_loss : 0.2144 |test_acc : 0.9167 \n",
      "Epoch 42 |train_loss : 0.0205 |train_acc : 1.0000 |test_loss : 0.2538 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0213 |train_acc : 1.0000 |test_loss : 0.3626 |test_acc : 0.6667 \n",
      "Epoch 44 |train_loss : 0.0190 |train_acc : 1.0000 |test_loss : 0.2544 |test_acc : 0.9167 \n",
      "Epoch 45 |train_loss : 0.0156 |train_acc : 1.0000 |test_loss : 0.1901 |test_acc : 0.9167 \n",
      "Epoch 46 |train_loss : 0.0186 |train_acc : 1.0000 |test_loss : 0.1440 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0158 |train_acc : 1.0000 |test_loss : 0.3190 |test_acc : 0.9167 \n",
      "Epoch 48 |train_loss : 0.0148 |train_acc : 1.0000 |test_loss : 0.2272 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0117 |train_acc : 1.0000 |test_loss : 0.2430 |test_acc : 1.0000 \n",
      "Epoch 50 |train_loss : 0.0143 |train_acc : 1.0000 |test_loss : 0.2161 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 2\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet152/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363593833c6e4c6bb2204363afef5f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7260 |train_acc : 0.4583 |test_loss : 0.7033 |test_acc : 0.5833 \n",
      "Epoch 2 |train_loss : 0.7308 |train_acc : 0.5833 |test_loss : 0.6268 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.7153 |train_acc : 0.4583 |test_loss : 0.7020 |test_acc : 0.1667 \n",
      "Epoch 4 |train_loss : 0.6914 |train_acc : 0.5417 |test_loss : 0.6549 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.7400 |train_acc : 0.5833 |test_loss : 0.6006 |test_acc : 0.8333 \n",
      "Epoch 6 |train_loss : 0.6881 |train_acc : 0.7083 |test_loss : 0.6451 |test_acc : 0.8333 \n",
      "Epoch 7 |train_loss : 0.7021 |train_acc : 0.5833 |test_loss : 0.6911 |test_acc : 0.5833 \n",
      "Epoch 8 |train_loss : 0.7028 |train_acc : 0.2500 |test_loss : 0.6911 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.6963 |train_acc : 0.3750 |test_loss : 0.6995 |test_acc : 0.1667 \n",
      "Epoch 10 |train_loss : 0.7025 |train_acc : 0.5000 |test_loss : 0.6910 |test_acc : 0.5833 \n",
      "Epoch 11 |train_loss : 0.6823 |train_acc : 0.7083 |test_loss : 0.6495 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.7095 |train_acc : 0.5833 |test_loss : 0.6248 |test_acc : 0.8333 \n",
      "Epoch 13 |train_loss : 0.6701 |train_acc : 0.7083 |test_loss : 0.6251 |test_acc : 0.8333 \n",
      "Epoch 14 |train_loss : 0.6766 |train_acc : 0.7083 |test_loss : 0.6319 |test_acc : 0.8333 \n",
      "Epoch 15 |train_loss : 0.7306 |train_acc : 0.5833 |test_loss : 0.6964 |test_acc : 0.5833 \n",
      "Epoch 16 |train_loss : 0.6919 |train_acc : 0.7083 |test_loss : 0.6913 |test_acc : 0.5833 \n",
      "Epoch 17 |train_loss : 0.6930 |train_acc : 0.7083 |test_loss : 0.6724 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.7073 |train_acc : 0.5833 |test_loss : 0.6319 |test_acc : 0.8333 \n",
      "Epoch 19 |train_loss : 0.6936 |train_acc : 0.7083 |test_loss : 0.6909 |test_acc : 0.5833 \n",
      "Epoch 20 |train_loss : 0.7090 |train_acc : 0.5833 |test_loss : 0.6936 |test_acc : 0.5833 \n",
      "Epoch 21 |train_loss : 0.7057 |train_acc : 0.5833 |test_loss : 0.6918 |test_acc : 0.5833 \n",
      "Epoch 22 |train_loss : 0.6948 |train_acc : 0.5833 |test_loss : 0.6974 |test_acc : 0.1667 \n",
      "Epoch 23 |train_loss : 0.7053 |train_acc : 0.2917 |test_loss : 0.7149 |test_acc : 0.1667 \n",
      "Epoch 24 |train_loss : 0.6933 |train_acc : 0.4583 |test_loss : 0.6753 |test_acc : 0.8333 \n",
      "Epoch 25 |train_loss : 0.6805 |train_acc : 0.7083 |test_loss : 0.6288 |test_acc : 0.8333 \n",
      "Epoch 26 |train_loss : 0.6833 |train_acc : 0.7083 |test_loss : 0.5937 |test_acc : 0.8333 \n",
      "Epoch 27 |train_loss : 0.7181 |train_acc : 0.5833 |test_loss : 0.6211 |test_acc : 0.8333 \n",
      "Epoch 28 |train_loss : 0.6887 |train_acc : 0.7083 |test_loss : 0.6438 |test_acc : 0.8333 \n",
      "Epoch 29 |train_loss : 0.7204 |train_acc : 0.5833 |test_loss : 0.6146 |test_acc : 0.8333 \n",
      "Epoch 30 |train_loss : 0.6848 |train_acc : 0.7083 |test_loss : 0.6620 |test_acc : 0.8333 \n",
      "Epoch 31 |train_loss : 0.6779 |train_acc : 0.7083 |test_loss : 0.6401 |test_acc : 0.8333 \n",
      "Epoch 32 |train_loss : 0.6781 |train_acc : 0.7083 |test_loss : 0.6115 |test_acc : 0.8333 \n",
      "Epoch 33 |train_loss : 0.6753 |train_acc : 0.7083 |test_loss : 0.7103 |test_acc : 0.5833 \n",
      "Epoch 34 |train_loss : 0.6779 |train_acc : 0.7083 |test_loss : 0.5846 |test_acc : 0.8333 \n",
      "Epoch 35 |train_loss : 0.7397 |train_acc : 0.5833 |test_loss : 0.6079 |test_acc : 0.8333 \n",
      "Epoch 36 |train_loss : 0.7024 |train_acc : 0.5833 |test_loss : 0.6955 |test_acc : 0.1667 \n",
      "Epoch 37 |train_loss : 0.7076 |train_acc : 0.4167 |test_loss : 0.7862 |test_acc : 0.1667 \n",
      "Epoch 38 |train_loss : 0.7307 |train_acc : 0.2917 |test_loss : 0.7322 |test_acc : 0.1667 \n",
      "Epoch 39 |train_loss : 0.7018 |train_acc : 0.3333 |test_loss : 0.6911 |test_acc : 0.5833 \n",
      "Epoch 40 |train_loss : 0.6890 |train_acc : 0.7083 |test_loss : 0.6696 |test_acc : 0.8333 \n",
      "Epoch 41 |train_loss : 0.7003 |train_acc : 0.5833 |test_loss : 0.6540 |test_acc : 0.8333 \n",
      "Epoch 42 |train_loss : 0.6793 |train_acc : 0.7083 |test_loss : 0.6360 |test_acc : 0.8333 \n",
      "Epoch 43 |train_loss : 0.6836 |train_acc : 0.7083 |test_loss : 0.6258 |test_acc : 0.8333 \n",
      "Epoch 44 |train_loss : 0.6708 |train_acc : 0.7083 |test_loss : 0.6087 |test_acc : 0.8333 \n",
      "Epoch 45 |train_loss : 0.6845 |train_acc : 0.7083 |test_loss : 0.7022 |test_acc : 0.5833 \n",
      "Epoch 46 |train_loss : 0.6878 |train_acc : 0.7083 |test_loss : 0.6246 |test_acc : 0.8333 \n",
      "Epoch 47 |train_loss : 0.7241 |train_acc : 0.5833 |test_loss : 0.6937 |test_acc : 0.5833 \n",
      "Epoch 48 |train_loss : 0.6905 |train_acc : 0.7083 |test_loss : 0.6914 |test_acc : 0.5833 \n",
      "Epoch 49 |train_loss : 0.6914 |train_acc : 0.7083 |test_loss : 0.6714 |test_acc : 0.8333 \n",
      "Epoch 50 |train_loss : 0.7148 |train_acc : 0.5833 |test_loss : 0.6393 |test_acc : 0.8333 \n",
      "Epoch 51 |train_loss : 0.7094 |train_acc : 0.5833 |test_loss : 0.6586 |test_acc : 0.8333 \n",
      "Epoch 52 |train_loss : 0.6872 |train_acc : 0.5833 |test_loss : 0.7009 |test_acc : 0.1667 \n",
      "Epoch 53 |train_loss : 0.7108 |train_acc : 0.2917 |test_loss : 0.7060 |test_acc : 0.4167 \n",
      "Epoch 54 |train_loss : 0.7094 |train_acc : 0.2917 |test_loss : 0.6901 |test_acc : 0.8333 \n",
      "Epoch 55 |train_loss : 0.6771 |train_acc : 0.7083 |test_loss : 0.6346 |test_acc : 0.8333 \n",
      "Epoch 56 |train_loss : 0.6673 |train_acc : 0.7083 |test_loss : 0.6173 |test_acc : 0.8333 \n",
      "Epoch 57 |train_loss : 0.6523 |train_acc : 0.7083 |test_loss : 0.5745 |test_acc : 0.8333 \n",
      "Epoch 58 |train_loss : 0.7748 |train_acc : 0.5833 |test_loss : 0.7178 |test_acc : 0.5833 \n",
      "Epoch 59 |train_loss : 0.7309 |train_acc : 0.5833 |test_loss : 0.6587 |test_acc : 0.8333 \n",
      "Epoch 60 |train_loss : 0.7141 |train_acc : 0.2917 |test_loss : 0.7244 |test_acc : 0.1667 \n",
      "Epoch 61 |train_loss : 0.7000 |train_acc : 0.4583 |test_loss : 0.6732 |test_acc : 0.8333 \n",
      "Epoch 62 |train_loss : 0.7157 |train_acc : 0.5833 |test_loss : 0.6324 |test_acc : 0.8333 \n",
      "Epoch 63 |train_loss : 0.6851 |train_acc : 0.7083 |test_loss : 0.6468 |test_acc : 0.8333 \n",
      "Epoch 64 |train_loss : 0.7173 |train_acc : 0.5833 |test_loss : 0.6403 |test_acc : 0.8333 \n",
      "Epoch 65 |train_loss : 0.6987 |train_acc : 0.5833 |test_loss : 0.6983 |test_acc : 0.1667 \n",
      "Epoch 66 |train_loss : 0.6857 |train_acc : 0.4167 |test_loss : 0.7018 |test_acc : 0.4167 \n",
      "Epoch 67 |train_loss : 0.7167 |train_acc : 0.2917 |test_loss : 0.7066 |test_acc : 0.4167 \n",
      "Epoch 68 |train_loss : 0.7177 |train_acc : 0.3333 |test_loss : 0.6812 |test_acc : 0.8333 \n",
      "Epoch 69 |train_loss : 0.6986 |train_acc : 0.3750 |test_loss : 0.6922 |test_acc : 0.5833 \n",
      "Epoch 70 |train_loss : 0.6879 |train_acc : 0.7083 |test_loss : 0.6083 |test_acc : 0.8333 \n",
      "Epoch 71 |train_loss : 0.7249 |train_acc : 0.5833 |test_loss : 0.6181 |test_acc : 0.8333 \n",
      "Epoch 72 |train_loss : 0.6937 |train_acc : 0.7083 |test_loss : 0.6914 |test_acc : 0.5833 \n",
      "Epoch 73 |train_loss : 0.6840 |train_acc : 0.7083 |test_loss : 0.6393 |test_acc : 0.8333 \n",
      "Epoch 74 |train_loss : 0.6598 |train_acc : 0.7083 |test_loss : 0.6197 |test_acc : 0.8333 \n",
      "Epoch 75 |train_loss : 0.7598 |train_acc : 0.5833 |test_loss : 0.5714 |test_acc : 0.8333 \n",
      "Epoch 76 |train_loss : 0.7335 |train_acc : 0.5833 |test_loss : 0.6936 |test_acc : 0.5833 \n",
      "Epoch 77 |train_loss : 0.6797 |train_acc : 0.5833 |test_loss : 0.7165 |test_acc : 0.1667 \n",
      "Epoch 78 |train_loss : 0.6888 |train_acc : 0.4167 |test_loss : 0.7734 |test_acc : 0.1667 \n",
      "Epoch 79 |train_loss : 0.7359 |train_acc : 0.2917 |test_loss : 0.7732 |test_acc : 0.1667 \n",
      "Epoch 80 |train_loss : 0.7028 |train_acc : 0.2917 |test_loss : 0.6747 |test_acc : 0.8333 \n",
      "Epoch 81 |train_loss : 0.6647 |train_acc : 0.7083 |test_loss : 0.6244 |test_acc : 0.8333 \n",
      "Epoch 82 |train_loss : 0.7507 |train_acc : 0.5833 |test_loss : 0.6032 |test_acc : 0.8333 \n",
      "Epoch 83 |train_loss : 0.6936 |train_acc : 0.7083 |test_loss : 0.6367 |test_acc : 0.8333 \n",
      "Epoch 84 |train_loss : 0.7093 |train_acc : 0.5833 |test_loss : 0.6914 |test_acc : 0.5833 \n",
      "Epoch 85 |train_loss : 0.7014 |train_acc : 0.5000 |test_loss : 0.7080 |test_acc : 0.1667 \n",
      "Epoch 86 |train_loss : 0.6955 |train_acc : 0.4167 |test_loss : 0.7532 |test_acc : 0.1667 \n",
      "Epoch 87 |train_loss : 0.7016 |train_acc : 0.4167 |test_loss : 0.7242 |test_acc : 0.1667 \n",
      "Epoch 88 |train_loss : 0.7211 |train_acc : 0.2917 |test_loss : 0.6974 |test_acc : 0.4167 \n",
      "Epoch 89 |train_loss : 0.6844 |train_acc : 0.6250 |test_loss : 0.6489 |test_acc : 0.8333 \n",
      "Epoch 90 |train_loss : 0.6681 |train_acc : 0.7083 |test_loss : 0.6994 |test_acc : 0.5833 \n",
      "Epoch 91 |train_loss : 0.6795 |train_acc : 0.7083 |test_loss : 0.5865 |test_acc : 0.8333 \n",
      "Epoch 92 |train_loss : 0.6827 |train_acc : 0.7083 |test_loss : 0.5748 |test_acc : 0.8333 \n",
      "Epoch 93 |train_loss : 0.6683 |train_acc : 0.7083 |test_loss : 0.7049 |test_acc : 0.5833 \n",
      "Epoch 94 |train_loss : 0.7314 |train_acc : 0.5833 |test_loss : 0.5995 |test_acc : 0.8333 \n",
      "Epoch 95 |train_loss : 0.6766 |train_acc : 0.7083 |test_loss : 0.6486 |test_acc : 0.8333 \n",
      "Epoch 96 |train_loss : 0.6792 |train_acc : 0.7083 |test_loss : 0.6975 |test_acc : 0.5833 \n",
      "Epoch 97 |train_loss : 0.6830 |train_acc : 0.7083 |test_loss : 0.6988 |test_acc : 0.5833 \n",
      "Epoch 98 |train_loss : 0.7213 |train_acc : 0.5833 |test_loss : 0.6291 |test_acc : 0.8333 \n",
      "Epoch 99 |train_loss : 0.6750 |train_acc : 0.7083 |test_loss : 0.6484 |test_acc : 0.8333 \n",
      "Epoch 100 |train_loss : 0.6877 |train_acc : 0.7083 |test_loss : 0.6594 |test_acc : 0.8333 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 3\n",
      "[INFO] model: custom_resnet152\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new resnet152 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet152/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39a44b06a0b4e6c8c2e328192aaf628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7377 |train_acc : 0.2917 |test_loss : 0.6664 |test_acc : 0.8333 \n",
      "Epoch 2 |train_loss : 0.6866 |train_acc : 0.4583 |test_loss : 0.6961 |test_acc : 0.3333 \n",
      "Epoch 3 |train_loss : 0.6773 |train_acc : 0.7500 |test_loss : 0.6340 |test_acc : 0.8333 \n",
      "Epoch 4 |train_loss : 0.6391 |train_acc : 0.7083 |test_loss : 0.5988 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.7343 |train_acc : 0.5833 |test_loss : 0.7050 |test_acc : 0.5833 \n",
      "Epoch 6 |train_loss : 0.6642 |train_acc : 0.6250 |test_loss : 0.6599 |test_acc : 0.7500 \n",
      "Epoch 7 |train_loss : 0.6335 |train_acc : 0.7083 |test_loss : 0.6977 |test_acc : 0.5000 \n",
      "Epoch 8 |train_loss : 0.6324 |train_acc : 0.5417 |test_loss : 0.6592 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.7301 |train_acc : 0.6250 |test_loss : 0.6909 |test_acc : 0.5833 \n",
      "Epoch 10 |train_loss : 0.6052 |train_acc : 0.7917 |test_loss : 0.7051 |test_acc : 0.2500 \n",
      "Epoch 11 |train_loss : 0.5882 |train_acc : 0.6250 |test_loss : 0.8017 |test_acc : 0.1667 \n",
      "Epoch 12 |train_loss : 0.6381 |train_acc : 0.4583 |test_loss : 0.6849 |test_acc : 0.4167 \n",
      "Epoch 13 |train_loss : 0.6325 |train_acc : 0.6667 |test_loss : 0.5694 |test_acc : 0.8333 \n",
      "Epoch 14 |train_loss : 0.5906 |train_acc : 0.7500 |test_loss : 0.5738 |test_acc : 0.9167 \n",
      "Epoch 15 |train_loss : 0.5623 |train_acc : 0.9583 |test_loss : 0.5618 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.5854 |train_acc : 0.7500 |test_loss : 0.5611 |test_acc : 0.9167 \n",
      "Epoch 17 |train_loss : 0.5116 |train_acc : 0.7917 |test_loss : 0.5912 |test_acc : 0.9167 \n",
      "Epoch 18 |train_loss : 0.4611 |train_acc : 1.0000 |test_loss : 0.6379 |test_acc : 0.6667 \n",
      "Epoch 19 |train_loss : 0.4213 |train_acc : 1.0000 |test_loss : 0.6133 |test_acc : 0.5833 \n",
      "Epoch 20 |train_loss : 0.4339 |train_acc : 0.9583 |test_loss : 0.5113 |test_acc : 0.9167 \n",
      "Epoch 21 |train_loss : 0.3795 |train_acc : 0.9583 |test_loss : 0.5310 |test_acc : 0.8333 \n",
      "Epoch 22 |train_loss : 0.3354 |train_acc : 1.0000 |test_loss : 0.5086 |test_acc : 0.9167 \n",
      "Epoch 23 |train_loss : 0.2977 |train_acc : 1.0000 |test_loss : 0.5110 |test_acc : 0.9167 \n",
      "Epoch 24 |train_loss : 0.2753 |train_acc : 1.0000 |test_loss : 0.4319 |test_acc : 0.9167 \n",
      "Epoch 25 |train_loss : 0.2824 |train_acc : 1.0000 |test_loss : 0.6613 |test_acc : 0.6667 \n",
      "Epoch 26 |train_loss : 0.2868 |train_acc : 1.0000 |test_loss : 0.5265 |test_acc : 0.9167 \n",
      "Epoch 27 |train_loss : 0.2368 |train_acc : 0.9583 |test_loss : 0.4490 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1949 |train_acc : 1.0000 |test_loss : 0.6378 |test_acc : 0.5833 \n",
      "Epoch 29 |train_loss : 0.1665 |train_acc : 1.0000 |test_loss : 0.3760 |test_acc : 0.9167 \n",
      "Epoch 30 |train_loss : 0.1444 |train_acc : 1.0000 |test_loss : 0.3342 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.1387 |train_acc : 1.0000 |test_loss : 0.6627 |test_acc : 0.6667 \n",
      "Epoch 32 |train_loss : 0.1255 |train_acc : 1.0000 |test_loss : 0.3860 |test_acc : 0.9167 \n",
      "Epoch 33 |train_loss : 0.0957 |train_acc : 1.0000 |test_loss : 0.7919 |test_acc : 0.6667 \n",
      "Epoch 34 |train_loss : 0.1124 |train_acc : 1.0000 |test_loss : 0.5976 |test_acc : 0.6667 \n",
      "Epoch 35 |train_loss : 0.0897 |train_acc : 1.0000 |test_loss : 0.3423 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.0812 |train_acc : 1.0000 |test_loss : 0.3488 |test_acc : 0.9167 \n",
      "Epoch 37 |train_loss : 0.0721 |train_acc : 1.0000 |test_loss : 0.2738 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0578 |train_acc : 1.0000 |test_loss : 0.4728 |test_acc : 0.9167 \n",
      "Epoch 39 |train_loss : 0.0444 |train_acc : 1.0000 |test_loss : 0.3647 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.0382 |train_acc : 1.0000 |test_loss : 0.3646 |test_acc : 0.9167 \n",
      "Epoch 41 |train_loss : 0.0369 |train_acc : 1.0000 |test_loss : 0.4347 |test_acc : 0.9167 \n",
      "Epoch 42 |train_loss : 0.0318 |train_acc : 1.0000 |test_loss : 0.3720 |test_acc : 0.9167 \n",
      "Epoch 43 |train_loss : 0.0311 |train_acc : 1.0000 |test_loss : 0.3521 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.0302 |train_acc : 1.0000 |test_loss : 0.3320 |test_acc : 0.9167 \n",
      "Epoch 45 |train_loss : 0.0282 |train_acc : 1.0000 |test_loss : 0.4469 |test_acc : 0.9167 \n",
      "Epoch 46 |train_loss : 0.0254 |train_acc : 1.0000 |test_loss : 0.3158 |test_acc : 0.9167 \n",
      "Epoch 47 |train_loss : 0.0234 |train_acc : 1.0000 |test_loss : 0.3570 |test_acc : 0.9167 \n",
      "Epoch 48 |train_loss : 0.0269 |train_acc : 1.0000 |test_loss : 0.7291 |test_acc : 0.6667 \n",
      "Epoch 49 |train_loss : 0.0223 |train_acc : 1.0000 |test_loss : 0.3525 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0165 |train_acc : 1.0000 |test_loss : 0.3320 |test_acc : 0.9167 \n",
      "Epoch 51 |train_loss : 0.0182 |train_acc : 1.0000 |test_loss : 0.3612 |test_acc : 0.9167 \n",
      "Epoch 52 |train_loss : 0.0187 |train_acc : 1.0000 |test_loss : 0.3665 |test_acc : 0.9167 \n",
      "Epoch 53 |train_loss : 0.0159 |train_acc : 1.0000 |test_loss : 0.5250 |test_acc : 0.9167 \n",
      "Epoch 54 |train_loss : 0.0154 |train_acc : 1.0000 |test_loss : 0.4178 |test_acc : 0.9167 \n",
      "Epoch 55 |train_loss : 0.0127 |train_acc : 1.0000 |test_loss : 0.3733 |test_acc : 0.9167 \n",
      "Epoch 56 |train_loss : 0.0133 |train_acc : 1.0000 |test_loss : 0.3799 |test_acc : 0.9167 \n",
      "Epoch 57 |train_loss : 0.0113 |train_acc : 1.0000 |test_loss : 0.4311 |test_acc : 0.9167 \n",
      "Epoch 58 |train_loss : 0.0117 |train_acc : 1.0000 |test_loss : 0.8615 |test_acc : 0.6667 \n",
      "Epoch 59 |train_loss : 0.0099 |train_acc : 1.0000 |test_loss : 0.4737 |test_acc : 0.9167 \n",
      "Epoch 60 |train_loss : 0.0089 |train_acc : 1.0000 |test_loss : 0.4268 |test_acc : 0.9167 \n",
      "Epoch 61 |train_loss : 0.0100 |train_acc : 1.0000 |test_loss : 0.4858 |test_acc : 0.9167 \n",
      "Epoch 62 |train_loss : 0.0088 |train_acc : 1.0000 |test_loss : 0.4915 |test_acc : 0.9167 \n",
      "Epoch 63 |train_loss : 0.0086 |train_acc : 1.0000 |test_loss : 0.3932 |test_acc : 0.9167 \n",
      "Epoch 64 |train_loss : 0.0073 |train_acc : 1.0000 |test_loss : 0.4086 |test_acc : 0.9167 \n",
      "Epoch 65 |train_loss : 0.0080 |train_acc : 1.0000 |test_loss : 0.4457 |test_acc : 0.9167 \n",
      "Epoch 66 |train_loss : 0.0075 |train_acc : 1.0000 |test_loss : 0.5106 |test_acc : 0.9167 \n",
      "Epoch 67 |train_loss : 0.0076 |train_acc : 1.0000 |test_loss : 0.9618 |test_acc : 0.6667 \n",
      "Epoch 68 |train_loss : 0.0068 |train_acc : 1.0000 |test_loss : 0.5290 |test_acc : 0.9167 \n",
      "Epoch 69 |train_loss : 0.0062 |train_acc : 1.0000 |test_loss : 0.9311 |test_acc : 0.6667 \n",
      "Epoch 70 |train_loss : 0.0058 |train_acc : 1.0000 |test_loss : 0.4206 |test_acc : 0.9167 \n",
      "Epoch 71 |train_loss : 0.0060 |train_acc : 1.0000 |test_loss : 0.4254 |test_acc : 0.9167 \n",
      "Epoch 72 |train_loss : 0.0063 |train_acc : 1.0000 |test_loss : 0.9249 |test_acc : 0.6667 \n",
      "Epoch 73 |train_loss : 0.0065 |train_acc : 1.0000 |test_loss : 0.3623 |test_acc : 0.9167 \n",
      "Epoch 74 |train_loss : 0.0053 |train_acc : 1.0000 |test_loss : 0.4501 |test_acc : 0.9167 \n",
      "Epoch 75 |train_loss : 0.0064 |train_acc : 1.0000 |test_loss : 0.4093 |test_acc : 0.9167 \n",
      "Epoch 76 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.4313 |test_acc : 0.9167 \n",
      "Epoch 77 |train_loss : 0.0048 |train_acc : 1.0000 |test_loss : 0.4904 |test_acc : 0.9167 \n",
      "Epoch 78 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.9980 |test_acc : 0.6667 \n",
      "Epoch 79 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.4078 |test_acc : 0.9167 \n",
      "Epoch 80 |train_loss : 0.0047 |train_acc : 1.0000 |test_loss : 0.4252 |test_acc : 0.9167 \n",
      "Epoch 81 |train_loss : 0.0042 |train_acc : 1.0000 |test_loss : 0.5120 |test_acc : 0.9167 \n",
      "Epoch 82 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.4324 |test_acc : 0.9167 \n",
      "Epoch 83 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.4200 |test_acc : 0.9167 \n",
      "Epoch 84 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 0.4044 |test_acc : 0.9167 \n",
      "Epoch 85 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.4071 |test_acc : 0.9167 \n",
      "Epoch 86 |train_loss : 0.0042 |train_acc : 1.0000 |test_loss : 0.4204 |test_acc : 0.9167 \n",
      "Epoch 87 |train_loss : 0.0039 |train_acc : 1.0000 |test_loss : 0.3497 |test_acc : 0.9167 \n",
      "Epoch 88 |train_loss : 0.0039 |train_acc : 1.0000 |test_loss : 0.3937 |test_acc : 0.9167 \n",
      "Epoch 89 |train_loss : 0.0033 |train_acc : 1.0000 |test_loss : 0.3999 |test_acc : 0.9167 \n",
      "Epoch 90 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.3733 |test_acc : 0.9167 \n",
      "Epoch 91 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.4031 |test_acc : 0.9167 \n",
      "Epoch 92 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 0.4162 |test_acc : 0.9167 \n",
      "Epoch 93 |train_loss : 0.0033 |train_acc : 1.0000 |test_loss : 0.3650 |test_acc : 0.9167 \n",
      "Epoch 94 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.4397 |test_acc : 0.9167 \n",
      "Epoch 95 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.4321 |test_acc : 0.9167 \n",
      "Epoch 96 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.3853 |test_acc : 0.9167 \n",
      "Epoch 97 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.3810 |test_acc : 0.9167 \n",
      "Epoch 98 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.4295 |test_acc : 0.9167 \n",
      "Epoch 99 |train_loss : 0.0027 |train_acc : 1.0000 |test_loss : 0.4034 |test_acc : 0.9167 \n",
      "Epoch 100 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.9972 |test_acc : 0.6667 \n",
      "Epoch 101 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.4191 |test_acc : 0.9167 \n",
      "Epoch 102 |train_loss : 0.0033 |train_acc : 1.0000 |test_loss : 0.3670 |test_acc : 0.9167 \n",
      "Epoch 103 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.3390 |test_acc : 0.9167 \n",
      "Epoch 104 |train_loss : 0.0029 |train_acc : 1.0000 |test_loss : 0.7797 |test_acc : 0.6667 \n",
      "Epoch 105 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.7966 |test_acc : 0.6667 \n",
      "Epoch 106 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.4038 |test_acc : 0.9167 \n",
      "Epoch 107 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.4442 |test_acc : 0.9167 \n",
      "Epoch 108 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.3331 |test_acc : 0.9167 \n",
      "Epoch 109 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.3202 |test_acc : 0.9167 \n",
      "Epoch 110 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.4400 |test_acc : 0.9167 \n",
      "Epoch 111 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.3262 |test_acc : 0.9167 \n",
      "Epoch 112 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.3511 |test_acc : 0.9167 \n",
      "Epoch 113 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.3411 |test_acc : 0.9167 \n",
      "Epoch 114 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.7621 |test_acc : 0.6667 \n",
      "Epoch 115 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.3263 |test_acc : 0.9167 \n",
      "Epoch 116 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.3824 |test_acc : 0.9167 \n",
      "Epoch 117 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.3340 |test_acc : 0.9167 \n",
      "Epoch 118 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.3142 |test_acc : 0.9167 \n",
      "Epoch 119 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.4125 |test_acc : 0.9167 \n",
      "Epoch 120 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.4027 |test_acc : 0.9167 \n",
      "Epoch 121 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.3634 |test_acc : 0.9167 \n",
      "Epoch 122 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.2606 |test_acc : 0.9167 \n",
      "Epoch 123 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.3274 |test_acc : 0.9167 \n",
      "Epoch 124 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3117 |test_acc : 0.9167 \n",
      "Epoch 125 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3337 |test_acc : 0.9167 \n",
      "Epoch 126 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3404 |test_acc : 0.9167 \n",
      "Epoch 127 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3297 |test_acc : 0.9167 \n",
      "Epoch 128 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3328 |test_acc : 0.9167 \n",
      "Epoch 129 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3776 |test_acc : 0.9167 \n",
      "Epoch 130 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3165 |test_acc : 0.9167 \n",
      "Epoch 131 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.7160 |test_acc : 0.6667 \n",
      "Epoch 132 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.3563 |test_acc : 0.9167 \n",
      "Epoch 133 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.3582 |test_acc : 0.9167 \n",
      "Epoch 134 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3162 |test_acc : 0.9167 \n",
      "Epoch 135 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.3094 |test_acc : 0.9167 \n",
      "Epoch 136 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.2880 |test_acc : 0.9167 \n",
      "Epoch 137 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.3761 |test_acc : 0.9167 \n",
      "Epoch 138 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.2762 |test_acc : 0.9167 \n",
      "Epoch 139 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.2997 |test_acc : 0.9167 \n",
      "Epoch 140 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3431 |test_acc : 0.9167 \n",
      "Epoch 141 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.2410 |test_acc : 0.9167 \n",
      "Epoch 142 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.6116 |test_acc : 0.6667 \n",
      "Epoch 143 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3221 |test_acc : 0.9167 \n",
      "Epoch 144 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.3062 |test_acc : 0.9167 \n",
      "Epoch 145 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.3113 |test_acc : 0.9167 \n",
      "Epoch 146 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.4169 |test_acc : 0.9167 \n",
      "Epoch 147 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.5266 |test_acc : 0.6667 \n",
      "Epoch 148 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.5199 |test_acc : 0.6667 \n",
      "Epoch 149 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3506 |test_acc : 0.9167 \n",
      "Epoch 150 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.2850 |test_acc : 0.9167 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 4\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet101/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf29f755ff994a3f8e8162efdd227baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7339 |train_acc : 0.2917 |test_loss : 0.6576 |test_acc : 0.8333 \n",
      "Epoch 2 |train_loss : 0.6736 |train_acc : 0.7083 |test_loss : 0.6244 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.6840 |train_acc : 0.7083 |test_loss : 0.6102 |test_acc : 0.8333 \n",
      "Epoch 4 |train_loss : 0.6700 |train_acc : 0.7083 |test_loss : 0.6202 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.6716 |train_acc : 0.7083 |test_loss : 0.7043 |test_acc : 0.5833 \n",
      "Epoch 6 |train_loss : 0.6818 |train_acc : 0.7083 |test_loss : 0.6136 |test_acc : 0.8333 \n",
      "Epoch 7 |train_loss : 0.7342 |train_acc : 0.5833 |test_loss : 0.5976 |test_acc : 0.8333 \n",
      "Epoch 8 |train_loss : 0.6822 |train_acc : 0.7083 |test_loss : 0.6392 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.6704 |train_acc : 0.7083 |test_loss : 0.6321 |test_acc : 0.8333 \n",
      "Epoch 10 |train_loss : 0.7035 |train_acc : 0.5833 |test_loss : 0.6488 |test_acc : 0.8333 \n",
      "Epoch 11 |train_loss : 0.6868 |train_acc : 0.7083 |test_loss : 0.6628 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.6764 |train_acc : 0.7083 |test_loss : 0.6446 |test_acc : 0.8333 \n",
      "Epoch 13 |train_loss : 0.6769 |train_acc : 0.7083 |test_loss : 0.6365 |test_acc : 0.8333 \n",
      "Epoch 14 |train_loss : 0.6817 |train_acc : 0.7083 |test_loss : 0.6204 |test_acc : 0.8333 \n",
      "Epoch 15 |train_loss : 0.6667 |train_acc : 0.7083 |test_loss : 0.6212 |test_acc : 0.8333 \n",
      "Epoch 16 |train_loss : 0.6900 |train_acc : 0.7083 |test_loss : 0.5970 |test_acc : 0.8333 \n",
      "Epoch 17 |train_loss : 0.6760 |train_acc : 0.7083 |test_loss : 0.5873 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.6712 |train_acc : 0.7083 |test_loss : 0.6126 |test_acc : 0.8333 \n",
      "Epoch 19 |train_loss : 0.6790 |train_acc : 0.7083 |test_loss : 0.5939 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.6772 |train_acc : 0.7083 |test_loss : 0.6039 |test_acc : 0.8333 \n",
      "Epoch 21 |train_loss : 0.7232 |train_acc : 0.5833 |test_loss : 0.7006 |test_acc : 0.5833 \n",
      "Epoch 22 |train_loss : 0.6887 |train_acc : 0.7083 |test_loss : 0.6309 |test_acc : 0.8333 \n",
      "Epoch 23 |train_loss : 0.7054 |train_acc : 0.5833 |test_loss : 0.6427 |test_acc : 0.8333 \n",
      "Epoch 24 |train_loss : 0.7005 |train_acc : 0.5833 |test_loss : 0.6754 |test_acc : 0.8333 \n",
      "Epoch 25 |train_loss : 0.6907 |train_acc : 0.5833 |test_loss : 0.6995 |test_acc : 0.1667 \n",
      "Epoch 26 |train_loss : 0.6916 |train_acc : 0.4167 |test_loss : 0.6986 |test_acc : 0.4167 \n",
      "Epoch 27 |train_loss : 0.6946 |train_acc : 0.4167 |test_loss : 0.7214 |test_acc : 0.1667 \n",
      "Epoch 28 |train_loss : 0.7124 |train_acc : 0.2917 |test_loss : 0.7294 |test_acc : 0.1667 \n",
      "Epoch 29 |train_loss : 0.6894 |train_acc : 0.6250 |test_loss : 0.6864 |test_acc : 0.5833 \n",
      "Epoch 30 |train_loss : 0.6603 |train_acc : 0.7083 |test_loss : 0.4975 |test_acc : 0.8333 \n",
      "Epoch 31 |train_loss : 0.6735 |train_acc : 0.7083 |test_loss : 0.6218 |test_acc : 0.8333 \n",
      "Epoch 32 |train_loss : 0.6908 |train_acc : 0.7083 |test_loss : 0.6325 |test_acc : 0.8333 \n",
      "Epoch 33 |train_loss : 0.6755 |train_acc : 0.5833 |test_loss : 0.5147 |test_acc : 0.8333 \n",
      "Epoch 34 |train_loss : 0.7369 |train_acc : 0.5833 |test_loss : 0.6274 |test_acc : 0.5833 \n",
      "Epoch 35 |train_loss : 0.7554 |train_acc : 0.3750 |test_loss : 0.7128 |test_acc : 0.1667 \n",
      "Epoch 36 |train_loss : 0.5958 |train_acc : 0.7500 |test_loss : 0.5027 |test_acc : 0.8333 \n",
      "Epoch 37 |train_loss : 0.6208 |train_acc : 0.5833 |test_loss : 0.6362 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.6085 |train_acc : 0.7917 |test_loss : 0.4659 |test_acc : 0.8333 \n",
      "Epoch 39 |train_loss : 0.6853 |train_acc : 0.6250 |test_loss : 0.5060 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.5936 |train_acc : 0.8333 |test_loss : 0.5441 |test_acc : 0.7500 \n",
      "Epoch 41 |train_loss : 0.5345 |train_acc : 0.9167 |test_loss : 0.5831 |test_acc : 0.7500 \n",
      "Epoch 42 |train_loss : 0.4662 |train_acc : 0.9583 |test_loss : 0.5076 |test_acc : 0.9167 \n",
      "Epoch 43 |train_loss : 0.4634 |train_acc : 0.8750 |test_loss : 0.4700 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.5169 |train_acc : 0.9167 |test_loss : 0.5917 |test_acc : 0.8333 \n",
      "Epoch 45 |train_loss : 0.4427 |train_acc : 0.9583 |test_loss : 0.4598 |test_acc : 0.8333 \n",
      "Epoch 46 |train_loss : 0.4123 |train_acc : 0.9583 |test_loss : 0.7204 |test_acc : 0.5000 \n",
      "Epoch 47 |train_loss : 0.4365 |train_acc : 1.0000 |test_loss : 0.6382 |test_acc : 0.5833 \n",
      "Epoch 48 |train_loss : 0.3423 |train_acc : 0.9583 |test_loss : 0.5869 |test_acc : 0.5833 \n",
      "Epoch 49 |train_loss : 0.3224 |train_acc : 0.9583 |test_loss : 0.4584 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.3318 |train_acc : 0.9583 |test_loss : 0.4791 |test_acc : 0.8333 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 5\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet101/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b57c9ab510b40da9bfa1b6a489c69eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7274 |train_acc : 0.3750 |test_loss : 0.6771 |test_acc : 0.8333 \n",
      "Epoch 2 |train_loss : 0.6792 |train_acc : 0.7083 |test_loss : 0.6305 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.7228 |train_acc : 0.5833 |test_loss : 0.7000 |test_acc : 0.5833 \n",
      "Epoch 4 |train_loss : 0.6792 |train_acc : 0.7083 |test_loss : 0.6221 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.7237 |train_acc : 0.5833 |test_loss : 0.6030 |test_acc : 0.8333 \n",
      "Epoch 6 |train_loss : 0.6957 |train_acc : 0.5833 |test_loss : 0.6327 |test_acc : 0.8333 \n",
      "Epoch 7 |train_loss : 0.6775 |train_acc : 0.7083 |test_loss : 0.6524 |test_acc : 0.8333 \n",
      "Epoch 8 |train_loss : 0.6812 |train_acc : 0.7083 |test_loss : 0.6571 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.7089 |train_acc : 0.5833 |test_loss : 0.6442 |test_acc : 0.8333 \n",
      "Epoch 10 |train_loss : 0.6836 |train_acc : 0.7083 |test_loss : 0.6909 |test_acc : 0.5833 \n",
      "Epoch 11 |train_loss : 0.6837 |train_acc : 0.7083 |test_loss : 0.6586 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.7075 |train_acc : 0.5833 |test_loss : 0.6915 |test_acc : 0.5833 \n",
      "Epoch 13 |train_loss : 0.6956 |train_acc : 0.7083 |test_loss : 0.6697 |test_acc : 0.8333 \n",
      "Epoch 14 |train_loss : 0.6820 |train_acc : 0.7083 |test_loss : 0.6396 |test_acc : 0.8333 \n",
      "Epoch 15 |train_loss : 0.6799 |train_acc : 0.7083 |test_loss : 0.6327 |test_acc : 0.8333 \n",
      "Epoch 16 |train_loss : 0.6697 |train_acc : 0.7083 |test_loss : 0.6179 |test_acc : 0.8333 \n",
      "Epoch 17 |train_loss : 0.7374 |train_acc : 0.5833 |test_loss : 0.6177 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.6761 |train_acc : 0.7083 |test_loss : 0.6937 |test_acc : 0.5833 \n",
      "Epoch 19 |train_loss : 0.6729 |train_acc : 0.7083 |test_loss : 0.6387 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.7150 |train_acc : 0.5833 |test_loss : 0.6199 |test_acc : 0.8333 \n",
      "Epoch 21 |train_loss : 0.6723 |train_acc : 0.7083 |test_loss : 0.6356 |test_acc : 0.8333 \n",
      "Epoch 22 |train_loss : 0.6985 |train_acc : 0.5833 |test_loss : 0.6502 |test_acc : 0.8333 \n",
      "Epoch 23 |train_loss : 0.7004 |train_acc : 0.5833 |test_loss : 0.6660 |test_acc : 0.8333 \n",
      "Epoch 24 |train_loss : 0.6981 |train_acc : 0.5833 |test_loss : 0.6756 |test_acc : 0.8333 \n",
      "Epoch 25 |train_loss : 0.7165 |train_acc : 0.2083 |test_loss : 0.7125 |test_acc : 0.1667 \n",
      "Epoch 26 |train_loss : 0.7014 |train_acc : 0.2500 |test_loss : 0.6797 |test_acc : 0.8333 \n",
      "Epoch 27 |train_loss : 0.6999 |train_acc : 0.5833 |test_loss : 0.6827 |test_acc : 0.8333 \n",
      "Epoch 28 |train_loss : 0.6926 |train_acc : 0.7083 |test_loss : 0.6801 |test_acc : 0.8333 \n",
      "Epoch 29 |train_loss : 0.7099 |train_acc : 0.5833 |test_loss : 0.6452 |test_acc : 0.8333 \n",
      "Epoch 30 |train_loss : 0.6832 |train_acc : 0.7083 |test_loss : 0.6527 |test_acc : 0.8333 \n",
      "Epoch 31 |train_loss : 0.6786 |train_acc : 0.7083 |test_loss : 0.6931 |test_acc : 0.5833 \n",
      "Epoch 32 |train_loss : 0.6740 |train_acc : 0.7083 |test_loss : 0.6205 |test_acc : 0.8333 \n",
      "Epoch 33 |train_loss : 0.7288 |train_acc : 0.5833 |test_loss : 0.5999 |test_acc : 0.8333 \n",
      "Epoch 34 |train_loss : 0.7172 |train_acc : 0.5833 |test_loss : 0.6949 |test_acc : 0.5833 \n",
      "Epoch 35 |train_loss : 0.7047 |train_acc : 0.5833 |test_loss : 0.6757 |test_acc : 0.8333 \n",
      "Epoch 36 |train_loss : 0.6942 |train_acc : 0.4167 |test_loss : 0.7258 |test_acc : 0.1667 \n",
      "Epoch 37 |train_loss : 0.7158 |train_acc : 0.2917 |test_loss : 0.7463 |test_acc : 0.1667 \n",
      "Epoch 38 |train_loss : 0.7002 |train_acc : 0.4167 |test_loss : 0.7116 |test_acc : 0.1667 \n",
      "Epoch 39 |train_loss : 0.7002 |train_acc : 0.2917 |test_loss : 0.6940 |test_acc : 0.1667 \n",
      "Epoch 40 |train_loss : 0.6841 |train_acc : 0.5417 |test_loss : 0.6919 |test_acc : 0.5833 \n",
      "Epoch 41 |train_loss : 0.7290 |train_acc : 0.5833 |test_loss : 0.6978 |test_acc : 0.5833 \n",
      "Epoch 42 |train_loss : 0.6804 |train_acc : 0.7083 |test_loss : 0.6238 |test_acc : 0.8333 \n",
      "Epoch 43 |train_loss : 0.6767 |train_acc : 0.7083 |test_loss : 0.6934 |test_acc : 0.5833 \n",
      "Epoch 44 |train_loss : 0.7122 |train_acc : 0.5833 |test_loss : 0.6374 |test_acc : 0.8333 \n",
      "Epoch 45 |train_loss : 0.6868 |train_acc : 0.7083 |test_loss : 0.6911 |test_acc : 0.5833 \n",
      "Epoch 46 |train_loss : 0.6743 |train_acc : 0.7083 |test_loss : 0.6918 |test_acc : 0.5833 \n",
      "Epoch 47 |train_loss : 0.6812 |train_acc : 0.7083 |test_loss : 0.6413 |test_acc : 0.8333 \n",
      "Epoch 48 |train_loss : 0.6816 |train_acc : 0.7083 |test_loss : 0.6312 |test_acc : 0.8333 \n",
      "Epoch 49 |train_loss : 0.6765 |train_acc : 0.7083 |test_loss : 0.6298 |test_acc : 0.8333 \n",
      "Epoch 50 |train_loss : 0.6680 |train_acc : 0.7083 |test_loss : 0.7004 |test_acc : 0.5833 \n",
      "Epoch 51 |train_loss : 0.6783 |train_acc : 0.7083 |test_loss : 0.6158 |test_acc : 0.8333 \n",
      "Epoch 52 |train_loss : 0.6729 |train_acc : 0.7083 |test_loss : 0.5843 |test_acc : 0.8333 \n",
      "Epoch 53 |train_loss : 0.6772 |train_acc : 0.7083 |test_loss : 0.7040 |test_acc : 0.5833 \n",
      "Epoch 54 |train_loss : 0.6876 |train_acc : 0.7083 |test_loss : 0.6040 |test_acc : 0.8333 \n",
      "Epoch 55 |train_loss : 0.7089 |train_acc : 0.5833 |test_loss : 0.6081 |test_acc : 0.8333 \n",
      "Epoch 56 |train_loss : 0.6884 |train_acc : 0.7083 |test_loss : 0.6365 |test_acc : 0.8333 \n",
      "Epoch 57 |train_loss : 0.7151 |train_acc : 0.5833 |test_loss : 0.6272 |test_acc : 0.8333 \n",
      "Epoch 58 |train_loss : 0.6876 |train_acc : 0.7083 |test_loss : 0.6425 |test_acc : 0.8333 \n",
      "Epoch 59 |train_loss : 0.7029 |train_acc : 0.5833 |test_loss : 0.6575 |test_acc : 0.8333 \n",
      "Epoch 60 |train_loss : 0.6973 |train_acc : 0.7083 |test_loss : 0.6837 |test_acc : 0.8333 \n",
      "Epoch 61 |train_loss : 0.7004 |train_acc : 0.5833 |test_loss : 0.6715 |test_acc : 0.8333 \n",
      "Epoch 62 |train_loss : 0.7036 |train_acc : 0.5833 |test_loss : 0.6651 |test_acc : 0.8333 \n",
      "Epoch 63 |train_loss : 0.6981 |train_acc : 0.5417 |test_loss : 0.6933 |test_acc : 0.4167 \n",
      "Epoch 64 |train_loss : 0.6907 |train_acc : 0.5417 |test_loss : 0.6748 |test_acc : 0.8333 \n",
      "Epoch 65 |train_loss : 0.7079 |train_acc : 0.5833 |test_loss : 0.6451 |test_acc : 0.8333 \n",
      "Epoch 66 |train_loss : 0.7070 |train_acc : 0.5833 |test_loss : 0.6378 |test_acc : 0.8333 \n",
      "Epoch 67 |train_loss : 0.7007 |train_acc : 0.5833 |test_loss : 0.6913 |test_acc : 0.5833 \n",
      "Epoch 68 |train_loss : 0.6996 |train_acc : 0.3750 |test_loss : 0.7010 |test_acc : 0.1667 \n",
      "Epoch 69 |train_loss : 0.6989 |train_acc : 0.3333 |test_loss : 0.6820 |test_acc : 0.8333 \n",
      "Epoch 70 |train_loss : 0.6885 |train_acc : 0.7083 |test_loss : 0.6909 |test_acc : 0.5833 \n",
      "Epoch 71 |train_loss : 0.6794 |train_acc : 0.7083 |test_loss : 0.6413 |test_acc : 0.8333 \n",
      "Epoch 72 |train_loss : 0.6767 |train_acc : 0.7083 |test_loss : 0.6342 |test_acc : 0.8333 \n",
      "Epoch 73 |train_loss : 0.7157 |train_acc : 0.5833 |test_loss : 0.6061 |test_acc : 0.8333 \n",
      "Epoch 74 |train_loss : 0.7144 |train_acc : 0.5833 |test_loss : 0.6365 |test_acc : 0.8333 \n",
      "Epoch 75 |train_loss : 0.6973 |train_acc : 0.5833 |test_loss : 0.6909 |test_acc : 0.5833 \n",
      "Epoch 76 |train_loss : 0.6939 |train_acc : 0.5417 |test_loss : 0.6955 |test_acc : 0.1667 \n",
      "Epoch 77 |train_loss : 0.6940 |train_acc : 0.2500 |test_loss : 0.6935 |test_acc : 0.4167 \n",
      "Epoch 78 |train_loss : 0.6955 |train_acc : 0.3750 |test_loss : 0.6893 |test_acc : 0.8333 \n",
      "Epoch 79 |train_loss : 0.6886 |train_acc : 0.7083 |test_loss : 0.6697 |test_acc : 0.8333 \n",
      "Epoch 80 |train_loss : 0.6754 |train_acc : 0.7083 |test_loss : 0.6442 |test_acc : 0.8333 \n",
      "Epoch 81 |train_loss : 0.6555 |train_acc : 0.7083 |test_loss : 0.6984 |test_acc : 0.5833 \n",
      "Epoch 82 |train_loss : 0.6759 |train_acc : 0.7083 |test_loss : 0.6062 |test_acc : 0.8333 \n",
      "Epoch 83 |train_loss : 0.6690 |train_acc : 0.7083 |test_loss : 0.5758 |test_acc : 0.8333 \n",
      "Epoch 84 |train_loss : 0.6769 |train_acc : 0.7083 |test_loss : 0.6062 |test_acc : 0.8333 \n",
      "Epoch 85 |train_loss : 0.7450 |train_acc : 0.5833 |test_loss : 0.6055 |test_acc : 0.8333 \n",
      "Epoch 86 |train_loss : 0.6992 |train_acc : 0.7083 |test_loss : 0.6404 |test_acc : 0.8333 \n",
      "Epoch 87 |train_loss : 0.6871 |train_acc : 0.7083 |test_loss : 0.6501 |test_acc : 0.8333 \n",
      "Epoch 88 |train_loss : 0.6815 |train_acc : 0.7083 |test_loss : 0.6469 |test_acc : 0.8333 \n",
      "Epoch 89 |train_loss : 0.6762 |train_acc : 0.7083 |test_loss : 0.6207 |test_acc : 0.8333 \n",
      "Epoch 90 |train_loss : 0.6682 |train_acc : 0.7083 |test_loss : 0.6225 |test_acc : 0.8333 \n",
      "Epoch 91 |train_loss : 0.6685 |train_acc : 0.7083 |test_loss : 0.5992 |test_acc : 0.8333 \n",
      "Epoch 92 |train_loss : 0.6835 |train_acc : 0.7083 |test_loss : 0.7036 |test_acc : 0.5833 \n",
      "Epoch 93 |train_loss : 0.7331 |train_acc : 0.5833 |test_loss : 0.5930 |test_acc : 0.8333 \n",
      "Epoch 94 |train_loss : 0.6902 |train_acc : 0.7083 |test_loss : 0.6927 |test_acc : 0.5833 \n",
      "Epoch 95 |train_loss : 0.6931 |train_acc : 0.7083 |test_loss : 0.6569 |test_acc : 0.8333 \n",
      "Epoch 96 |train_loss : 0.6819 |train_acc : 0.7083 |test_loss : 0.6452 |test_acc : 0.8333 \n",
      "Epoch 97 |train_loss : 0.6703 |train_acc : 0.7083 |test_loss : 0.6171 |test_acc : 0.8333 \n",
      "Epoch 98 |train_loss : 0.6803 |train_acc : 0.7083 |test_loss : 0.6994 |test_acc : 0.5833 \n",
      "Epoch 99 |train_loss : 0.7198 |train_acc : 0.5833 |test_loss : 0.6190 |test_acc : 0.8333 \n",
      "Epoch 100 |train_loss : 0.6794 |train_acc : 0.7083 |test_loss : 0.6343 |test_acc : 0.8333 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 6\n",
      "[INFO] model: custom_resnet101\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new resnet101 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_resnet101/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeec78bd471f41cebe4b31fabc0c2759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7709 |train_acc : 0.2917 |test_loss : 0.7438 |test_acc : 0.1667 \n",
      "Epoch 2 |train_loss : 0.6737 |train_acc : 0.5417 |test_loss : 0.6279 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.7208 |train_acc : 0.5833 |test_loss : 0.6628 |test_acc : 0.5833 \n",
      "Epoch 4 |train_loss : 0.6616 |train_acc : 0.7083 |test_loss : 0.6541 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.6362 |train_acc : 0.7500 |test_loss : 0.6055 |test_acc : 0.8333 \n",
      "Epoch 6 |train_loss : 0.6100 |train_acc : 0.7500 |test_loss : 0.5958 |test_acc : 0.8333 \n",
      "Epoch 7 |train_loss : 0.5984 |train_acc : 0.7500 |test_loss : 0.6055 |test_acc : 0.8333 \n",
      "Epoch 8 |train_loss : 0.5387 |train_acc : 0.7500 |test_loss : 0.5201 |test_acc : 0.8333 \n",
      "Epoch 9 |train_loss : 0.5556 |train_acc : 0.7083 |test_loss : 0.4902 |test_acc : 0.8333 \n",
      "Epoch 10 |train_loss : 0.5364 |train_acc : 0.8750 |test_loss : 0.5802 |test_acc : 0.8333 \n",
      "Epoch 11 |train_loss : 0.5434 |train_acc : 0.7083 |test_loss : 0.5099 |test_acc : 0.8333 \n",
      "Epoch 12 |train_loss : 0.4581 |train_acc : 0.9583 |test_loss : 0.4886 |test_acc : 0.8333 \n",
      "Epoch 13 |train_loss : 0.4277 |train_acc : 0.9583 |test_loss : 0.5736 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.3376 |train_acc : 0.9583 |test_loss : 0.5591 |test_acc : 0.5833 \n",
      "Epoch 15 |train_loss : 0.5220 |train_acc : 0.6250 |test_loss : 0.5369 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.3878 |train_acc : 1.0000 |test_loss : 0.7752 |test_acc : 0.2500 \n",
      "Epoch 17 |train_loss : 0.4471 |train_acc : 0.8333 |test_loss : 0.4863 |test_acc : 0.8333 \n",
      "Epoch 18 |train_loss : 0.2820 |train_acc : 1.0000 |test_loss : 0.5810 |test_acc : 0.5833 \n",
      "Epoch 19 |train_loss : 0.2417 |train_acc : 1.0000 |test_loss : 0.4497 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.2271 |train_acc : 0.9583 |test_loss : 0.5150 |test_acc : 0.9167 \n",
      "Epoch 21 |train_loss : 0.2250 |train_acc : 1.0000 |test_loss : 0.3880 |test_acc : 0.8333 \n",
      "Epoch 22 |train_loss : 0.2192 |train_acc : 1.0000 |test_loss : 0.3925 |test_acc : 0.9167 \n",
      "Epoch 23 |train_loss : 0.1962 |train_acc : 1.0000 |test_loss : 0.2836 |test_acc : 0.8333 \n",
      "Epoch 24 |train_loss : 0.2346 |train_acc : 0.9583 |test_loss : 0.3594 |test_acc : 0.9167 \n",
      "Epoch 25 |train_loss : 0.2054 |train_acc : 1.0000 |test_loss : 0.3909 |test_acc : 0.8333 \n",
      "Epoch 26 |train_loss : 0.2213 |train_acc : 0.9583 |test_loss : 0.4479 |test_acc : 0.8333 \n",
      "Epoch 27 |train_loss : 0.1431 |train_acc : 1.0000 |test_loss : 0.3670 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1014 |train_acc : 1.0000 |test_loss : 0.3038 |test_acc : 0.8333 \n",
      "Epoch 29 |train_loss : 0.0823 |train_acc : 1.0000 |test_loss : 0.2621 |test_acc : 0.9167 \n",
      "Epoch 30 |train_loss : 0.0647 |train_acc : 1.0000 |test_loss : 0.2919 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.0557 |train_acc : 1.0000 |test_loss : 0.2333 |test_acc : 0.9167 \n",
      "Epoch 32 |train_loss : 0.0379 |train_acc : 1.0000 |test_loss : 0.3696 |test_acc : 0.9167 \n",
      "Epoch 33 |train_loss : 0.0356 |train_acc : 1.0000 |test_loss : 0.2423 |test_acc : 0.9167 \n",
      "Epoch 34 |train_loss : 0.0432 |train_acc : 1.0000 |test_loss : 0.2649 |test_acc : 0.9167 \n",
      "Epoch 35 |train_loss : 0.0309 |train_acc : 1.0000 |test_loss : 0.3527 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.0362 |train_acc : 1.0000 |test_loss : 0.2865 |test_acc : 0.9167 \n",
      "Epoch 37 |train_loss : 0.0278 |train_acc : 1.0000 |test_loss : 0.3837 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0218 |train_acc : 1.0000 |test_loss : 0.2538 |test_acc : 0.9167 \n",
      "Epoch 39 |train_loss : 0.0180 |train_acc : 1.0000 |test_loss : 0.2146 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.0162 |train_acc : 1.0000 |test_loss : 0.2604 |test_acc : 0.9167 \n",
      "Epoch 41 |train_loss : 0.0133 |train_acc : 1.0000 |test_loss : 0.9400 |test_acc : 0.6667 \n",
      "Epoch 42 |train_loss : 0.0129 |train_acc : 1.0000 |test_loss : 0.9071 |test_acc : 0.6667 \n",
      "Epoch 43 |train_loss : 0.0127 |train_acc : 1.0000 |test_loss : 0.3823 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.0106 |train_acc : 1.0000 |test_loss : 0.3059 |test_acc : 0.9167 \n",
      "Epoch 45 |train_loss : 0.0133 |train_acc : 1.0000 |test_loss : 0.3867 |test_acc : 0.9167 \n",
      "Epoch 46 |train_loss : 0.0121 |train_acc : 1.0000 |test_loss : 0.3451 |test_acc : 0.9167 \n",
      "Epoch 47 |train_loss : 0.0095 |train_acc : 1.0000 |test_loss : 0.2808 |test_acc : 0.9167 \n",
      "Epoch 48 |train_loss : 0.0092 |train_acc : 1.0000 |test_loss : 0.3660 |test_acc : 0.9167 \n",
      "Epoch 49 |train_loss : 0.0084 |train_acc : 1.0000 |test_loss : 0.2875 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0082 |train_acc : 1.0000 |test_loss : 0.3281 |test_acc : 0.9167 \n",
      "Epoch 51 |train_loss : 0.0075 |train_acc : 1.0000 |test_loss : 0.3059 |test_acc : 0.9167 \n",
      "Epoch 52 |train_loss : 0.0074 |train_acc : 1.0000 |test_loss : 0.2788 |test_acc : 0.9167 \n",
      "Epoch 53 |train_loss : 0.0072 |train_acc : 1.0000 |test_loss : 0.3081 |test_acc : 0.9167 \n",
      "Epoch 54 |train_loss : 0.0084 |train_acc : 1.0000 |test_loss : 0.3108 |test_acc : 0.9167 \n",
      "Epoch 55 |train_loss : 0.0067 |train_acc : 1.0000 |test_loss : 0.3351 |test_acc : 0.9167 \n",
      "Epoch 56 |train_loss : 0.0060 |train_acc : 1.0000 |test_loss : 0.3304 |test_acc : 0.9167 \n",
      "Epoch 57 |train_loss : 0.0069 |train_acc : 1.0000 |test_loss : 0.3759 |test_acc : 0.9167 \n",
      "Epoch 58 |train_loss : 0.0050 |train_acc : 1.0000 |test_loss : 0.3747 |test_acc : 0.9167 \n",
      "Epoch 59 |train_loss : 0.0064 |train_acc : 1.0000 |test_loss : 0.3181 |test_acc : 0.9167 \n",
      "Epoch 60 |train_loss : 0.0051 |train_acc : 1.0000 |test_loss : 0.2925 |test_acc : 0.9167 \n",
      "Epoch 61 |train_loss : 0.0045 |train_acc : 1.0000 |test_loss : 0.4088 |test_acc : 0.9167 \n",
      "Epoch 62 |train_loss : 0.0049 |train_acc : 1.0000 |test_loss : 0.3233 |test_acc : 0.9167 \n",
      "Epoch 63 |train_loss : 0.0037 |train_acc : 1.0000 |test_loss : 0.3097 |test_acc : 0.9167 \n",
      "Epoch 64 |train_loss : 0.0053 |train_acc : 1.0000 |test_loss : 0.3132 |test_acc : 0.9167 \n",
      "Epoch 65 |train_loss : 0.0043 |train_acc : 1.0000 |test_loss : 0.4087 |test_acc : 0.9167 \n",
      "Epoch 66 |train_loss : 0.0038 |train_acc : 1.0000 |test_loss : 0.3441 |test_acc : 0.9167 \n",
      "Epoch 67 |train_loss : 0.0043 |train_acc : 1.0000 |test_loss : 0.3385 |test_acc : 0.9167 \n",
      "Epoch 68 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 1.1343 |test_acc : 0.6667 \n",
      "Epoch 69 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.3416 |test_acc : 0.9167 \n",
      "Epoch 70 |train_loss : 0.0030 |train_acc : 1.0000 |test_loss : 0.2946 |test_acc : 0.9167 \n",
      "Epoch 71 |train_loss : 0.0030 |train_acc : 1.0000 |test_loss : 0.3101 |test_acc : 0.9167 \n",
      "Epoch 72 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.3539 |test_acc : 0.9167 \n",
      "Epoch 73 |train_loss : 0.0030 |train_acc : 1.0000 |test_loss : 0.3740 |test_acc : 0.9167 \n",
      "Epoch 74 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.2955 |test_acc : 0.9167 \n",
      "Epoch 75 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.3300 |test_acc : 0.9167 \n",
      "Epoch 76 |train_loss : 0.0029 |train_acc : 1.0000 |test_loss : 0.3417 |test_acc : 0.9167 \n",
      "Epoch 77 |train_loss : 0.0031 |train_acc : 1.0000 |test_loss : 0.2545 |test_acc : 0.9167 \n",
      "Epoch 78 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.3298 |test_acc : 0.9167 \n",
      "Epoch 79 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.3286 |test_acc : 0.9167 \n",
      "Epoch 80 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.3702 |test_acc : 0.9167 \n",
      "Epoch 81 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.3139 |test_acc : 0.9167 \n",
      "Epoch 82 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.3362 |test_acc : 0.9167 \n",
      "Epoch 83 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.3860 |test_acc : 0.9167 \n",
      "Epoch 84 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 1.2428 |test_acc : 0.6667 \n",
      "Epoch 85 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.2710 |test_acc : 0.9167 \n",
      "Epoch 86 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.3903 |test_acc : 0.9167 \n",
      "Epoch 87 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.3878 |test_acc : 0.9167 \n",
      "Epoch 88 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.3193 |test_acc : 0.9167 \n",
      "Epoch 89 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.2997 |test_acc : 0.9167 \n",
      "Epoch 90 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.3093 |test_acc : 0.9167 \n",
      "Epoch 91 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.3451 |test_acc : 0.9167 \n",
      "Epoch 92 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.3038 |test_acc : 0.9167 \n",
      "Epoch 93 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.3222 |test_acc : 0.9167 \n",
      "Epoch 94 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.3150 |test_acc : 0.9167 \n",
      "Epoch 95 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 1.2187 |test_acc : 0.6667 \n",
      "Epoch 96 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 1.2288 |test_acc : 0.6667 \n",
      "Epoch 97 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3387 |test_acc : 0.9167 \n",
      "Epoch 98 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.3420 |test_acc : 0.9167 \n",
      "Epoch 99 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.3286 |test_acc : 0.9167 \n",
      "Epoch 100 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.4074 |test_acc : 0.9167 \n",
      "Epoch 101 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3807 |test_acc : 0.9167 \n",
      "Epoch 102 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.4041 |test_acc : 0.9167 \n",
      "Epoch 103 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 1.2468 |test_acc : 0.6667 \n",
      "Epoch 104 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.2988 |test_acc : 0.9167 \n",
      "Epoch 105 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.3281 |test_acc : 0.9167 \n",
      "Epoch 106 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.3988 |test_acc : 0.9167 \n",
      "Epoch 107 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.4038 |test_acc : 0.9167 \n",
      "Epoch 108 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 1.2958 |test_acc : 0.6667 \n",
      "Epoch 109 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3153 |test_acc : 0.9167 \n",
      "Epoch 110 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.3850 |test_acc : 0.9167 \n",
      "Epoch 111 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3815 |test_acc : 0.9167 \n",
      "Epoch 112 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.4050 |test_acc : 0.9167 \n",
      "Epoch 113 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3066 |test_acc : 0.9167 \n",
      "Epoch 114 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3827 |test_acc : 0.9167 \n",
      "Epoch 115 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3874 |test_acc : 0.9167 \n",
      "Epoch 116 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.2968 |test_acc : 0.9167 \n",
      "Epoch 117 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3723 |test_acc : 0.9167 \n",
      "Epoch 118 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3219 |test_acc : 0.9167 \n",
      "Epoch 119 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3230 |test_acc : 0.9167 \n",
      "Epoch 120 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3996 |test_acc : 0.9167 \n",
      "Epoch 121 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3212 |test_acc : 0.9167 \n",
      "Epoch 122 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3938 |test_acc : 0.9167 \n",
      "Epoch 123 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3146 |test_acc : 0.9167 \n",
      "Epoch 124 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3249 |test_acc : 0.9167 \n",
      "Epoch 125 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3299 |test_acc : 0.9167 \n",
      "Epoch 126 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3921 |test_acc : 0.9167 \n",
      "Epoch 127 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3308 |test_acc : 0.9167 \n",
      "Epoch 128 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.4127 |test_acc : 0.9167 \n",
      "Epoch 129 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.2875 |test_acc : 0.9167 \n",
      "Epoch 130 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.4005 |test_acc : 0.9167 \n",
      "Epoch 131 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3274 |test_acc : 0.9167 \n",
      "Epoch 132 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3279 |test_acc : 0.9167 \n",
      "Epoch 133 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3296 |test_acc : 0.9167 \n",
      "Epoch 134 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3281 |test_acc : 0.9167 \n",
      "Epoch 135 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3285 |test_acc : 0.9167 \n",
      "Epoch 136 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 1.4601 |test_acc : 0.6667 \n",
      "Epoch 137 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3422 |test_acc : 0.9167 \n",
      "Epoch 138 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.3265 |test_acc : 0.9167 \n",
      "Epoch 139 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3503 |test_acc : 0.9167 \n",
      "Epoch 140 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.4206 |test_acc : 0.9167 \n",
      "Epoch 141 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3934 |test_acc : 0.9167 \n",
      "Epoch 142 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 1.4259 |test_acc : 0.6667 \n",
      "Epoch 143 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.3222 |test_acc : 0.9167 \n",
      "Epoch 144 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.3300 |test_acc : 0.9167 \n",
      "Epoch 145 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.4061 |test_acc : 0.9167 \n",
      "Epoch 146 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.3452 |test_acc : 0.9167 \n",
      "Epoch 147 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.3472 |test_acc : 0.9167 \n",
      "Epoch 148 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.3310 |test_acc : 0.9167 \n",
      "Epoch 149 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.2788 |test_acc : 0.9167 \n",
      "Epoch 150 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.3365 |test_acc : 0.9167 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 7\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 50\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_effntb2/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452e8ea7d5cc4aad97158cd9fddcac14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7127 |train_acc : 0.5833 |test_loss : 0.8049 |test_acc : 0.1667 \n",
      "Epoch 2 |train_loss : 0.7449 |train_acc : 0.2917 |test_loss : 0.6718 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.6589 |train_acc : 0.6250 |test_loss : 0.6641 |test_acc : 0.5833 \n",
      "Epoch 4 |train_loss : 0.6821 |train_acc : 0.7083 |test_loss : 0.5121 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.6897 |train_acc : 0.7083 |test_loss : 0.6618 |test_acc : 0.6667 \n",
      "Epoch 6 |train_loss : 0.6704 |train_acc : 0.7083 |test_loss : 0.6558 |test_acc : 0.7500 \n",
      "Epoch 7 |train_loss : 0.5802 |train_acc : 0.7917 |test_loss : 0.5190 |test_acc : 0.9167 \n",
      "Epoch 8 |train_loss : 0.5730 |train_acc : 0.7500 |test_loss : 0.5137 |test_acc : 0.9167 \n",
      "Epoch 9 |train_loss : 0.6022 |train_acc : 0.6250 |test_loss : 0.5079 |test_acc : 0.9167 \n",
      "Epoch 10 |train_loss : 0.5622 |train_acc : 0.7917 |test_loss : 0.4747 |test_acc : 0.9167 \n",
      "Epoch 11 |train_loss : 0.5028 |train_acc : 0.7917 |test_loss : 0.4883 |test_acc : 0.9167 \n",
      "Epoch 12 |train_loss : 0.5749 |train_acc : 0.6250 |test_loss : 0.6984 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.4255 |train_acc : 0.9167 |test_loss : 0.4198 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.5066 |train_acc : 0.7500 |test_loss : 0.5864 |test_acc : 0.7500 \n",
      "Epoch 15 |train_loss : 0.4569 |train_acc : 0.7917 |test_loss : 0.4256 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.3348 |train_acc : 0.9583 |test_loss : 0.6390 |test_acc : 0.6667 \n",
      "Epoch 17 |train_loss : 0.3179 |train_acc : 0.9583 |test_loss : 0.4757 |test_acc : 0.9167 \n",
      "Epoch 18 |train_loss : 0.3307 |train_acc : 0.9583 |test_loss : 0.4201 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.2582 |train_acc : 0.9583 |test_loss : 0.3710 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.2644 |train_acc : 0.9583 |test_loss : 0.3355 |test_acc : 0.8333 \n",
      "Epoch 21 |train_loss : 0.2166 |train_acc : 1.0000 |test_loss : 0.2904 |test_acc : 0.9167 \n",
      "Epoch 22 |train_loss : 0.2525 |train_acc : 1.0000 |test_loss : 0.4786 |test_acc : 0.9167 \n",
      "Epoch 23 |train_loss : 0.4174 |train_acc : 0.7917 |test_loss : 0.3616 |test_acc : 0.9167 \n",
      "Epoch 24 |train_loss : 0.3539 |train_acc : 0.8750 |test_loss : 0.5117 |test_acc : 0.5833 \n",
      "Epoch 25 |train_loss : 0.1847 |train_acc : 1.0000 |test_loss : 0.3311 |test_acc : 0.9167 \n",
      "Epoch 26 |train_loss : 0.2711 |train_acc : 0.9583 |test_loss : 0.3324 |test_acc : 0.9167 \n",
      "Epoch 27 |train_loss : 0.1977 |train_acc : 1.0000 |test_loss : 0.2691 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1343 |train_acc : 1.0000 |test_loss : 0.4637 |test_acc : 0.9167 \n",
      "Epoch 29 |train_loss : 0.1174 |train_acc : 1.0000 |test_loss : 0.2654 |test_acc : 0.8333 \n",
      "Epoch 30 |train_loss : 0.1050 |train_acc : 1.0000 |test_loss : 0.2480 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.0906 |train_acc : 1.0000 |test_loss : 0.2143 |test_acc : 0.9167 \n",
      "Epoch 32 |train_loss : 0.0659 |train_acc : 1.0000 |test_loss : 0.2074 |test_acc : 0.8333 \n",
      "Epoch 33 |train_loss : 0.0646 |train_acc : 1.0000 |test_loss : 0.1743 |test_acc : 0.9167 \n",
      "Epoch 34 |train_loss : 0.0552 |train_acc : 1.0000 |test_loss : 0.1845 |test_acc : 0.9167 \n",
      "Epoch 35 |train_loss : 0.0398 |train_acc : 1.0000 |test_loss : 0.1528 |test_acc : 1.0000 \n",
      "Epoch 36 |train_loss : 0.0411 |train_acc : 1.0000 |test_loss : 0.1392 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0302 |train_acc : 1.0000 |test_loss : 0.1885 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0360 |train_acc : 1.0000 |test_loss : 0.2363 |test_acc : 0.9167 \n",
      "Epoch 39 |train_loss : 0.0363 |train_acc : 1.0000 |test_loss : 0.2785 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.0328 |train_acc : 1.0000 |test_loss : 0.1307 |test_acc : 1.0000 \n",
      "Epoch 41 |train_loss : 0.0395 |train_acc : 1.0000 |test_loss : 0.1283 |test_acc : 1.0000 \n",
      "Epoch 42 |train_loss : 0.0343 |train_acc : 1.0000 |test_loss : 0.1726 |test_acc : 0.9167 \n",
      "Epoch 43 |train_loss : 0.0431 |train_acc : 1.0000 |test_loss : 0.1472 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.0239 |train_acc : 1.0000 |test_loss : 0.1230 |test_acc : 1.0000 \n",
      "Epoch 45 |train_loss : 0.0175 |train_acc : 1.0000 |test_loss : 0.2393 |test_acc : 0.9167 \n",
      "Epoch 46 |train_loss : 0.0162 |train_acc : 1.0000 |test_loss : 0.1155 |test_acc : 1.0000 \n",
      "Epoch 47 |train_loss : 0.0123 |train_acc : 1.0000 |test_loss : 0.1073 |test_acc : 1.0000 \n",
      "Epoch 48 |train_loss : 0.0114 |train_acc : 1.0000 |test_loss : 0.2409 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0092 |train_acc : 1.0000 |test_loss : 0.1545 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0104 |train_acc : 1.0000 |test_loss : 0.1055 |test_acc : 0.9167 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 8\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 100\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_effntb2/100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532714acf0140cd81d5207dc3705f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7127 |train_acc : 0.5833 |test_loss : 0.8048 |test_acc : 0.1667 \n",
      "Epoch 2 |train_loss : 0.7449 |train_acc : 0.2917 |test_loss : 0.6718 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.6589 |train_acc : 0.6250 |test_loss : 0.6638 |test_acc : 0.5833 \n",
      "Epoch 4 |train_loss : 0.6821 |train_acc : 0.7083 |test_loss : 0.5119 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.6895 |train_acc : 0.7083 |test_loss : 0.6620 |test_acc : 0.6667 \n",
      "Epoch 6 |train_loss : 0.6704 |train_acc : 0.7083 |test_loss : 0.6558 |test_acc : 0.7500 \n",
      "Epoch 7 |train_loss : 0.5804 |train_acc : 0.7917 |test_loss : 0.5189 |test_acc : 0.9167 \n",
      "Epoch 8 |train_loss : 0.5730 |train_acc : 0.7500 |test_loss : 0.5142 |test_acc : 0.9167 \n",
      "Epoch 9 |train_loss : 0.6062 |train_acc : 0.6250 |test_loss : 0.5016 |test_acc : 0.9167 \n",
      "Epoch 10 |train_loss : 0.5847 |train_acc : 0.7917 |test_loss : 0.5051 |test_acc : 0.8333 \n",
      "Epoch 11 |train_loss : 0.5369 |train_acc : 0.7917 |test_loss : 0.5262 |test_acc : 0.9167 \n",
      "Epoch 12 |train_loss : 0.6021 |train_acc : 0.6250 |test_loss : 0.7456 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.4678 |train_acc : 0.7917 |test_loss : 0.5108 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.4557 |train_acc : 0.8333 |test_loss : 0.4464 |test_acc : 0.9167 \n",
      "Epoch 15 |train_loss : 0.4022 |train_acc : 0.9167 |test_loss : 0.4196 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.3413 |train_acc : 0.9583 |test_loss : 0.6893 |test_acc : 0.6667 \n",
      "Epoch 17 |train_loss : 0.3475 |train_acc : 0.9583 |test_loss : 0.4379 |test_acc : 0.9167 \n",
      "Epoch 18 |train_loss : 0.3560 |train_acc : 1.0000 |test_loss : 0.4517 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.3163 |train_acc : 0.9583 |test_loss : 0.3887 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.3019 |train_acc : 0.8333 |test_loss : 0.3594 |test_acc : 0.9167 \n",
      "Epoch 21 |train_loss : 0.2758 |train_acc : 0.9583 |test_loss : 0.2970 |test_acc : 0.9167 \n",
      "Epoch 22 |train_loss : 0.2690 |train_acc : 1.0000 |test_loss : 0.4627 |test_acc : 0.9167 \n",
      "Epoch 23 |train_loss : 0.3808 |train_acc : 0.7917 |test_loss : 0.4254 |test_acc : 1.0000 \n",
      "Epoch 24 |train_loss : 0.3978 |train_acc : 0.9583 |test_loss : 0.3819 |test_acc : 1.0000 \n",
      "Epoch 25 |train_loss : 0.2321 |train_acc : 1.0000 |test_loss : 0.3038 |test_acc : 0.9167 \n",
      "Epoch 26 |train_loss : 0.2718 |train_acc : 0.9583 |test_loss : 0.3335 |test_acc : 0.9167 \n",
      "Epoch 27 |train_loss : 0.2114 |train_acc : 1.0000 |test_loss : 0.2533 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1839 |train_acc : 1.0000 |test_loss : 0.4097 |test_acc : 0.9167 \n",
      "Epoch 29 |train_loss : 0.1405 |train_acc : 1.0000 |test_loss : 0.3180 |test_acc : 0.9167 \n",
      "Epoch 30 |train_loss : 0.1603 |train_acc : 1.0000 |test_loss : 0.2761 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.1172 |train_acc : 1.0000 |test_loss : 0.2231 |test_acc : 0.9167 \n",
      "Epoch 32 |train_loss : 0.0904 |train_acc : 1.0000 |test_loss : 0.2466 |test_acc : 0.9167 \n",
      "Epoch 33 |train_loss : 0.0885 |train_acc : 1.0000 |test_loss : 0.1759 |test_acc : 0.9167 \n",
      "Epoch 34 |train_loss : 0.0973 |train_acc : 1.0000 |test_loss : 0.2344 |test_acc : 0.9167 \n",
      "Epoch 35 |train_loss : 0.0553 |train_acc : 1.0000 |test_loss : 0.3319 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.0720 |train_acc : 1.0000 |test_loss : 0.1596 |test_acc : 1.0000 \n",
      "Epoch 37 |train_loss : 0.0632 |train_acc : 1.0000 |test_loss : 0.2441 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0728 |train_acc : 0.9583 |test_loss : 0.2272 |test_acc : 1.0000 \n",
      "Epoch 39 |train_loss : 0.0708 |train_acc : 1.0000 |test_loss : 0.2227 |test_acc : 1.0000 \n",
      "Epoch 40 |train_loss : 0.0583 |train_acc : 1.0000 |test_loss : 0.2590 |test_acc : 0.9167 \n",
      "Epoch 41 |train_loss : 0.1128 |train_acc : 1.0000 |test_loss : 0.1557 |test_acc : 0.9167 \n",
      "Epoch 42 |train_loss : 0.1036 |train_acc : 1.0000 |test_loss : 0.2039 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.1021 |train_acc : 1.0000 |test_loss : 0.3990 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.1130 |train_acc : 1.0000 |test_loss : 0.1929 |test_acc : 0.9167 \n",
      "Epoch 45 |train_loss : 0.0370 |train_acc : 1.0000 |test_loss : 0.3330 |test_acc : 0.9167 \n",
      "Epoch 46 |train_loss : 0.0322 |train_acc : 1.0000 |test_loss : 0.2061 |test_acc : 0.9167 \n",
      "Epoch 47 |train_loss : 0.0305 |train_acc : 1.0000 |test_loss : 0.1441 |test_acc : 0.9167 \n",
      "Epoch 48 |train_loss : 0.0216 |train_acc : 1.0000 |test_loss : 0.2107 |test_acc : 1.0000 \n",
      "Epoch 49 |train_loss : 0.0225 |train_acc : 1.0000 |test_loss : 0.2141 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0175 |train_acc : 1.0000 |test_loss : 0.2037 |test_acc : 0.9167 \n",
      "Epoch 51 |train_loss : 0.0159 |train_acc : 1.0000 |test_loss : 0.1532 |test_acc : 0.9167 \n",
      "Epoch 52 |train_loss : 0.0135 |train_acc : 1.0000 |test_loss : 0.1781 |test_acc : 0.9167 \n",
      "Epoch 53 |train_loss : 0.0130 |train_acc : 1.0000 |test_loss : 0.1994 |test_acc : 0.9167 \n",
      "Epoch 54 |train_loss : 0.0099 |train_acc : 1.0000 |test_loss : 0.1107 |test_acc : 1.0000 \n",
      "Epoch 55 |train_loss : 0.0084 |train_acc : 1.0000 |test_loss : 0.1627 |test_acc : 1.0000 \n",
      "Epoch 56 |train_loss : 0.0106 |train_acc : 1.0000 |test_loss : 0.1068 |test_acc : 1.0000 \n",
      "Epoch 57 |train_loss : 0.0091 |train_acc : 1.0000 |test_loss : 0.0938 |test_acc : 1.0000 \n",
      "Epoch 58 |train_loss : 0.0071 |train_acc : 1.0000 |test_loss : 0.1153 |test_acc : 0.9167 \n",
      "Epoch 59 |train_loss : 0.0077 |train_acc : 1.0000 |test_loss : 0.1218 |test_acc : 0.9167 \n",
      "Epoch 60 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.1561 |test_acc : 1.0000 \n",
      "Epoch 61 |train_loss : 0.0063 |train_acc : 1.0000 |test_loss : 0.0715 |test_acc : 1.0000 \n",
      "Epoch 62 |train_loss : 0.0056 |train_acc : 1.0000 |test_loss : 0.0807 |test_acc : 1.0000 \n",
      "Epoch 63 |train_loss : 0.0048 |train_acc : 1.0000 |test_loss : 0.1636 |test_acc : 1.0000 \n",
      "Epoch 64 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.0760 |test_acc : 1.0000 \n",
      "Epoch 65 |train_loss : 0.0049 |train_acc : 1.0000 |test_loss : 0.0725 |test_acc : 1.0000 \n",
      "Epoch 66 |train_loss : 0.0046 |train_acc : 1.0000 |test_loss : 0.0796 |test_acc : 1.0000 \n",
      "Epoch 67 |train_loss : 0.0050 |train_acc : 1.0000 |test_loss : 0.0611 |test_acc : 1.0000 \n",
      "Epoch 68 |train_loss : 0.0038 |train_acc : 1.0000 |test_loss : 0.1420 |test_acc : 1.0000 \n",
      "Epoch 69 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.0608 |test_acc : 1.0000 \n",
      "Epoch 70 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.0644 |test_acc : 1.0000 \n",
      "Epoch 71 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.0637 |test_acc : 1.0000 \n",
      "Epoch 72 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.0855 |test_acc : 1.0000 \n",
      "Epoch 73 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.0501 |test_acc : 1.0000 \n",
      "Epoch 74 |train_loss : 0.0030 |train_acc : 1.0000 |test_loss : 0.0800 |test_acc : 1.0000 \n",
      "Epoch 75 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.0483 |test_acc : 1.0000 \n",
      "Epoch 76 |train_loss : 0.0036 |train_acc : 1.0000 |test_loss : 0.0477 |test_acc : 1.0000 \n",
      "Epoch 77 |train_loss : 0.0029 |train_acc : 1.0000 |test_loss : 0.0493 |test_acc : 1.0000 \n",
      "Epoch 78 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.0635 |test_acc : 1.0000 \n",
      "Epoch 79 |train_loss : 0.0027 |train_acc : 1.0000 |test_loss : 0.0586 |test_acc : 1.0000 \n",
      "Epoch 80 |train_loss : 0.0024 |train_acc : 1.0000 |test_loss : 0.0384 |test_acc : 1.0000 \n",
      "Epoch 81 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.0435 |test_acc : 1.0000 \n",
      "Epoch 82 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.0425 |test_acc : 1.0000 \n",
      "Epoch 83 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0537 |test_acc : 1.0000 \n",
      "Epoch 84 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0479 |test_acc : 1.0000 \n",
      "Epoch 85 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.0647 |test_acc : 1.0000 \n",
      "Epoch 86 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0500 |test_acc : 1.0000 \n",
      "Epoch 87 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0470 |test_acc : 1.0000 \n",
      "Epoch 88 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.0530 |test_acc : 1.0000 \n",
      "Epoch 89 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.1116 |test_acc : 1.0000 \n",
      "Epoch 90 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0543 |test_acc : 1.0000 \n",
      "Epoch 91 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.1101 |test_acc : 1.0000 \n",
      "Epoch 92 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.1004 |test_acc : 1.0000 \n",
      "Epoch 93 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0646 |test_acc : 1.0000 \n",
      "Epoch 94 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.0566 |test_acc : 1.0000 \n",
      "Epoch 95 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.0458 |test_acc : 1.0000 \n",
      "Epoch 96 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.1073 |test_acc : 1.0000 \n",
      "Epoch 97 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0568 |test_acc : 1.0000 \n",
      "Epoch 98 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0551 |test_acc : 1.0000 \n",
      "Epoch 99 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0484 |test_acc : 1.0000 \n",
      "Epoch 100 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.0405 |test_acc : 1.0000 \n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] Experiment number: 9\n",
      "[INFO] model: custom_effntb2\n",
      "[INFO] Optimizer: Adam\n",
      "[INFO] Epochs: 150\n",
      "[INFO] create new effntb2 model.\n",
      "[INFO] create summary writer, saving to: runs/2024-11-23/One_Session/Adam/custom_effntb2/150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f9b65d1a464dc4b855136d578fd9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 |train_loss : 0.7128 |train_acc : 0.5833 |test_loss : 0.8045 |test_acc : 0.1667 \n",
      "Epoch 2 |train_loss : 0.7450 |train_acc : 0.2917 |test_loss : 0.6722 |test_acc : 0.8333 \n",
      "Epoch 3 |train_loss : 0.6592 |train_acc : 0.6250 |test_loss : 0.6645 |test_acc : 0.5833 \n",
      "Epoch 4 |train_loss : 0.6824 |train_acc : 0.7083 |test_loss : 0.5125 |test_acc : 0.8333 \n",
      "Epoch 5 |train_loss : 0.6904 |train_acc : 0.7083 |test_loss : 0.6615 |test_acc : 0.6667 \n",
      "Epoch 6 |train_loss : 0.6708 |train_acc : 0.7500 |test_loss : 0.6560 |test_acc : 0.7500 \n",
      "Epoch 7 |train_loss : 0.5798 |train_acc : 0.8333 |test_loss : 0.5155 |test_acc : 0.9167 \n",
      "Epoch 8 |train_loss : 0.5764 |train_acc : 0.7083 |test_loss : 0.5201 |test_acc : 0.9167 \n",
      "Epoch 9 |train_loss : 0.6093 |train_acc : 0.6250 |test_loss : 0.5028 |test_acc : 0.9167 \n",
      "Epoch 10 |train_loss : 0.5880 |train_acc : 0.7500 |test_loss : 0.4956 |test_acc : 0.8333 \n",
      "Epoch 11 |train_loss : 0.5417 |train_acc : 0.7917 |test_loss : 0.5432 |test_acc : 0.9167 \n",
      "Epoch 12 |train_loss : 0.6010 |train_acc : 0.6250 |test_loss : 0.7471 |test_acc : 0.6667 \n",
      "Epoch 13 |train_loss : 0.4660 |train_acc : 0.7917 |test_loss : 0.5094 |test_acc : 0.9167 \n",
      "Epoch 14 |train_loss : 0.4560 |train_acc : 0.8333 |test_loss : 0.4431 |test_acc : 0.9167 \n",
      "Epoch 15 |train_loss : 0.3988 |train_acc : 0.9167 |test_loss : 0.4220 |test_acc : 0.9167 \n",
      "Epoch 16 |train_loss : 0.3365 |train_acc : 1.0000 |test_loss : 0.7244 |test_acc : 0.6667 \n",
      "Epoch 17 |train_loss : 0.3373 |train_acc : 0.9583 |test_loss : 0.4384 |test_acc : 1.0000 \n",
      "Epoch 18 |train_loss : 0.3517 |train_acc : 1.0000 |test_loss : 0.4463 |test_acc : 0.9167 \n",
      "Epoch 19 |train_loss : 0.3003 |train_acc : 0.9583 |test_loss : 0.3702 |test_acc : 0.8333 \n",
      "Epoch 20 |train_loss : 0.2691 |train_acc : 0.9167 |test_loss : 0.3760 |test_acc : 0.9167 \n",
      "Epoch 21 |train_loss : 0.2924 |train_acc : 0.9583 |test_loss : 0.2939 |test_acc : 0.9167 \n",
      "Epoch 22 |train_loss : 0.2700 |train_acc : 1.0000 |test_loss : 0.4740 |test_acc : 0.9167 \n",
      "Epoch 23 |train_loss : 0.3743 |train_acc : 0.7917 |test_loss : 0.5700 |test_acc : 0.3333 \n",
      "Epoch 24 |train_loss : 0.3630 |train_acc : 0.7500 |test_loss : 0.4480 |test_acc : 0.9167 \n",
      "Epoch 25 |train_loss : 0.1823 |train_acc : 1.0000 |test_loss : 0.3310 |test_acc : 0.9167 \n",
      "Epoch 26 |train_loss : 0.2568 |train_acc : 0.9583 |test_loss : 0.2765 |test_acc : 0.9167 \n",
      "Epoch 27 |train_loss : 0.2211 |train_acc : 1.0000 |test_loss : 0.2982 |test_acc : 0.9167 \n",
      "Epoch 28 |train_loss : 0.1492 |train_acc : 1.0000 |test_loss : 0.4106 |test_acc : 0.9167 \n",
      "Epoch 29 |train_loss : 0.1276 |train_acc : 1.0000 |test_loss : 0.2564 |test_acc : 0.9167 \n",
      "Epoch 30 |train_loss : 0.1131 |train_acc : 1.0000 |test_loss : 0.2664 |test_acc : 0.9167 \n",
      "Epoch 31 |train_loss : 0.1025 |train_acc : 1.0000 |test_loss : 0.2247 |test_acc : 0.9167 \n",
      "Epoch 32 |train_loss : 0.0730 |train_acc : 1.0000 |test_loss : 0.2320 |test_acc : 0.9167 \n",
      "Epoch 33 |train_loss : 0.0696 |train_acc : 1.0000 |test_loss : 0.1739 |test_acc : 0.9167 \n",
      "Epoch 34 |train_loss : 0.0549 |train_acc : 1.0000 |test_loss : 0.2825 |test_acc : 0.9167 \n",
      "Epoch 35 |train_loss : 0.0420 |train_acc : 1.0000 |test_loss : 0.2181 |test_acc : 0.9167 \n",
      "Epoch 36 |train_loss : 0.0344 |train_acc : 1.0000 |test_loss : 0.1829 |test_acc : 0.9167 \n",
      "Epoch 37 |train_loss : 0.0308 |train_acc : 1.0000 |test_loss : 0.2526 |test_acc : 0.9167 \n",
      "Epoch 38 |train_loss : 0.0359 |train_acc : 1.0000 |test_loss : 0.3495 |test_acc : 0.9167 \n",
      "Epoch 39 |train_loss : 0.0744 |train_acc : 1.0000 |test_loss : 0.4117 |test_acc : 0.9167 \n",
      "Epoch 40 |train_loss : 0.0642 |train_acc : 1.0000 |test_loss : 0.2228 |test_acc : 0.9167 \n",
      "Epoch 41 |train_loss : 0.0938 |train_acc : 1.0000 |test_loss : 0.2434 |test_acc : 0.9167 \n",
      "Epoch 42 |train_loss : 0.0426 |train_acc : 1.0000 |test_loss : 0.1274 |test_acc : 1.0000 \n",
      "Epoch 43 |train_loss : 0.0397 |train_acc : 1.0000 |test_loss : 0.1705 |test_acc : 0.9167 \n",
      "Epoch 44 |train_loss : 0.0331 |train_acc : 1.0000 |test_loss : 0.1388 |test_acc : 0.9167 \n",
      "Epoch 45 |train_loss : 0.0217 |train_acc : 1.0000 |test_loss : 0.1683 |test_acc : 1.0000 \n",
      "Epoch 46 |train_loss : 0.0175 |train_acc : 1.0000 |test_loss : 0.1382 |test_acc : 0.9167 \n",
      "Epoch 47 |train_loss : 0.0142 |train_acc : 1.0000 |test_loss : 0.1442 |test_acc : 0.9167 \n",
      "Epoch 48 |train_loss : 0.0122 |train_acc : 1.0000 |test_loss : 0.3193 |test_acc : 0.6667 \n",
      "Epoch 49 |train_loss : 0.0121 |train_acc : 1.0000 |test_loss : 0.1800 |test_acc : 0.9167 \n",
      "Epoch 50 |train_loss : 0.0099 |train_acc : 1.0000 |test_loss : 0.1245 |test_acc : 0.9167 \n",
      "Epoch 51 |train_loss : 0.0094 |train_acc : 1.0000 |test_loss : 0.1383 |test_acc : 0.9167 \n",
      "Epoch 52 |train_loss : 0.0082 |train_acc : 1.0000 |test_loss : 0.1627 |test_acc : 0.9167 \n",
      "Epoch 53 |train_loss : 0.0078 |train_acc : 1.0000 |test_loss : 0.1554 |test_acc : 0.9167 \n",
      "Epoch 54 |train_loss : 0.0073 |train_acc : 1.0000 |test_loss : 0.0898 |test_acc : 1.0000 \n",
      "Epoch 55 |train_loss : 0.0061 |train_acc : 1.0000 |test_loss : 0.1640 |test_acc : 0.9167 \n",
      "Epoch 56 |train_loss : 0.0075 |train_acc : 1.0000 |test_loss : 0.1118 |test_acc : 0.9167 \n",
      "Epoch 57 |train_loss : 0.0072 |train_acc : 1.0000 |test_loss : 0.0773 |test_acc : 1.0000 \n",
      "Epoch 58 |train_loss : 0.0059 |train_acc : 1.0000 |test_loss : 0.1657 |test_acc : 0.9167 \n",
      "Epoch 59 |train_loss : 0.0051 |train_acc : 1.0000 |test_loss : 0.1118 |test_acc : 0.9167 \n",
      "Epoch 60 |train_loss : 0.0043 |train_acc : 1.0000 |test_loss : 0.1610 |test_acc : 1.0000 \n",
      "Epoch 61 |train_loss : 0.0049 |train_acc : 1.0000 |test_loss : 0.0964 |test_acc : 0.9167 \n",
      "Epoch 62 |train_loss : 0.0044 |train_acc : 1.0000 |test_loss : 0.0919 |test_acc : 1.0000 \n",
      "Epoch 63 |train_loss : 0.0034 |train_acc : 1.0000 |test_loss : 0.1815 |test_acc : 1.0000 \n",
      "Epoch 64 |train_loss : 0.0033 |train_acc : 1.0000 |test_loss : 0.0899 |test_acc : 1.0000 \n",
      "Epoch 65 |train_loss : 0.0034 |train_acc : 1.0000 |test_loss : 0.1061 |test_acc : 1.0000 \n",
      "Epoch 66 |train_loss : 0.0033 |train_acc : 1.0000 |test_loss : 0.1277 |test_acc : 0.9167 \n",
      "Epoch 67 |train_loss : 0.0035 |train_acc : 1.0000 |test_loss : 0.1057 |test_acc : 0.9167 \n",
      "Epoch 68 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.1262 |test_acc : 1.0000 \n",
      "Epoch 69 |train_loss : 0.0032 |train_acc : 1.0000 |test_loss : 0.0914 |test_acc : 0.9167 \n",
      "Epoch 70 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.0947 |test_acc : 0.9167 \n",
      "Epoch 71 |train_loss : 0.0027 |train_acc : 1.0000 |test_loss : 0.1026 |test_acc : 1.0000 \n",
      "Epoch 72 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.1094 |test_acc : 1.0000 \n",
      "Epoch 73 |train_loss : 0.0028 |train_acc : 1.0000 |test_loss : 0.0845 |test_acc : 1.0000 \n",
      "Epoch 74 |train_loss : 0.0025 |train_acc : 1.0000 |test_loss : 0.1309 |test_acc : 0.9167 \n",
      "Epoch 75 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.0876 |test_acc : 1.0000 \n",
      "Epoch 76 |train_loss : 0.0026 |train_acc : 1.0000 |test_loss : 0.0773 |test_acc : 1.0000 \n",
      "Epoch 77 |train_loss : 0.0023 |train_acc : 1.0000 |test_loss : 0.0741 |test_acc : 1.0000 \n",
      "Epoch 78 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.1146 |test_acc : 0.9167 \n",
      "Epoch 79 |train_loss : 0.0022 |train_acc : 1.0000 |test_loss : 0.1078 |test_acc : 0.9167 \n",
      "Epoch 80 |train_loss : 0.0021 |train_acc : 1.0000 |test_loss : 0.0638 |test_acc : 1.0000 \n",
      "Epoch 81 |train_loss : 0.0018 |train_acc : 1.0000 |test_loss : 0.0837 |test_acc : 1.0000 \n",
      "Epoch 82 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0859 |test_acc : 0.9167 \n",
      "Epoch 83 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.0811 |test_acc : 1.0000 \n",
      "Epoch 84 |train_loss : 0.0020 |train_acc : 1.0000 |test_loss : 0.0863 |test_acc : 0.9167 \n",
      "Epoch 85 |train_loss : 0.0017 |train_acc : 1.0000 |test_loss : 0.1740 |test_acc : 0.9167 \n",
      "Epoch 86 |train_loss : 0.0019 |train_acc : 1.0000 |test_loss : 0.0827 |test_acc : 1.0000 \n",
      "Epoch 87 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0688 |test_acc : 1.0000 \n",
      "Epoch 88 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.0987 |test_acc : 1.0000 \n",
      "Epoch 89 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.3000 |test_acc : 0.6667 \n",
      "Epoch 90 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.1307 |test_acc : 0.9167 \n",
      "Epoch 91 |train_loss : 0.0015 |train_acc : 1.0000 |test_loss : 0.2624 |test_acc : 0.6667 \n",
      "Epoch 92 |train_loss : 0.0014 |train_acc : 1.0000 |test_loss : 0.2307 |test_acc : 1.0000 \n",
      "Epoch 93 |train_loss : 0.0016 |train_acc : 1.0000 |test_loss : 0.1311 |test_acc : 0.9167 \n",
      "Epoch 94 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.1398 |test_acc : 0.9167 \n",
      "Epoch 95 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.1294 |test_acc : 0.9167 \n",
      "Epoch 96 |train_loss : 0.0013 |train_acc : 1.0000 |test_loss : 0.2637 |test_acc : 0.6667 \n",
      "Epoch 97 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0964 |test_acc : 0.9167 \n",
      "Epoch 98 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.1157 |test_acc : 0.9167 \n",
      "Epoch 99 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.1105 |test_acc : 0.9167 \n",
      "Epoch 100 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0979 |test_acc : 0.9167 \n",
      "Epoch 101 |train_loss : 0.0012 |train_acc : 1.0000 |test_loss : 0.0897 |test_acc : 0.9167 \n",
      "Epoch 102 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.1206 |test_acc : 0.9167 \n",
      "Epoch 103 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.1108 |test_acc : 0.9167 \n",
      "Epoch 104 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.1054 |test_acc : 0.9167 \n",
      "Epoch 105 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.2777 |test_acc : 0.6667 \n",
      "Epoch 106 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.1126 |test_acc : 0.9167 \n",
      "Epoch 107 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.1095 |test_acc : 0.9167 \n",
      "Epoch 108 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.1108 |test_acc : 0.9167 \n",
      "Epoch 109 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.1357 |test_acc : 0.9167 \n",
      "Epoch 110 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.1193 |test_acc : 0.9167 \n",
      "Epoch 111 |train_loss : 0.0011 |train_acc : 1.0000 |test_loss : 0.1061 |test_acc : 0.9167 \n",
      "Epoch 112 |train_loss : 0.0010 |train_acc : 1.0000 |test_loss : 0.3734 |test_acc : 0.6667 \n",
      "Epoch 113 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1307 |test_acc : 0.9167 \n",
      "Epoch 114 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.0997 |test_acc : 0.9167 \n",
      "Epoch 115 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.0910 |test_acc : 0.9167 \n",
      "Epoch 116 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1262 |test_acc : 0.9167 \n",
      "Epoch 117 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1109 |test_acc : 0.9167 \n",
      "Epoch 118 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1370 |test_acc : 0.9167 \n",
      "Epoch 119 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1269 |test_acc : 0.9167 \n",
      "Epoch 120 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1281 |test_acc : 0.9167 \n",
      "Epoch 121 |train_loss : 0.0009 |train_acc : 1.0000 |test_loss : 0.3470 |test_acc : 0.6667 \n",
      "Epoch 122 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1454 |test_acc : 0.9167 \n",
      "Epoch 123 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.2276 |test_acc : 1.0000 \n",
      "Epoch 124 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0997 |test_acc : 1.0000 \n",
      "Epoch 125 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1076 |test_acc : 0.9167 \n",
      "Epoch 126 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1605 |test_acc : 0.9167 \n",
      "Epoch 127 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.0913 |test_acc : 1.0000 \n",
      "Epoch 128 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1101 |test_acc : 0.9167 \n",
      "Epoch 129 |train_loss : 0.0008 |train_acc : 1.0000 |test_loss : 0.1326 |test_acc : 0.9167 \n",
      "Epoch 130 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.0766 |test_acc : 1.0000 \n",
      "Epoch 131 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.1003 |test_acc : 1.0000 \n",
      "Epoch 132 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1569 |test_acc : 0.9167 \n",
      "Epoch 133 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.1308 |test_acc : 0.9167 \n",
      "Epoch 134 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1049 |test_acc : 0.9167 \n",
      "Epoch 135 |train_loss : 0.0007 |train_acc : 1.0000 |test_loss : 0.2021 |test_acc : 1.0000 \n",
      "Epoch 136 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1257 |test_acc : 0.9167 \n",
      "Epoch 137 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1278 |test_acc : 0.9167 \n",
      "Epoch 138 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1420 |test_acc : 0.9167 \n",
      "Epoch 139 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.2780 |test_acc : 0.6667 \n",
      "Epoch 140 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.1114 |test_acc : 0.9167 \n",
      "Epoch 141 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.1357 |test_acc : 0.9167 \n",
      "Epoch 142 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.3427 |test_acc : 0.6667 \n",
      "Epoch 143 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.3238 |test_acc : 0.6667 \n",
      "Epoch 144 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.2953 |test_acc : 0.6667 \n",
      "Epoch 145 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.3157 |test_acc : 0.6667 \n",
      "Epoch 146 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1309 |test_acc : 0.9167 \n",
      "Epoch 147 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.2338 |test_acc : 1.0000 \n",
      "Epoch 148 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.1166 |test_acc : 0.9167 \n",
      "Epoch 149 |train_loss : 0.0005 |train_acc : 1.0000 |test_loss : 0.1305 |test_acc : 0.9167 \n",
      "Epoch 150 |train_loss : 0.0006 |train_acc : 1.0000 |test_loss : 0.1265 |test_acc : 0.9167 \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.experiment_generator import run_experiments\n",
    "\n",
    "parameters = {\"epochs\": [50, 100, 150], \"optimizers\":[\"Adam\"], \"models\": [\"custom_resnet152\", \"custom_resnet101\", \"custom_effntb2\"], \"name\": \"One_Session\"}\n",
    "cm_fig = run_experiments(test_dataloader, train_dataloader, parameters, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
