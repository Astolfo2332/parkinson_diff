{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L13i1ZmhsR7A",
        "outputId": "614be495-34ef-4b72-c9e4-9ff15db0cd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision version not correct\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "torch version:2.5.1+cu121\n",
            "torchvision version:0.20.1+cu121\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import torch\n",
        "  import torcchvision\n",
        "  assert int(torch.__version__.split(\".\")) >=12, \"torch veraion should be 1.12+\"\n",
        "  assert int(torchvision.__version__.split(\".\")) >=0.13, \"torchvision version should be 0.13+\"\n",
        "  print(f\"torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")\n",
        "except:\n",
        "  print(f\"[INFO] torch/torchvision version not correct\")\n",
        "  !pip3 install -U torch torchvision\n",
        "  import torch\n",
        "  import torchvision\n",
        "  print(f\"torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8jKb9FfvAW6",
        "outputId": "fc3518fe-dd0a-4a4a-c83d-0cfe5190daa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torchinfo not found, installing it...\n",
            "[INFO] going_modular not found, installing it...\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4356, done.\u001b[K\n",
            "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 4356 (delta 213), reused 253 (delta 177), pack-reused 4035 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4356/4356), 654.51 MiB | 36.64 MiB/s, done.\n",
            "Resolving deltas: 100% (2584/2584), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] torchinfo not found, installing it...\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "\n",
        "try:\n",
        "  from going_modular import data_setup, engine\n",
        "except:\n",
        "  print(\"[INFO] going_modular not found, installing it...\")\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  from going_modular.going_modular import data_setup, engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bsYKV5MyxY4U",
        "outputId": "e93b8f37-c059-49b9-9cb6-86609a5efd79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ySSGkMa9u4Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3309e70-972b-4979-b08f-2c2d27cc21ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-A0NO4jzXGy",
        "outputId": "70184d8f-f93b-4494-ccc2-ddf9ffc56450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4356, done.\u001b[K\n",
            "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 4356 (delta 213), reused 253 (delta 177), pack-reused 4035 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4356/4356), 654.51 MiB | 40.95 MiB/s, done.\n",
            "Resolving deltas: 100% (2584/2584), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mrdbourke/pytorch-deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N4IU87R9zxiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a236762-f6b6-4003-9244-b0b48630a904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot move 'pytorch-deep-learning/going_modular' to './going_modular': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "!mv pytorch-deep-learning/going_modular ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OTIZteV9z4Ac"
      },
      "outputs": [],
      "source": [
        "!rm -rf pytorch-deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNTdX_E6xv-U",
        "outputId": "a368d91f-381e-4c47-d462-13db06fe4426"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91),\n",
              " (91, 109, 91)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "subjetos = [\"sub-RC4101\", \"sub-RC4103\", \"sub-RC4106\", \"sub-RC4107\"]\n",
        "sesiones = [\"ses-1\", \"ses-2\"]\n",
        "imag_norm = []\n",
        "for sujeto in subjetos:\n",
        "    for sesion in sesiones:\n",
        "        ruta = f\"drive/MyDrive/Colab Notebooks/output/derivatives/preprocessed/{sujeto}/{sesion}/anat/{sujeto}_{sesion}_T1w_brain_registered.nii.gz\"\n",
        "        img1= nib.load(ruta)\n",
        "        imag_norm.append(img1.shape)\n",
        "\n",
        "imag_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZTj83ty-n0mA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "base=\"drive/MyDrive/Colab Notebooks/output/derivatives/preprocessed\"\n",
        "imag_dir = []\n",
        "for sujeto in subjetos:\n",
        "  for sesion in sesiones:\n",
        "    ruta = f\"{base}/{sujeto}/{sesion}/anat/{sujeto}_{sesion}_T1w_brain_registered.nii.gz\"\n",
        "imag_dir.append(ruta)\n",
        "\n",
        "random.shuffle(imag_dir)\n",
        "train_ratio = 0.75\n",
        "train_size = int(len(imag_dir) * train_ratio)\n",
        "train= imag_dir[:train_size]\n",
        "test = imag_dir[train_size:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "subjetos = [\"sub-RC4101\", \"sub-RC4103\", \"sub-RC4106\", \"sub-RC4107\"]\n",
        "sesiones = [\"ses-1\", \"ses-2\"]\n",
        "base_path = \"drive/MyDrive/Colab Notebooks/output/derivatives/preprocessed\"\n",
        "\n",
        "\n",
        "image_paths = []\n",
        "for sujeto in subjetos:\n",
        "    for sesion in sesiones:\n",
        "        ruta = f\"{base_path}/{sujeto}/{sesion}/anat/{sujeto}_{sesion}_T1w_brain_registered.nii.gz\"\n",
        "        image_paths.append(ruta)\n",
        "\n",
        "random.shuffle(image_paths)\n",
        "\n",
        "train_ratio = 0.75\n",
        "train_size = int(len(image_paths) * train_ratio)\n",
        "train_paths = image_paths[:train_size]\n",
        "test_paths = image_paths[train_size:]\n",
        "\n",
        "def load_and_normalize_image(image_path):\n",
        "    image = nib.load(image_path).get_fdata()\n",
        "    image = image.astype(np.float32)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = torch.tensor(image)\n",
        "    mean = torch.tensor([0.485]).view(1, 1, 1, 1)\n",
        "    std = torch.tensor([0.229]).view(1, 1, 1, 1)\n",
        "    image = (image - mean) / std\n",
        "\n",
        "    return image\n",
        "\n",
        "train_images = torch.stack([load_and_normalize_image(p) for p in train_paths])\n",
        "test_images = torch.stack([load_and_normalize_image(p) for p in test_paths])\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_dataloader = DataLoader(TensorDataset(train_images), batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(TensorDataset(test_images), batch_size=batch_size, shuffle=False)\n",
        "for batch in train_dataloader:\n",
        "  print(f\"Tamaño del batch de entrenamiento: {batch[0].shape}\")\n",
        "for batch in test_dataloader:\n",
        "  print(f\"Tamaño del batch de prueba: {batch[0].shape}\")\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1oR02NwWhZt",
        "outputId": "a48d81c9-f431-4bff-947d-f995eee0a1f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de entrenamiento: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de prueba: torch.Size([1, 1, 91, 109, 91])\n",
            "Tamaño del batch de prueba: torch.Size([1, 1, 91, 109, 91])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b5dd7c9d8a0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b5dd7c9f8e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2miq92TLnPwQ"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import torch\n",
        "import numpy as np\n",
        "import random from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def load_and_normalize_image(image_path):\n",
        "    image = nib.load(image_path).get_fdata()\n",
        "    image = image.astype(np.float32)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = torch.tensor(image)\n",
        "    mean = torch.tensor([0.485]).view(1, 1, 1, 1, 1)\n",
        "    std = torch.tensor([0.229]).view(1, 1, 1, 1, 1)\n",
        "    image = (image - mean) / std\n",
        "    return image\n",
        "\n",
        "subjetos = [\"sub-RC4101\", \"sub-RC4103\", \"sub-RC4106\", \"sub-RC4107\"]\n",
        "sesiones = [\"ses-1\", \"ses-2\"]\n",
        "base_path = \"drive/MyDrive/Colab Notebooks/output/derivatives/preprocessed\"\n",
        "\n",
        "image_paths = []\n",
        "for sujeto in subjetos:\n",
        "    for sesion in sesiones:\n",
        "        ruta = f\"{base_path}/{sujeto}/{sesion}/anat/{sujeto}_{sesion}_T1w_brain_registered.nii.gz\"\n",
        "        image_paths.append(ruta)\n",
        "\n",
        "random.shuffle(image_paths)\n",
        "\n",
        "train_ratio = 0.75\n",
        "train_size = int(len(image_paths) * train_ratio)\n",
        "train_paths = image_paths[:train_size]\n",
        "test_paths = image_paths[train_size:]\n",
        "\n",
        "train_images = torch.stack([load_and_normalize_image(p) for p in train_paths])\n",
        "test_images = torch.stack([load_and_normalize_image(p) for p in test_paths])\n",
        "\n",
        "train_labels = torch.tensor([random.randint(0, 1) for _ in train_paths], dtype=torch.long)\n",
        "test_labels = torch.tensor([random.randint(0, 1) for _ in test_paths], dtype=torch.long)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_dataloader = DataLoader(TensorDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(TensorDataset(test_images, test_labels), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    print(f\"Tamaño del batch de entrenamiento: {batch[0].shape}\")\n",
        "    break\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    print(f\"Tamaño del batch de prueba: {batch[0].shape}\")\n",
        "    break\n",
        "\n",
        "train_dataloader, test_dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "QSejEOJnfkiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WACkjFBp3OLr"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model_dict = { 'efficientnet_b0': (torchvision.models.efficientnet_b0, torchvision.models.EfficientNet_B0_Weights.DEFAULT, 1280),\n",
        "              'vgg16': (torchvision.models.vgg16, torchvision.models.VGG16_Weights.DEFAULT, 25088),\n",
        "               'vgg19': (torchvision.models.vgg19, torchvision.models.VGG19_Weights.DEFAULT, 25088) }\n",
        "def prepare_model(model_name):\n",
        "    model_fn, weights, in_features = model_dict[model_name]\n",
        "    model = model_fn(weights=weights)\n",
        "    model.features[0][0] = nn.Conv3d(\n",
        "        in_channels=1,\n",
        "        out_channels=model.features[0][0].out_channels,\n",
        "        kernel_size=model.features[0][0].kernel_size,\n",
        "        stride=model.features[0][0].stride,\n",
        "        padding=model.features[0][0].padding,\n",
        "        bias=False\n",
        "    )\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(in_features=in_features, out_features=2)  # 2 salidas para las dos clases\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "    return model\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "model_names = ['efficientnet_b0', 'vgg16', 'vgg19']\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"Preparando y entrenando el modelo: {model_name}\")\n",
        "    model = prepare_model(model_name)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model = train_model(model, train_dataloader, criterion, optimizer, num_epochs)\n",
        "    print(f\"Entrenamiento del modelo {model_name} completado.\\n\")\n"
      ],
      "metadata": {
        "id": "K2k-E_gdqYxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}